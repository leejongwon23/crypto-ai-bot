from flask import Flask, jsonify, request, send_file
from recommend import main
import train, os, threading, datetime, pandas as pd, pytz, traceback, sys, shutil, time, csv
from apscheduler.schedulers.background import BackgroundScheduler
from telegram_bot import send_message
from predict_test import test_all_predictions
from data.utils import get_latest_price, SYMBOLS, get_kline_by_strategy
from predict_trigger import run as trigger_run

PERSIST_DIR = "/persistent"
MODEL_DIR = os.path.join(PERSIST_DIR, "models")
LOG_DIR = os.path.join(PERSIST_DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

LOG_FILE = os.path.join(LOG_DIR, "train_log.csv")
PREDICTION_LOG = os.path.join(PERSIST_DIR, "prediction_log.csv")
WRONG_PREDICTIONS = os.path.join(PERSIST_DIR, "wrong_predictions.csv")
AUDIT_LOG = os.path.join(LOG_DIR, "evaluation_audit.csv")
MESSAGE_LOG = os.path.join(LOG_DIR, "message_log.csv")
FAILURE_COUNT_LOG = os.path.join(LOG_DIR, "failure_count.csv")

VOLATILITY_THRESHOLD = {"ë‹¨ê¸°": 0.003, "ì¤‘ê¸°": 0.005, "ì¥ê¸°": 0.008}
PREDICTION_INTERVALS = {"ë‹¨ê¸°": 3600, "ì¤‘ê¸°": 10800, "ì¥ê¸°": 21600}
last_prediction_time = {s: 0 for s in PREDICTION_INTERVALS}

def get_symbols_by_volatility(strategy):
    if strategy not in VOLATILITY_THRESHOLD: return []
    threshold, selected = VOLATILITY_THRESHOLD[strategy], []
    for symbol in SYMBOLS:
        try:
            df = get_kline_by_strategy(symbol, strategy)
            if df is None or len(df) < 20: continue
            vol = df["close"].pct_change().rolling(window=20).std().iloc[-1]
            if vol and vol >= threshold: selected.append(symbol)
        except Exception as e:
            print(f"[ERROR] {symbol}-{strategy} ë³€ë™ì„± ê³„ì‚° ì‹¤íŒ¨: {e}")
    return selected

def start_regular_prediction_loop():
    def loop():
        while True:
            now = time.time()
            for s in PREDICTION_INTERVALS:
                if now - last_prediction_time[s] >= PREDICTION_INTERVALS[s]:
                    try:
                        print(f"[ì •ê¸° ì˜ˆì¸¡] {s} {datetime.datetime.now()} ì‹¤í–‰")
                        sys.stdout.flush()
                        main(s)
                        last_prediction_time[s] = time.time()
                    except Exception as e:
                        print(f"[ì •ê¸° ì˜ˆì¸¡ ì˜¤ë¥˜] {s}: {e}")
            time.sleep(60)
    threading.Thread(target=loop, daemon=True).start()

def start_scheduler():
    print(">>> start_scheduler() í˜¸ì¶œë¨")
    sys.stdout.flush()
    scheduler = BackgroundScheduler(timezone=pytz.timezone('Asia/Seoul'))
    scheduler.add_job(lambda: __import__('logger').evaluate_predictions(get_latest_price), 'cron', minute=20)
    scheduler.add_job(lambda: threading.Thread(target=train.train_model_loop, args=("ë‹¨ê¸°",), daemon=True).start(), 'cron', hour='0,3,6,9,12,15,18,21', minute=30)
    scheduler.add_job(lambda: threading.Thread(target=train.train_model_loop, args=("ì¤‘ê¸°",), daemon=True).start(), 'cron', hour='1,7,13,19', minute=30)
    scheduler.add_job(lambda: threading.Thread(target=train.train_model_loop, args=("ì¥ê¸°",), daemon=True).start(), 'cron', hour='2,14', minute=30)
    scheduler.add_job(test_all_predictions, 'cron', minute=10)
    scheduler.add_job(trigger_run, 'interval', minutes=30)
    scheduler.start()

app = Flask(__name__)
print(">>> Flask ì•± ìƒì„± ì™„ë£Œ")
sys.stdout.flush()

@app.route("/")
def index(): return "Yopo server is running"

@app.route("/ping")
def ping(): return "pong"

@app.route("/run")
def run():
    try:
        print("[RUN] main() ì‹¤í–‰ ì‹œì‘"); sys.stdout.flush()
        main()
        print("[RUN] main() ì‹¤í–‰ ì™„ë£Œ"); sys.stdout.flush()
        return "Recommendation started"
    except Exception as e:
        print("[ERROR] /run ì‹¤íŒ¨:"); traceback.print_exc(); sys.stdout.flush()
        return f"Error: {e}", 500

@app.route("/check-log")
def check_log():
    try:
        if not os.path.exists(PREDICTION_LOG): return jsonify({"error": "prediction_log.csv not found"})
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig")
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/train-now")
def train_now():
    try:
        threading.Thread(target=train.train_all_models, daemon=True).start()
        return "âœ… ëª¨ë“  ì½”ì¸ + ì „ëµ í•™ìŠµì´ ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘ëìŠµë‹ˆë‹¤!"
    except Exception as e:
        return f"í•™ìŠµ ì‹œì‘ ì‹¤íŒ¨: {e}", 500

@app.route("/train-log")
def train_log():
    try:
        if not os.path.exists(LOG_FILE): return "ì•„ì§ í•™ìŠµ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤."
        with open(LOG_FILE, "r", encoding="utf-8-sig") as f:
            return "<pre>" + f.read() + "</pre>"
    except Exception as e:
        return f"ë¡œê·¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}", 500

@app.route("/models")
def list_model_files():
    try:
        if not os.path.exists(MODEL_DIR): return "models í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        files = os.listdir(MODEL_DIR)
        return "<pre>" + "\n".join(files) + "</pre>" if files else "models í´ë”ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."
    except Exception as e:
        return f"ëª¨ë¸ íŒŒì¼ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", 500

@app.route("/check-wrong")
def check_wrong():
    try:
        if not os.path.exists(WRONG_PREDICTIONS): return jsonify([])
        df = pd.read_csv(WRONG_PREDICTIONS, encoding="utf-8-sig")
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-stats")
def check_stats():
    try:
        result = __import__('logger').print_prediction_stats()
        if not isinstance(result, str): return f"ì¶œë ¥ í˜•ì‹ ì˜¤ë¥˜: {result}", 500
        for s, r in {"ğŸ“Š":"<b>ğŸ“Š</b>", "âœ…":"<b style='color:green'>âœ…</b>", "âŒ":"<b style='color:red'>âŒ</b>", "â³":"<b>â³</b>", "ğŸ¯":"<b>ğŸ¯</b>", "ğŸ“Œ":"<b>ğŸ“Œ</b>"}.items():
            result = result.replace(s, r)
        return f"<div style='font-family:monospace; line-height:1.6;'>{result.replace(chr(10),'<br>')}</div>"
    except Exception as e:
        return f"ì •í™•ë„ í†µê³„ ì¶œë ¥ ì‹¤íŒ¨: {e}", 500

@app.route("/reset-all")
def reset_all():
    if request.args.get("key") != "3572": return "âŒ ì¸ì¦ ì‹¤íŒ¨: ì˜ëª»ëœ ì ‘ê·¼", 403
    try:
        def clear(path, headers):
            with open(path, "w", newline="", encoding="utf-8-sig") as f:
                csv.DictWriter(f, fieldnames=headers).writeheader()
        if os.path.exists(MODEL_DIR): shutil.rmtree(MODEL_DIR)
        os.makedirs(MODEL_DIR, exist_ok=True)
        clear(PREDICTION_LOG, ["symbol", "strategy", "direction", "price", "target", "timestamp", "confidence", "model", "success", "reason", "status"])
        clear(WRONG_PREDICTIONS, ["symbol", "strategy", "reason", "timestamp"])
        clear(LOG_FILE, ["timestamp", "symbol", "strategy", "model", "accuracy", "f1", "loss"])
        clear(AUDIT_LOG, ["timestamp", "symbol", "strategy", "result", "status"])
        clear(MESSAGE_LOG, ["timestamp", "symbol", "strategy", "message"])
        clear(FAILURE_COUNT_LOG, ["symbol", "strategy", "failures"])
        return "âœ… ì´ˆê¸°í™” ì™„ë£Œ (í—¤ë” í¬í•¨)"
    except Exception as e:
        return f"ì‚­ì œ ì‹¤íŒ¨: {e}", 500

@app.route("/audit-log")
def audit_log():
    try:
        if not os.path.exists(AUDIT_LOG): return jsonify({"error": "audit log not found"})
        df = pd.read_csv(AUDIT_LOG, encoding="utf-8-sig")
        return jsonify(df.tail(30).to_dict(orient="records"))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/audit-log-download")
def audit_log_download():
    try:
        if not os.path.exists(AUDIT_LOG): return "í‰ê°€ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.", 404
        return send_file(AUDIT_LOG, mimetype="text/csv", as_attachment=True, download_name="evaluation_audit.csv")
    except Exception as e:
        return f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}", 500

@app.route("/health-check")
def health_check():
    results, summary = [], []
    try:
        if os.path.exists(PREDICTION_LOG):
            df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig")
            total, done = len(df), len(df[df["status"].isin(["success", "fail"])])
            results.append(f"âœ… ì˜ˆì¸¡ ê¸°ë¡ OK ({total}ê±´)")
            summary.append(f"- í‰ê°€ ì™„ë£Œìœ¨: {(done/total*100):.1f}%" if total else "- í‰ê°€ ì—†ìŒ")
        else:
            results.append("âŒ ì˜ˆì¸¡ ê¸°ë¡ ì—†ìŒ")
    except Exception as e:
        results.append(f"âŒ ì˜ˆì¸¡ í™•ì¸ ì‹¤íŒ¨: {e}")

    try:
        models = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pt")]
        results.append(f"âœ… ëª¨ë¸ íŒŒì¼ OK ({len(models)}ê°œ)" if models else "âŒ ëª¨ë¸ ì—†ìŒ")
    except Exception as e:
        results.append(f"âŒ ëª¨ë¸ í™•ì¸ ì‹¤íŒ¨: {e}")

    try:
        if os.path.exists(MESSAGE_LOG):
            df = pd.read_csv(MESSAGE_LOG, encoding="utf-8-sig")
            results.append(f"âœ… ë©”ì‹œì§€ ë¡œê·¸ OK ({len(df)}ê±´)")
    except Exception as e:
        results.append(f"âŒ ë©”ì‹œì§€ í™•ì¸ ì‹¤íŒ¨: {e}")

    return f"<div style='font-family:monospace; line-height:1.6;'>" + "<br>".join(results + [""] + summary) + "</div>"

if __name__ == "__main__":
    print(">>> __main__ ì§„ì…, ì„œë²„ ì‹¤í–‰ ì¤€ë¹„"); sys.stdout.flush()
    start_scheduler()
    start_regular_prediction_loop()
    send_message("[ì‹œìŠ¤í…œ ì‹œì‘] YOPO ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. ì „ëµë³„ ì˜ˆì¸¡ì€ ì£¼ê¸°ì ìœ¼ë¡œ ìë™ ì‘ë™í•©ë‹ˆë‹¤.")
    print("âœ… ì„œë²„ ì´ˆê¸°í™” ì™„ë£Œ (ì •ê¸° ì˜ˆì¸¡ ë£¨í”„ í¬í•¨)")
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))
