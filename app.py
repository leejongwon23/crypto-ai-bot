# === app.py (FINAL with /diag/e2e HTML ì§€ì›) ===
from flask import Flask, jsonify, request
from recommend import main
import train, os, threading, datetime, pandas as pd, pytz, traceback, sys, shutil, csv, re
from apscheduler.schedulers.background import BackgroundScheduler
from telegram_bot import send_message
from predict_test import test_all_predictions
from predict_trigger import run as trigger_run
from data.utils import SYMBOLS, get_kline_by_strategy
from visualization import generate_visual_report, generate_visuals_for_strategy
from wrong_data_loader import load_training_prediction_data
from predict import evaluate_predictions
from train import train_symbol_group_loop
import maintenance_fix_meta
from logger import ensure_prediction_log_exists
from integrity_guard import run as _integrity_check; _integrity_check()

# âœ… [ADD] ì¢…í•©ì ê²€ ëª¨ë“ˆ
from diag_e2e import run as diag_e2e_run

# âœ… cleanup ëª¨ë“ˆ ê²½ë¡œ ë³´ì • (src/ì—ì„œ ì‹¤í–‰í•˜ë“ , ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•˜ë“  ë™ì‘)
try:
    from scheduler_cleanup import start_cleanup_scheduler   # [KEEP]
    import safe_cleanup                                      # [KEEP]
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from scheduler_cleanup import start_cleanup_scheduler    # [KEEP]
    import safe_cleanup                                      # [KEEP]

# âœ… ì„œë²„ ì‹œì‘ ì§ì „ ìš©ëŸ‰ ì •ë¦¬ (ì˜ˆì™¸ ê°€ë“œ)
try:
    safe_cleanup.cleanup_logs_and_models()
except Exception as e:
    print(f"[ê²½ê³ ] startup cleanup ì‹¤íŒ¨: {e}")

# ===== ê²½ë¡œ í†µì¼ =====
PERSIST_DIR = "/persistent"
LOG_DIR = os.path.join(PERSIST_DIR, "logs")
MODEL_DIR = os.path.join(PERSIST_DIR, "models")
os.makedirs(LOG_DIR, exist_ok=True)

# âœ… prediction_logì€ loggerì™€ ë™ì¼í•œ ìœ„ì¹˜/í—¤ë”ë¡œ ê´€ë¦¬ (logs/ì•„ë‹˜!)
PREDICTION_LOG = os.path.join(PERSIST_DIR, "prediction_log.csv")

LOG_FILE         = os.path.join(LOG_DIR, "train_log.csv")
WRONG_PREDICTIONS= os.path.join(PERSIST_DIR, "wrong_predictions.csv")
AUDIT_LOG        = os.path.join(LOG_DIR, "evaluation_audit.csv")
MESSAGE_LOG      = os.path.join(LOG_DIR, "message_log.csv")
FAILURE_LOG      = os.path.join(LOG_DIR, "failure_count.csv")

# âœ… ë¡œê·¸ íŒŒì¼ ì¡´ì¬ ë³´ì¥(ì •í™• í—¤ë”)
ensure_prediction_log_exists()

now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

# -----------------------------
# ìŠ¤ì¼€ì¤„ëŸ¬ (í‰ê°€/íŠ¸ë¦¬ê±°/ë©”íƒ€ë³µêµ¬)
# -----------------------------
_sched = None
def start_scheduler():
    global _sched
    if _sched is not None:
        print("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë¯¸ ì‹¤í–‰ ì¤‘, ì¬ì‹œì‘ ìƒëµ"); sys.stdout.flush()
        return

    print(">>> ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"); sys.stdout.flush()
    sched = BackgroundScheduler(timezone=pytz.timezone("Asia/Seoul"))

    # âœ… ì „ëµë³„ í‰ê°€(30ë¶„ë§ˆë‹¤)
    def í‰ê°€ì‘ì—…(strategy):
        def wrapped():
            try:
                ts = now_kst().strftime("%Y-%m-%d %H:%M:%S")
                print(f"[EVAL][{ts}] ì „ëµ={strategy} ì‹œì‘"); sys.stdout.flush()
                evaluate_predictions(lambda sym, _: get_kline_by_strategy(sym, strategy))
            except Exception as e:
                print(f"[EVAL] {strategy} ì‹¤íŒ¨: {e}")
        threading.Thread(target=wrapped, daemon=True).start()

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        sched.add_job(lambda s=strat: í‰ê°€ì‘ì—…(s), trigger="interval", minutes=30, id=f"eval_{strat}", replace_existing=True)

    # âœ… ì˜ˆì¸¡ íŠ¸ë¦¬ê±°(ë©”íƒ€ì ìš© í¬í•¨) 30ë¶„
    sched.add_job(trigger_run, "interval", minutes=30, id="predict_trigger", replace_existing=True)

    # âœ… ë©”íƒ€ JSON ì •í•©ì„±/ë³µêµ¬ ì£¼ê¸°ì‘ì—… (30ë¶„)  â† [ADD]
    def meta_fix_job():
        try:
            maintenance_fix_meta.fix_all_meta_json()
        except Exception as e:
            print(f"[META-FIX] ì£¼ê¸°ì‘ì—… ì‹¤íŒ¨: {e}")
    sched.add_job(meta_fix_job, "interval", minutes=30, id="meta_fix", replace_existing=True)

    sched.start()
    _sched = sched
    print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ"); sys.stdout.flush()

# ===== Flask =====
app = Flask(__name__)
print(">>> Flask ì•± ìƒì„± ì™„ë£Œ"); sys.stdout.flush()

# -----------------------------
# ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™”(í•œ ë²ˆë§Œ)
# -----------------------------
_INIT_DONE = False
_INIT_LOCK = threading.Lock()

def _init_background_once():
    global _INIT_DONE
    with _INIT_LOCK:
        if _INIT_DONE:
            return
        try:
            from failure_db import ensure_failure_db
            print(">>> ì„œë²„ ì‹¤í–‰ ì¤€ë¹„")
            ensure_failure_db(); print("âœ… failure_patterns DB ì´ˆê¸°í™” ì™„ë£Œ")

            # í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ
            threading.Thread(target=train_symbol_group_loop, daemon=True).start()
            print("âœ… í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ ì‹œì‘")

            # ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬(ê¸°ë³¸ 30ë¶„)
            start_cleanup_scheduler()
            print("âœ… cleanup ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

            # í‰ê°€/íŠ¸ë¦¬ê±°/ë©”íƒ€ë³µêµ¬ ìŠ¤ì¼€ì¤„ëŸ¬
            try:
                start_scheduler()
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")

            # ë©”íƒ€ ë³´ì •(ë¶€íŒ… ì‹œ 1íšŒ ì„  ì‹¤í–‰)
            threading.Thread(target=maintenance_fix_meta.fix_all_meta_json, daemon=True).start()
            print("âœ… maintenance_fix_meta ì´ˆê¸° ì‹¤í–‰ íŠ¸ë¦¬ê±°")

            # í…”ë ˆê·¸ë¨ ì•Œë¦¼
            try:
                send_message("[ì‹œì‘] YOPO ì„œë²„ ì‹¤í–‰ë¨")
                print("âœ… Telegram ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Telegram ë°œì†¡ ì‹¤íŒ¨: {e}")

            _INIT_DONE = True
            print("âœ… ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# Flask 3.1: before_first_request ì œê±° â†’ before_serving ì‚¬ìš©, ë¯¸ì§€ì› í™˜ê²½ì€ before_request 1íšŒ ì‹¤í–‰
if hasattr(app, "before_serving"):
    @app.before_serving
    def _boot_once():
        _init_background_once()
else:
    @app.before_request
    def _boot_once_compat():
        if not _INIT_DONE:
            _init_background_once()

# ===== ë¼ìš°íŠ¸ =====
@app.route("/yopo-health")
def yopo_health():
    percent = lambda v: f"{v:.1f}%" if pd.notna(v) else "0.0%"
    logs, strategy_html, problems = {}, [], []

    file_map = {"pred": PREDICTION_LOG, "train": LOG_FILE, "audit": AUDIT_LOG, "msg": MESSAGE_LOG}
    for name, path in file_map.items():
        try:
            logs[name] = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
            if "timestamp" in logs[name]:
                logs[name] = logs[name][logs[name]["timestamp"].notna()]
        except Exception:
            logs[name] = pd.DataFrame()

    # ëª¨ë¸ íŒŒì¼ íŒŒì‹± (ì ‘ë¯¸ì‚¬ í—ˆìš© ì •ê·œì‹)
    try:
        model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pt")]
    except Exception:
        model_files = []
    model_info = {}
    for f in model_files:
        m = re.match(r"(.+?)_(ë‹¨ê¸°|ì¤‘ê¸°|ì¥ê¸°)_(lstm|cnn_lstm|transformer)(?:_.*)?\.pt$", f)
        if m:
            symbol, strat, mtype = m.groups()
            model_info.setdefault(strat, {}).setdefault(symbol, set()).add(mtype)

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        try:
            pred  = logs.get("pred",  pd.DataFrame())
            train = logs.get("train", pd.DataFrame())
            audit = logs.get("audit", pd.DataFrame())
            pred  = pred.query(f"strategy == '{strat}'")  if not pred.empty  else pd.DataFrame()
            train = train.query(f"strategy == '{strat}'") if not train.empty else pd.DataFrame()
            audit = audit.query(f"strategy == '{strat}'") if not audit.empty else pd.DataFrame()

            if not pred.empty and "status" in pred.columns:
                pred["volatility"] = pred["status"].astype(str).str.startswith("v_")
            else:
                pred["volatility"] = False

            # return or rate
            try:
                pred["return"] = pd.to_numeric(pred.get("return", pd.Series(dtype=float)), errors="coerce").fillna(0.0)
            except Exception:
                pred["return"] = 0.0

            nvol = pred[~pred["volatility"]] if not pred.empty else pd.DataFrame()
            vol  = pred[ pred["volatility"]] if not pred.empty else pd.DataFrame()

            stat = lambda df, s: int(((not df.empty) and ("status" in df.columns)) and (df["status"]==s).sum()) or 0
            sn, fn, pn_, fnl = map(lambda s: stat(nvol, s), ["success", "fail", "pending", "failed"])
            sv, fv, pv, fvl = map(lambda s: stat(vol,  s), ["v_success", "v_fail", "pending", "failed"])

            def perf(df, kind="ì¼ë°˜"):
                try:
                    s = stat(df, "v_success" if kind == "ë³€ë™ì„±" else "success")
                    f = stat(df, "v_fail"    if kind == "ë³€ë™ì„±" else "fail")
                    t = s + f
                    avg = float(df["return"].mean()) if ("return" in df) and (df.shape[0]>0) else 0.0
                    return {"succ": s, "fail": f, "succ_rate": s/t*100 if t else 0,
                            "fail_rate": f/t*100 if t else 0, "r_avg": avg, "total": t}
                except Exception:
                    return {"succ": 0, "fail": 0, "succ_rate": 0, "fail_rate": 0, "r_avg": 0, "total": 0}

            pn, pv_stats = perf(nvol, "ì¼ë°˜"), perf(vol, "ë³€ë™ì„±")

            strat_models = model_info.get(strat, {})
            types = {"lstm": 0, "cnn_lstm": 0, "transformer": 0}
            for mtypes in strat_models.values():
                for t in mtypes: types[t] += 1
            trained_syms = [s for s, t in strat_models.items() if {"lstm","cnn_lstm","transformer"}.issubset(t)]
            try:
                untrained = sorted(set(SYMBOLS) - set(trained_syms))
            except Exception:
                untrained = []

            if sum(types.values()) == 0: problems.append(f"{strat}: ëª¨ë¸ ì—†ìŒ")
            if sn + fn + pn_ + fnl + sv + fv + pv + fvl == 0: problems.append(f"{strat}: ì˜ˆì¸¡ ì—†ìŒ")
            if pn["total"] == 0: problems.append(f"{strat}: í‰ê°€ ë¯¸ì‘ë™")
            if pn["fail_rate"]  > 50: problems.append(f"{strat}: ì¼ë°˜ ì‹¤íŒ¨ìœ¨ {pn['fail_rate']:.1f}%")
            if pv_stats["fail_rate"] > 50: problems.append(f"{strat}: ë³€ë™ì„± ì‹¤íŒ¨ìœ¨ {pv_stats['fail_rate']:.1f}%")

            table = "<i style='color:gray'>ìµœê·¼ ì˜ˆì¸¡ ì—†ìŒ ë˜ëŠ” ì»¬ëŸ¼ ë¶€ì¡±</i>"
            required_cols = {"timestamp","symbol","direction","return","status"}
            if (pred.shape[0] > 0) and required_cols.issubset(set(pred.columns)):
                recent10 = pred.sort_values("timestamp").tail(10).copy()
                rows = []
                for _, r in recent10.iterrows():
                    rtn = r.get("return", 0.0) or r.get("rate", 0.0)
                    try: rtn_pct = f"{float(rtn) * 100:.2f}%"
                    except: rtn_pct = "0.00%"
                    s = str(r.get('status',''))
                    status_icon = 'âœ…' if s in ['success','v_success'] else 'âŒ' if s in ['fail','v_fail'] else 'â³' if s in ['pending','v_pending'] else 'ğŸ›‘'
                    rows.append(f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('direction','')}</td><td>{rtn_pct}</td><td>{status_icon}</td></tr>")
                table = "<table border='1' style='margin-top:4px'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ë°©í–¥</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th></tr>" + "".join(rows) + "</table>"

            last_train = train['timestamp'].iloc[-1] if (not train.empty and 'timestamp' in train) else 'ì—†ìŒ'
            last_pred  = pred['timestamp'].iloc[-1]  if (not pred.empty and 'timestamp' in pred)  else 'ì—†ìŒ'
            last_audit = audit['timestamp'].iloc[-1] if (not audit.empty and 'timestamp' in audit) else 'ì—†ìŒ'

            info_html = f"""<div style='border:1px solid #aaa;margin:16px 0;padding:10px;font-family:monospace;background:#f8f8f8;'>
<b style='font-size:16px;'>ğŸ“Œ ì „ëµ: {strat}</b><br>
- ëª¨ë¸ ìˆ˜: {sum(types.values())} (lstm={types['lstm']}, cnn={types['cnn_lstm']}, trans={types['transformer']})<br>
- ì‹¬ë³¼ ìˆ˜: {len(SYMBOLS)} | ì™„ì „í•™ìŠµ: {len(trained_syms)} | ë¯¸ì™„ì„±: {len(untrained)}<br>
- ìµœê·¼ í•™ìŠµ: {last_train}<br>
- ìµœê·¼ ì˜ˆì¸¡: {last_pred}<br>
- ìµœê·¼ í‰ê°€: {last_audit}<br>
- ì˜ˆì¸¡ (ì¼ë°˜): {sn + fn + pn_ + fnl}ê±´ (âœ…{sn} âŒ{fn} â³{pn_} ğŸ›‘{fnl})<br>
- ì˜ˆì¸¡ (ë³€ë™ì„±): {sv + fv + pv + fvl}ê±´ (âœ…{sv} âŒ{fv} â³{pv} ğŸ›‘{fvl})<br>
<b style='color:#000088'>ğŸ¯ ì¼ë°˜ ì˜ˆì¸¡</b>: {pn['total']}ê±´ | {percent(pn['succ_rate'])} / {percent(pn['fail_rate'])} / {pn['r_avg']:.2f}%<br>
<b style='color:#880000'>ğŸŒªï¸ ë³€ë™ì„± ì˜ˆì¸¡</b>: {pv_stats['total']}ê±´ | {percent(pv_stats['succ_rate'])} / {percent(pv_stats['fail_rate'])} / {pv_stats['r_avg']:.2f}%<br>
<b>ğŸ“‹ ìµœê·¼ ì˜ˆì¸¡ 10ê±´</b><br>{table}
</div>"""

            try:
                visual = generate_visuals_for_strategy(strat)
            except Exception as e:
                visual = f"<div style='color:red'>[ì‹œê°í™” ì‹¤íŒ¨: {e}]</div>"

            strategy_html.append(f"<div style='margin-bottom:30px'>{info_html}<div style='margin:20px 0'>{visual}</div><hr></div>")
        except Exception as e:
            strategy_html.append(f"<div style='color:red;'>âŒ {strat} ì‹¤íŒ¨: {type(e).__name__} â†’ {e}</div>")

    status = "ğŸŸ¢ ì „ì²´ ì „ëµ ì •ìƒ ì‘ë™ ì¤‘" if not problems else "ğŸ”´ ì¢…í•©ì§„ë‹¨ ìš”ì•½:<br>" + "<br>".join(problems)
    return f"<div style='font-family:monospace;line-height:1.6;font-size:15px;'><b>{status}</b><hr>" + "".join(strategy_html) + "</div>"

@app.route("/")
def index(): return "Yopo server is running"

@app.route("/ping")
def ping(): return "pong"

# âœ… [MOD] ì¢…í•© ì ê²€ ë¼ìš°íŠ¸: view=html ì§€ì› (ì™„ì „ í•œê¸€ ë¦¬í¬íŠ¸)
@app.route("/diag/e2e")
def diag_e2e():
    """
    ì‚¬ìš©ë²•:
      /diag/e2e                                     â†’ ì „ì²´ ê·¸ë£¹ í•™ìŠµë£¨í”„ + í‰ê°€ (JSON)
      /diag/e2e?group=0                             â†’ ê·¸ë£¹#0ë§Œ í•™ìŠµ(+ì˜ˆì¸¡)+í‰ê°€ (JSON)
      /diag/e2e?group=1&predict=0&evaluate=0        â†’ ê·¸ë£¹#1 í•™ìŠµë§Œ (JSON)
      /diag/e2e?view=html                           â†’ ì „ì²´ ê·¸ë£¹ (í•œê¸€ HTML ë¦¬í¬íŠ¸)
      /diag/e2e?group=0&predict=1&evaluate=1&view=html â†’ ê·¸ë£¹#0 (í•œê¸€ HTML ë¦¬í¬íŠ¸)
    """
    try:
        group = request.args.get("group", "-1")
        do_predict = request.args.get("predict", "1") != "0"
        do_evaluate = request.args.get("evaluate", "1") != "0"
        view = request.args.get("view", "json")

        if view == "html":
            html = diag_e2e_run(group=int(group), do_predict=do_predict, do_evaluate=do_evaluate, view="html")
            return html  # text/html
        else:
            report = diag_e2e_run(group=int(group), do_predict=do_predict, do_evaluate=do_evaluate, view="json")
            return jsonify(report)
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/run")
def run():
    try:
        print("[RUN] ì „ëµë³„ ì˜ˆì¸¡ ì‹¤í–‰"); sys.stdout.flush()
        for strategy in ["ë‹¨ê¸°","ì¤‘ê¸°","ì¥ê¸°"]:
            main(strategy, force=True)
        return "Recommendation started"
    except Exception as e:
        traceback.print_exc(); return f"Error: {e}", 500

@app.route("/train-now")
def train_now():
    try:
        train.train_all_models()
        return "âœ… ëª¨ë“  ì „ëµ í•™ìŠµ ì‹œì‘ë¨"
    except Exception as e:
        return f"í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/train-log")
def train_log():
    try:
        if not os.path.exists(LOG_FILE): return "í•™ìŠµ ë¡œê·¸ ì—†ìŒ"
        df = pd.read_csv(LOG_FILE, encoding="utf-8-sig", on_bad_lines="skip")
        if df.empty or df.shape[1] == 0: return "í•™ìŠµ ê¸°ë¡ ì—†ìŒ"
        return "<pre>" + df.to_csv(index=False) + "</pre>"
    except Exception as e:
        return f"ì½ê¸° ì˜¤ë¥˜: {e}", 500

@app.route("/models")
def list_models():
    try:
        if not os.path.exists(MODEL_DIR): return "models í´ë” ì—†ìŒ"
        files = os.listdir(MODEL_DIR)
        return "<pre>" + "\n".join(files) + "</pre>" if files else "models í´ë” ë¹„ì–´ ìˆìŒ"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 500

@app.route("/check-log-full")
def check_log_full():
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)
        return jsonify(latest.to_dict(orient="records"))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-log")
def check_log():
    try:
        if not os.path.exists(PREDICTION_LOG):
            return jsonify({"error": "prediction_log.csv ì—†ìŒ"})
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        if "timestamp" not in df:
            return jsonify([])
        df = df[df["timestamp"].notna()]
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-eval-log")
def check_eval_log():
    try:
        path = PREDICTION_LOG
        if not os.path.exists(path): return "ì˜ˆì¸¡ ë¡œê·¸ ì—†ìŒ"

        df = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
        if "status" not in df.columns: return "ìƒíƒœ ì»¬ëŸ¼ ì—†ìŒ"

        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)

        def status_icon(s):
            return {"success":"âœ…","fail":"âŒ","v_success":"âœ…","v_fail":"âŒ","pending":"â³","v_pending":"â³"}.get(s,"â“")

        html = "<table border='1'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ì „ëµ</th><th>ëª¨ë¸</th><th>ì˜ˆì¸¡</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th><th>ì‚¬ìœ </th></tr>"
        for _, r in latest.iterrows():
            icon = status_icon(r.get("status",""))
            html += f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('strategy','')}</td><td>{r.get('model','')}</td><td>{r.get('direction','')}</td><td>{float(r.get('return',0) or 0):.4f}</td><td>{icon}</td><td>{r.get('reason','')}</td></tr>"
        html += "</table>"
        return html
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜: {e}", 500

from data.utils import SYMBOL_GROUPS

@app.route("/train-symbols")
def train_symbols():
    try:
        group_idx = int(request.args.get("group", -1))
        if group_idx < 0 or group_idx >= len(SYMBOL_GROUPS):
            return f"âŒ ì˜ëª»ëœ ê·¸ë£¹ ë²ˆí˜¸: {group_idx}", 400
        group_symbols = SYMBOL_GROUPS[group_idx]
        print(f"ğŸš€ ê·¸ë£¹ í•™ìŠµ ìš”ì²­ë¨ â†’ ê·¸ë£¹ #{group_idx} | ì‹¬ë³¼: {group_symbols}")
        threading.Thread(target=lambda: train.train_models(group_symbols), daemon=True).start()
        return f"âœ… ê·¸ë£¹ #{group_idx} í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘ë¨"
    except Exception as e:
        traceback.print_exc(); return f"âŒ ì˜¤ë¥˜: {e}", 500

@app.route("/train-symbols", methods=["POST"])
def train_selected_symbols():
    try:
        symbols = request.json.get("symbols", [])
        if not isinstance(symbols, list) or not symbols:
            return "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ symbols ë¦¬ìŠ¤íŠ¸", 400
        train.train_models(symbols)
        return f"âœ… {len(symbols)}ê°œ ì‹¬ë³¼ í•™ìŠµ ì‹œì‘ë¨"
    except Exception as e:
        return f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/meta-fix-now")  # â† [ADD] í•„ìš” ì‹œ ì¦‰ì‹œ ë©”íƒ€ ë³µêµ¬
def meta_fix_now():
    try:
        maintenance_fix_meta.fix_all_meta_json()
        return "âœ… meta.json ì ê²€/ë³µêµ¬ ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì‹¤íŒ¨: {e}", 500

@app.route("/reset-all")
def reset_all():
    if request.args.get("key") != "3572":
        return "âŒ ì¸ì¦ ì‹¤íŒ¨", 403
    try:
        from data.utils import _kline_cache, _feature_cache
        def clear_csv(f, h):
            os.makedirs(os.path.dirname(f), exist_ok=True)
            with open(f, "w", newline="", encoding="utf-8-sig") as wf:
                wf.write(",".join(h) + "\n")

        done_path = os.path.join(PERSIST_DIR, "train_done.json")
        if os.path.exists(done_path): os.remove(done_path)

        if os.path.exists(MODEL_DIR): shutil.rmtree(MODEL_DIR)
        os.makedirs(MODEL_DIR, exist_ok=True)

        if os.path.exists(LOG_DIR): shutil.rmtree(LOG_DIR)
        os.makedirs(LOG_DIR, exist_ok=True)

        _kline_cache.clear(); _feature_cache.clear()

        ensure_prediction_log_exists()
        clear_csv(WRONG_PREDICTIONS, ["timestamp","symbol","strategy","direction","entry_price","target_price","model","predicted_class","top_k","note","success","reason","rate","return_value","label","group_id","model_symbol","model_name","source","volatility","source_exchange"])
        clear_csv(LOG_FILE, ["timestamp","symbol","strategy","model","accuracy","f1","loss","note","source_exchange","status"])
        clear_csv(AUDIT_LOG, ["timestamp","symbol","strategy","result","status"])
        clear_csv(MESSAGE_LOG, ["timestamp","symbol","strategy","message"])
        clear_csv(FAILURE_LOG, ["symbol","strategy","failures"])
        return "âœ… ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", 500

@app.route("/force-fix-prediction-log")
def force_fix_prediction_log():
    """loggerì˜ í‘œì¤€ í—¤ë”ë¡œ prediction_log.csvë¥¼ ì•ˆì „í•˜ê²Œ ì¬ìƒì„±"""
    try:
        from logger import ensure_prediction_log_exists
        if os.path.exists(PREDICTION_LOG):
            os.remove(PREDICTION_LOG)
        ensure_prediction_log_exists()
        return "âœ… prediction_log.csv ê°•ì œ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜: {e}", 500

# ===== ë¡œì»¬ ê°œë°œ ì‹¤í–‰ìš© =====
if __name__ == "__main__":
    # ë¡œì»¬ì—ì„œ python app.pyë¡œ ëŒë¦´ ë•Œë§Œ ì„œë²„ ì‹¤í–‰
    try:
        port = int(os.environ.get("PORT", 5000))
    except ValueError:
        raise RuntimeError("âŒ Render í™˜ê²½ë³€ìˆ˜ PORTê°€ ì—†ìŠµë‹ˆë‹¤. Render ì„œë¹„ìŠ¤ íƒ€ì… í™•ì¸ í•„ìš”")

    # ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” í•œ ë²ˆ ì‹¤í–‰
    _init_background_once()

    print(f"âœ… Flask ì„œë²„ ì‹¤í–‰ ì‹œì‘ (PORT={port})")
    app.run(host="0.0.0.0", port=port)
