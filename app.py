# app.py â€” FINAL v2.2c (dirs auto-heal, PERSIST_DIR/PERSISTENT_DIR env)
# (trainâ†’predictâ†’next-group íŒŒì´í”„ë¼ì¸, ë¶€íŒ…ì‹œ í•„ìˆ˜ ê²½ë¡œ/ë¹ˆ ë¡œê·¸ ë³´ì¥, ì˜ˆì¸¡ë½ stale GC, ê·¸ë£¹í•™ìŠµ ë½/ê²Œì´íŠ¸)

from flask import Flask, jsonify, request, Response
from recommend import main
import train, os, threading, datetime, pytz, traceback, sys, shutil, re, time
import pandas as pd
from apscheduler.schedulers.background import BackgroundScheduler
from telegram_bot import send_message
from predict_trigger import run as trigger_run
from predict_trigger import _is_group_complete_for_all_strategies, _get_current_group_symbols
from data.utils import SYMBOLS, get_kline_by_strategy
from data.utils import (
    ready_for_group_predict, mark_group_predicted, group_all_complete,
    get_current_group_symbols, SYMBOL_GROUPS
)
from visualization import generate_visual_report, generate_visuals_for_strategy
from wrong_data_loader import load_training_prediction_data
from predict import evaluate_predictions
from train import train_symbol_group_loop  # compatibility
import maintenance_fix_meta
from logger import ensure_prediction_log_exists, ensure_train_log_exists, PREDICTION_HEADERS, TRAIN_HEADERS
from logger import log_audit_prediction as log_audit
from config import get_TRAIN_LOG_PATH

# === ê³µí†µ ê²½ë¡œ/ë””ë ‰í† ë¦¬ ===
# NOTE: Renderì—ì„œëŠ” /persistent ì“°ë©´ Permission deniedê°€ ëœ¨ë¯€ë¡œ ê¸°ë³¸ê°’ì„ /tmp/persistent ë¡œ ë‘”ë‹¤.
#       ë¡œì»¬/ìì²´ ì„œë²„ì—ì„œ ì˜ˆì „ì²˜ëŸ¼ /persistent ì“°ê³  ì‹¶ìœ¼ë©´
#       PERSIST_DIR=/persistent ë˜ëŠ” PERSISTENT_DIR=/persistent ë¡œ í™˜ê²½ë³€ìˆ˜ë§Œ ì£¼ë©´ ëœë‹¤.
PERSIST_DIR = (
    os.getenv("PERSIST_DIR")
    or os.getenv("PERSISTENT_DIR")
    or "/tmp/persistent"
)
LOG_DIR     = os.path.join(PERSIST_DIR, "logs")
MODEL_DIR   = os.path.join(PERSIST_DIR, "models")
RUN_DIR     = os.path.join(PERSIST_DIR, "run")

# --- âœ¨ í•„ìˆ˜ í´ë” ìë™ ìƒì„± ìœ í‹¸ (ë¶€íŒ…/ë¦¬ì…‹/ì¡°ê¸°QWIPE í›„ ì¬ì‚¬ìš©) ---
NEEDED_DIRS = [
    f"{PERSIST_DIR}/importances",
    f"{PERSIST_DIR}/guanwu/incoming",
    LOG_DIR,
    MODEL_DIR,
    RUN_DIR,
    "/tmp/importances",
]
def ensure_dirs():
    for p in NEEDED_DIRS:
        os.makedirs(p, exist_ok=True)

# ëª¨ë“ˆ ë¡œë“œ ì‹œ 1íšŒ ë³´ì¥
ensure_dirs()

# integrity guard optional
try:
    from integrity_guard import run as _integrity_check
    _integrity_check()
except Exception as e:
    print(f"[WARN] integrity_guard skipped: {e}")

from diag_e2e import run as diag_e2e_run

# cleanup modules
try:
    from scheduler_cleanup import start_cleanup_scheduler
    import safe_cleanup
    import scheduler_cleanup as _cleanup_mod
except Exception:
    try:
        sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
        from scheduler_cleanup import start_cleanup_scheduler
        import safe_cleanup
        import scheduler_cleanup as _cleanup_mod
    except Exception:
        start_cleanup_scheduler = lambda: None
        safe_cleanup = type("sc", (), {"get_directory_size_gb": lambda p: 0, "HARD_CAP_GB": 9.6, "run_emergency_purge": lambda: None, "cleanup_logs_and_models": lambda: None})
        _cleanup_mod = safe_cleanup

# predict-lock stale GC
try:
    import predict_lock as _pl
    _pl_clear = getattr(_pl, "clear_stale_predict_lock", lambda: None)
except Exception:
    _pl = None
    _pl_clear = lambda: None

# predict gate
try:
    from predict import open_predict_gate, close_predict_gate, predict
except Exception:
    def open_predict_gate(*args, **kwargs): return None
    def close_predict_gate(*args, **kwargs): return None
    def predict(*args, **kwargs): raise RuntimeError("predict ë¶ˆê°€")

def _safe_open_gate(note: str = ""):
    try:
        open_predict_gate(note=note)
        print(f"[gate] open ({note})"); sys.stdout.flush()
    except Exception as e:
        print(f"[gate] open err: {e}"); sys.stdout.flush()

def _safe_close_gate(note: str = ""):
    try:
        close_predict_gate(note=note)
        print(f"[gate] close ({note})"); sys.stdout.flush()
    except Exception as e:
        print(f"[gate] close err: {e}"); sys.stdout.flush()

# [ADD] ê·¸ë£¹ì ê¸ˆ ì „ìš© íŒŒì¼
GROUP_TRAIN_LOCK = os.path.join(RUN_DIR, "group_training.lock")

DEPLOY_ID  = os.getenv("RENDER_RELEASE_ID") or os.getenv("RENDER_GIT_COMMIT") or os.getenv("RENDER_SERVICE_ID") or "local"
BOOT_MARK  = os.path.join(PERSIST_DIR, f".boot_notice_{DEPLOY_ID}")

# locks
LOCK_DIR   = getattr(safe_cleanup, "LOCK_DIR", os.path.join(PERSIST_DIR, "locks"))
LOCK_PATH  = getattr(safe_cleanup, "LOCK_PATH", os.path.join(LOCK_DIR, "train_or_predict.lock"))
os.makedirs(LOCK_DIR, exist_ok=True)

# === GROUP_ACTIVE ë§ˆì»¤ ê²½ë¡œ ===
GROUP_ACTIVE_PATH = os.path.join(PERSIST_DIR, "GROUP_ACTIVE")

def _set_group_active(active: bool, group_idx: int | None = None, symbols: list | None = None):
    try:
        if active:
            with open(GROUP_ACTIVE_PATH, "w", encoding="utf-8") as f:
                ts = datetime.datetime.utcnow().isoformat()
                syms = ",".join(symbols or [])
                f.write(f"ts={ts}\n")
                if group_idx is not None:
                    f.write(f"group={group_idx}\n")
                f.write(f"symbols={syms}\n")
            print(f"[GROUP_ACTIVE] set group={group_idx} symbols={symbols}"); sys.stdout.flush()
        else:
            if os.path.exists(GROUP_ACTIVE_PATH):
                os.remove(GROUP_ACTIVE_PATH)
                print("[GROUP_ACTIVE] cleared"); sys.stdout.flush()
    except Exception as e:
        print(f"[GROUP_ACTIVE] set/clear err: {e}"); sys.stdout.flush()

def _is_group_active_file() -> bool:
    try:
        return os.path.exists(GROUP_ACTIVE_PATH)
    except Exception:
        return False

# BOOT: orphan ì „ì—­ë½ ì œê±° + ì˜ˆì¸¡ë½ stale GC + ê·¸ë£¹í•™ìŠµë½ ì œê±°
if os.path.exists(LOCK_PATH):
    try:
        os.remove(LOCK_PATH)
        print("[BOOT] orphan lock removed"); sys.stdout.flush()
    except Exception as e:
        print(f"[BOOT] lock remove failed: {e}"); sys.stdout.flush()
try:
    _pl_clear(); print("[BOOT] predict lock stale-GC done")
except Exception as e:
    print(f"[BOOT] predict lock GC failed: {e}")
try:
    if os.path.exists(GROUP_TRAIN_LOCK):
        os.remove(GROUP_TRAIN_LOCK)
        print("[BOOT] stale GROUP_TRAIN_LOCK removed"); sys.stdout.flush()
except Exception as e:
    print(f"[BOOT] GROUP_TRAIN_LOCK cleanup failed: {e}"); sys.stdout.flush()

def _acquire_global_lock():
    try:
        os.makedirs(LOCK_DIR, exist_ok=True)
        with open(LOCK_PATH, "w", encoding="utf-8") as f:
            f.write(f"locked at {datetime.datetime.now().isoformat()}\n")
        print(f"[LOCK] created: {LOCK_PATH}"); sys.stdout.flush()
        return True
    except Exception as e:
        print(f"[LOCK] create failed: {e}"); sys.stdout.flush()
        return False

def _release_global_lock():
    try:
        if os.path.exists(LOCK_PATH):
            os.remove(LOCK_PATH)
            print(f"[LOCK] removed: {LOCK_PATH}"); sys.stdout.flush()
            return True
    except Exception as e:
        print(f"[LOCK] remove failed: {e}"); sys.stdout.flush()
    return False

# ===== train API safe wrappers =====
def _is_training() -> bool:
    try:
        return bool(getattr(train, "is_loop_running", lambda: False)())
    except Exception:
        return False

def _start_train_loop_safe(force_restart=False, sleep_sec=0):
    fn = getattr(train, "start_train_loop", None)
    if callable(fn):
        try:
            return bool(fn(force_restart=force_restart, sleep_sec=sleep_sec))
        except Exception:
            try:
                fn(force_restart=force_restart, sleep_sec=sleep_sec)
                return True
            except Exception:
                return False
    for name in ("start_train_loop", "start_loop", "start"):
        fn2 = getattr(train, name, None)
        if callable(fn2):
            try:
                fn2()
                return True
            except Exception:
                continue
    return False

def _stop_train_loop_safe(timeout=30):
    fn = getattr(train, "stop_train_loop", None)
    if callable(fn):
        try:
            return bool(fn(timeout=timeout))
        except Exception:
            try:
                fn()
                return True
            except Exception:
                return False
    fn2 = getattr(train, "request_stop", None)
    if callable(fn2):
        try:
            fn2()
            return True
        except Exception:
            pass
    return False

def _request_stop_safe():
    fn = getattr(train, "request_stop", None)
    if callable(fn):
        try:
            fn()
            return True
        except Exception:
            return False
    return False

def _train_models_safe(symbols):
    fn = getattr(train, "train_models", None)
    if callable(fn):
        try:
            fn(symbols)
            return True
        except Exception as e:
            print(f"[TRAIN] train_models failed: {e}")
            return False
    fn2 = getattr(train, "train_symbol_group_loop", None)
    if callable(fn2):
        try:
            fn2(symbols)
            return True
        except Exception:
            return False
    return False

def _await_models_visible(symbols, timeout_sec=20, poll_sec=0.5):
    fn = getattr(train, "_await_models_visible", None)
    if callable(fn):
        try:
            return fn(symbols, timeout_sec=timeout_sec)
        except Exception:
            pass
    exts = (".pt", ".ptz", ".safetensors")
    deadline = time.time() + timeout_sec
    while time.time() < deadline:
        found = set()
        try:
            if os.path.isdir(MODEL_DIR):
                for f in os.listdir(MODEL_DIR):
                    for s in symbols:
                        if f.startswith(f"{s}_") and f.endswith(exts):
                            found.add(s)
                for s in symbols:
                    sdir = os.path.join(MODEL_DIR, s)
                    if os.path.isdir(sdir):
                        for strat in ("ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"):
                            d = os.path.join(sdir, strat)
                            if os.path.isdir(d):
                                if any(name.endswith(exts) for name in os.listdir(d)):
                                    found.add(s)
        except Exception:
            pass
        if found:
            return sorted(found)
        time.sleep(poll_sec)
    return []

def _has_model_for(symbol, strategy):
    fn = getattr(train, "_has_model_for", None)
    if callable(fn):
        try:
            return bool(fn(symbol, strategy))
        except Exception:
            pass
    try:
        exts = (".pt", ".ptz", ".safetensors")
        pref = f"{symbol}_{strategy}_"
        if os.path.isdir(MODEL_DIR):
            for f in os.listdir(MODEL_DIR):
                if f.startswith(pref) and f.endswith(exts):
                    return True
            d = os.path.join(MODEL_DIR, symbol, strategy)
            if os.path.isdir(d):
                if any(name.endswith(exts) for name in os.listdir(d)):
                    return True
    except Exception:
        pass
    return False

# quarantine wipe helper
def _quarantine_wipe_persistent():
    ts = datetime.datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    trash_dir = os.path.join(PERSIST_DIR, f"_trash_{ts}")
    os.makedirs(trash_dir, exist_ok=True)
    keep_names = {os.path.basename(LOCK_DIR)}
    moved = []
    for name in list(os.listdir(PERSIST_DIR)):
        if name in keep_names: continue
        src = os.path.join(PERSIST_DIR, name)
        dst = os.path.join(trash_dir, name)
        try:
            shutil.move(src, dst); moved.append(name)
        except Exception as e:
            print(f"âš ï¸ [QWIPE] move ì‹¤íŒ¨: {src} -> {dst} ({e})")
    # âœ… í•µì‹¬: ë°”ë¡œ ì¬ìƒì„±(í•™ìŠµ/íŠ¹ì§•ì¤‘ìš”ë„ ì €ì¥ ì¤‘ì—ë„ ë””ë ‰í„°ë¦¬ ì¡´ì¬ ë³´ì¥)
    ensure_dirs()
    print(f"ğŸ§¨ [QWIPE] moved_to_trash={moved} trash_dir={trash_dir}"); sys.stdout.flush()
    return trash_dir

def _async_emergency_purge():
    try:
        try:
            for name in list(os.listdir(PERSIST_DIR)):
                if name.startswith("_trash_"):
                    path = os.path.join(PERSIST_DIR, name)
                    shutil.rmtree(path, ignore_errors=True)
                    print(f"[BOOT-CLEANUP] trashed removed: {name}")
        except Exception as e:
            print(f"âš ï¸ [BOOT-CLEANUP] trash ì œê±° ì‹¤íŒ¨: {e}")
        used_gb = safe_cleanup.get_directory_size_gb(PERSIST_DIR)
        hard_cap = getattr(safe_cleanup, "HARD_CAP_GB", 9.6)
        print(f"[BOOT-CLEANUP] used={used_gb:.2f}GB hard_cap={hard_cap:.2f}GB"); sys.stdout.flush()
        if used_gb >= hard_cap:
            print("[EMERGENCY] pre-DB purge ì‹œì‘ (í•˜ë“œìº¡ ì´ˆê³¼)"); sys.stdout.flush()
            safe_cleanup.run_emergency_purge()
            print("[EMERGENCY] pre-DB purge ì™„ë£Œ"); sys.stdout.flush()
        else:
            if os.getenv("CLEANUP_ON_BOOT", "0") == "1":
                print("[BOOT-CLEANUP] CLEANUP_ON_BOOT=1 â†’ ì˜¨ê±´ ì •ë¦¬ ì‹¤í–‰"); sys.stdout.flush()
                safe_cleanup.cleanup_logs_and_models()
                print("[BOOT-CLEANUP] ì™„ë£Œ"); sys.stdout.flush()
            else:
                print("[BOOT-CLEANUP] ë¹„í™œì„±í™”(CLEANUP_ON_BOOT=0)"); sys.stdout.flush()
    except Exception as e:
        print(f"[ê²½ê³ ] pre-DB purge/cleanup ê²°ì • ì‹¤íŒ¨: {e}"); sys.stdout.flush()

threading.Thread(target=_async_emergency_purge, daemon=True).start()

PREDICTION_LOG = os.path.join(PERSIST_DIR, "prediction_log.csv")
LOG_FILE          = get_TRAIN_LOG_PATH()
WRONG_PREDICTIONS = os.path.join(PERSIST_DIR, "wrong_predictions.csv")
AUDIT_LOG         = os.path.join(LOG_DIR, "evaluation_audit.csv")
MESSAGE_LOG       = os.path.join(LOG_DIR, "message_log.csv")
FAILURE_LOG       = os.path.join(LOG_DIR, "failure_count.csv")

# ensure logs
try:
    ensure_train_log_exists()
except Exception:
    pass
ensure_prediction_log_exists()

now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

# ê·¸ë£¹ ì™„ì£¼ í›„ì—ë§Œ ì˜ˆì¸¡ í—ˆìš©
REQUIRE_GROUP_COMPLETE = int(os.getenv("REQUIRE_GROUP_COMPLETE", "1"))

# scheduler
_sched = None
def start_scheduler():
    global _sched
    if _sched is not None:
        print("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë¯¸ ì‹¤í–‰ ì¤‘, ì¬ì‹œì‘ ìƒëµ"); sys.stdout.flush()
        return
    if os.path.exists(LOCK_PATH):
        print("â¸ï¸ ë¦¬ì…‹ ë½ ê°ì§€ â†’ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì§€ì—°"); sys.stdout.flush()
        def _deferred():
            backoff = 1.0
            while os.path.exists(LOCK_PATH):
                time.sleep(backoff)
                backoff = min(backoff * 2.0, 60.0)
            try:
                start_scheduler(); print("â–¶ï¸ ì§€ì—° í›„ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"); sys.stdout.flush()
            except Exception as e:
                print(f"âŒ ì§€ì—° ì‹œì‘ ì‹¤íŒ¨: {e}")
        threading.Thread(target=_deferred, daemon=True).start()
        return

    try:
        _pl_clear(); print("[SCHED] predict lock stale-GC pre-start")
    except Exception as e:
        print(f"[SCHED] predict lock GC failed pre-start: {e}")

    print(">>> ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"); sys.stdout.flush()
    sched = BackgroundScheduler(
        timezone=pytz.timezone("Asia/Seoul"),
        job_defaults={"coalesce": True, "max_instances": 1, "misfire_grace_time": 90},
    )

    def í‰ê°€ì‘ì—…(strategy):
        def wrapped():
            try:
                if _is_training() or os.path.exists(LOCK_PATH) or _is_group_active_file() or os.path.exists(GROUP_TRAIN_LOCK):
                    print(f"[EVAL] skip: training/lock/group-active (strategy={strategy})"); sys.stdout.flush()
                    return
                ts = now_kst().strftime("%Y-%m-%d %H:%M:%S")
                print(f"[EVAL][{ts}] ì „ëµ={strategy} ì‹œì‘"); sys.stdout.flush()
                evaluate_predictions(lambda sym, _: get_kline_by_strategy(sym, strategy))
            except Exception as e:
                print(f"[EVAL] {strategy} ì‹¤íŒ¨: {e}")
        return wrapped

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        sched.add_job(
            í‰ê°€ì‘ì—…(strat),
            trigger="interval",
            minutes=30,
            id=f"eval_{strat}",
            replace_existing=True,
            coalesce=True,
            max_instances=1,
            misfire_grace_time=90,
        )

    def _pred_lock_gc():
        try:
            _pl_clear()
        except Exception as e:
            print(f"[LOCK] periodic GC fail: {e}")
    sched.add_job(
        _pred_lock_gc,
        "interval",
        minutes=int(os.getenv("PREDICT_LOCK_GC_MIN", "5")),
        id="predict_lock_gc",
        replace_existing=True,
        coalesce=True,
        max_instances=1,
        misfire_grace_time=90,
    )

    def _predict_job():
        try:
            if _is_training() or os.path.exists(LOCK_PATH) or _is_group_active_file() or os.path.exists(GROUP_TRAIN_LOCK):
                print("[PREDICT] skip: training/lock/group-active"); sys.stdout.flush()
                return
            _pl_clear()
            print("[PREDICT] trigger_run start"); sys.stdout.flush()
            _safe_open_gate("sched_trigger")
            try:
                trigger_run()
            except Exception as e:
                print(f"[PREDICT] âŒ trigger_run ì‹¤íŒ¨: {e}")
                try:
                    from predict import failed_result
                    failed_result("ALL", "auto", reason=str(e), source="sched_trigger")
                except Exception:
                    pass
            finally:
                _safe_close_gate("sched_trigger")
            print("[PREDICT] trigger_run done"); sys.stdout.flush()
        except Exception as e:
            print(f"[PREDICT] ì‹¤íŒ¨: {e}")

    sched.add_job(
        _predict_job,
        "interval",
        minutes=30,
        id="predict_trigger",
        replace_existing=True,
        coalesce=True,
        max_instances=1,
        misfire_grace_time=90,
    )

    def meta_fix_job():
        try:
            maintenance_fix_meta.fix_all_meta_json()
        except Exception as e:
            print(f"[META-FIX] ì£¼ê¸°ì‘ì—… ì‹¤íŒ¨: {e}")

    sched.add_job(
        meta_fix_job,
        "interval",
        minutes=30,
        id="meta_fix",
        replace_existing=True,
        coalesce=True,
        max_instances=1,
        misfire_grace_time=90,
    )

    sched.start()
    _sched = sched
    print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ"); sys.stdout.flush()

def _pause_and_clear_scheduler():
    global _sched
    try:
        if _sched is not None:
            print("[SCHED] pause + remove_all_jobs"); sys.stdout.flush()
            try: _sched.pause()
            except Exception: pass
            try: _sched.remove_all_jobs()
            except Exception: pass
            try: _sched.shutdown(wait=False)
            except Exception: pass
            _sched = None
    except Exception as e:
        print(f"[SCHED] ì •ì§€ ì‹¤íŒ¨: {e}"); sys.stdout.flush()

def _stop_all_aux_schedulers():
    try:
        _pause_and_clear_scheduler()
    except Exception:
        pass
    try:
        if hasattr(_cleanup_mod, "stop_cleanup_scheduler"):
            try:
                _cleanup_mod.stop_cleanup_scheduler()
                print("ğŸ§¹ [SCHED] cleanup ìŠ¤ì¼€ì¤„ëŸ¬ stop í˜¸ì¶œ"); sys.stdout.flush()
            except Exception as e:
                print(f"âš ï¸ cleanup stop ì‹¤íŒ¨: {e}"); sys.stdout.flush()
        for name in dir(_cleanup_mod):
            obj = getattr(_cleanup_mod, name, None)
            if isinstance(obj, BackgroundScheduler):
                try:
                    obj.shutdown(wait=False)
                    print(f"ğŸ§¹ [SCHED] cleanup.{name} shutdown"); sys.stdout.flush()
                except Exception:
                    pass
    except Exception as e:
        print(f"âš ï¸ cleanup ìŠ¤ì¼€ì¤„ëŸ¬ íƒì§€ ì‹¤íŒ¨: {e}"); sys.stdout.flush()

# Flask app
app = Flask(__name__)
print(">>> Flask ì•± ìƒì„± ì™„ë£Œ"); sys.stdout.flush()

# init once
_INIT_DONE = False
_INIT_LOCK = threading.Lock()

def _init_background_once():
    global _INIT_DONE
    with _INIT_LOCK:
        if _INIT_DONE:
            return
        try:
            if os.path.exists(LOCK_PATH):
                print("â¸ï¸ ë½ ê°ì§€ â†’ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì§€ì—°"); sys.stdout.flush()
                return
            from failure_db import ensure_failure_db
            print(">>> ì„œë²„ ì‹¤í–‰ ì¤€ë¹„")
            ensure_failure_db(); print("âœ… failure_patterns DB ì´ˆê¸°í™” ì™„ë£Œ")

            # í•„ìˆ˜ ê²½ë¡œ ë° ë¹ˆ ë¡œê·¸ ë³´ì¥(í´ë”ëŠ” ì´ë¯¸ ìƒì„±ë¨)
            try: ensure_train_log_exists()
            except Exception: pass
            try: ensure_prediction_log_exists()
            except Exception: pass

            _pl_clear()
            print("[pipeline] serialized: train -> predict -> next-group"); sys.stdout.flush()

            autostart = os.getenv("APP_AUTOSTART_TRAIN", "1") != "0"
            _safe_close_gate("init_train_start")
            if autostart:
                started = _start_train_loop_safe(force_restart=False, sleep_sec=0)
                print("âœ… í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ ì‹œì‘" if started else "âš ï¸ í•™ìŠµ ë£¨í”„ ì‹œì‘ ì‹¤íŒ¨ ë˜ëŠ” ì´ë¯¸ ì‹¤í–‰ ì¤‘")
            else:
                print("â¸ï¸ í•™ìŠµ ë£¨í”„ ìë™ ì‹œì‘ ì•ˆí•¨")

            start_cleanup_scheduler()
            print("âœ… cleanup ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")
            try:
                start_scheduler()
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")

            threading.Thread(target=maintenance_fix_meta.fix_all_meta_json, daemon=True).start()
            print("âœ… maintenance_fix_meta ì´ˆê¸° ì‹¤í–‰ íŠ¸ë¦¬ê±°")

            try:
                fd = os.open(BOOT_MARK, os.O_CREAT | os.O_EXCL | os.O_WRONLY)
                os.close(fd)
                send_message("[ì‹œì‘] YOPO ì„œë²„ ì‹¤í–‰ë¨")
                print("âœ… Telegram ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
            except FileExistsError:
                print("â„¹ï¸ ë¶€íŒ… ì•Œë¦¼ ìƒëµ")
            except Exception as e:
                print(f"âš ï¸ Telegram ë°œì†¡ ì‹¤íŒ¨: {e}")

            _INIT_DONE = True
            print("âœ… ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

if hasattr(app, "before_serving"):
    @app.before_serving
    def _boot_once():
        _init_background_once()
else:
    @app.before_request
    def _boot_once_compat():
        if not _INIT_DONE:
            _init_background_once()

# í•™ìŠµ ì§í›„ ì˜ˆì¸¡: ê·¸ë£¹ ì™„ì£¼ ê°€ë“œ
def _predict_after_training(symbols, source_note):
    if not symbols:
        return
    try:
        if REQUIRE_GROUP_COMPLETE == 1:
            group_syms = _get_current_group_symbols()
            if isinstance(group_syms, (list, tuple)) and len(group_syms) > 0:
                if not _is_group_complete_for_all_strategies(list(group_syms)):
                    print(f"[APP-PRED] ğŸš« ê·¸ë£¹ ë¯¸ì™„ë£Œ â†’ ì˜ˆì¸¡ ì°¨ë‹¨ ({source_note})"); sys.stdout.flush()
                    for sym in sorted(set(symbols)):
                        try: log_audit(sym, "ALL", "í•™ìŠµí›„ì˜ˆì¸¡ìŠ¤í‚µ", "ê·¸ë£¹ ë¯¸ì™„ë£Œ(REQUIRE_GROUP_COMPLETE=1)")
                        except Exception: pass
                    return
    except Exception as e:
        print(f"[APP-PRED] ê·¸ë£¹ì™„ë£Œê²€ì¦ ì‹¤íŒ¨: {e}")

    try:
        await_sec = int(os.getenv("PREDICT_MODEL_AWAIT_SEC","60"))
    except Exception:
        await_sec = 60
    vis = _await_models_visible(symbols, timeout_sec=await_sec)
    if not vis:
        print(f"[APP-PRED] ëª¨ë¸ ê°€ì‹œí™” ì‹¤íŒ¨ â†’ ì˜ˆì¸¡ ìƒëµ candidates={sorted(set(symbols))}")
        return
    if os.path.exists(LOCK_PATH):
        try:
            os.remove(LOCK_PATH)
            print("[APP-PRED] cleared stale lock before predict"); sys.stdout.flush()
        except Exception as e:
            print(f"[APP-PRED] lock remove failed: {e}"); sys.stdout.flush()
    _pl_clear()
    _safe_open_gate(source_note)
    try:
        for sym in sorted(set(vis)):
            for strat in ["ë‹¨ê¸°","ì¤‘ê¸°","ì¥ê¸°"]:
                try:
                    if not _has_model_for(sym, strat):
                        print(f"[APP-PRED] skip {sym}-{strat}: model missing")
                        continue
                    print(f"[APP-PRED] predict {sym}-{strat}")
                    try:
                        result = predict(sym, strat, source=source_note, model_type=None)
                        if not isinstance(result, dict):
                            print(f"[APP-PRED] âš ï¸ invalid return"); sys.stdout.flush()
                            try:
                                from predict import failed_result
                                failed_result(sym, strat, reason="invalid_return", source="app_predict")
                            except Exception: pass
                        else:
                            print(f"[APP-PRED] âœ… {sym}-{strat} ok: {result.get('reason','ok')}"); sys.stdout.flush()
                    except Exception as e:
                        print(f"[APP-PRED] âŒ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}"); sys.stdout.flush()
                        try:
                            from predict import failed_result
                            failed_result(sym, strat, reason=str(e), source="app_predict")
                        except Exception: pass
                except Exception as e:
                    print(f"[APP-PRED] {sym}-{strat} ì‹¤íŒ¨: {e}"); sys.stdout.flush()
    finally:
        _safe_close_gate(source_note + "_end")

# routes
@app.route("/")
def index(): return "Yopo server is running"

@app.route("/ping")
def ping(): return "pong"

@app.route("/admin/clear-predict-lock", methods=["POST","GET"])
def clear_predict_lock_admin():
    try:
        _pl_clear()
        return "âœ… predict lock stale-GC executed"
    except Exception as e:
        return f"âš ï¸ fail: {e}", 500

@app.route("/yopo-health")
def yopo_health():
    logs, strategy_html, problems = {}, [], []
    file_map = {"pred": PREDICTION_LOG, "train": LOG_FILE, "audit": AUDIT_LOG, "msg": MESSAGE_LOG}
    for name, path in file_map.items():
        try:
            logs[name] = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
            if "timestamp" in logs[name].columns:
                logs[name] = logs[name][logs[name]["timestamp"].notna()]
        except Exception:
            logs[name] = pd.DataFrame()
    try:
        model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith((".pt", ".ptz", ".safetensors"))]
    except Exception:
        model_files = []
    model_info = {}
    for f in model_files:
        m = re.match(r"(.+?)_(ë‹¨ê¸°|ì¤‘ê¸°|ì¥ê¸°)_(lstm|cnn_lstm|transformer)(?:_.*)?\.(pt|ptz|safetensors)$", f)
        if m:
            symbol, strat, mtype, _ext = m.groups()
            model_info.setdefault(strat, {}).setdefault(symbol, set()).add(mtype)
    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        try:
            pred  = logs.get("pred",  pd.DataFrame())
            train_log_df = logs.get("train", pd.DataFrame())
            audit = logs.get("audit", pd.DataFrame())
            pred  = pred.query(f"strategy == '{strat}'")  if not pred.empty  else pd.DataFrame()
            train_log_q = train_log_df.query(f"strategy == '{strat}'") if not train_log_df.empty else pd.DataFrame()
            audit = audit.query(f"strategy == '{strat}'") if not audit.empty else pd.DataFrame()
            if not pred.empty and "status" in pred.columns:
                pred["volatility"] = pred["status"].astype(str).str.startswith("v_")
            else:
                pred["volatility"] = False
            try:
                pred["return"] = pd.to_numeric(pred.get("return_value", pred.get("rate", pd.Series(dtype=float))), errors="coerce").fillna(0.0)
            except Exception:
                pred["return"] = 0.0
            nvol = pred[~pred["volatility"]] if not pred.empty else pd.DataFrame()
            vol  = pred[ pred["volatility"]] if not pred.empty else pd.DataFrame()
            def stat(df, s):
                try:
                    return int(((not df.empty) and ("status" in df.columns)) and (df["status"] == s).sum()) or 0
                except Exception:
                    return 0
            sn, fn, pn_, fnl = map(lambda s: stat(nvol, s), ["success", "fail", "pending", "failed"])
            sv, fv, pv, fvl = map(lambda s: stat(vol,  s), ["v_success", "v_fail", "pending", "failed"])
            def perf(df, kind="ì¼ë°˜"):
                try:
                    s = stat(df, "v_success" if kind == "ë³€ë™ì„±" else "success")
                    f = stat(df, "v_fail"    if kind == "ë³€ë™ì„±" else "fail")
                    t = s + f
                    avg = float(df["return"].mean()) if ("return" in df) and (df.shape[0] > 0) else 0.0
                    return {"succ": s, "fail": f, "succ_rate": s/t*100 if t else 0,
                            "fail_rate": f/t*100 if t else 0, "r_avg": avg, "total": t}
                except Exception:
                    return {"succ": 0, "fail": 0, "succ_rate": 0, "fail_rate": 0, "r_avg": 0, "total": 0}
            pn, pv_stats = perf(nvol, "ì¼ë°˜"), perf(vol, "ë³€ë™ì„±")
            strat_models = model_info.get(strat, {})
            types = {"lstm": 0, "cnn_lstm": 0, "transformer": 0}
            for mtypes in strat_models.values():
                for t in mtypes: types[t] += 1
            trained_syms = [s for s, t in strat_models.items() if {"lstm","cnn_lstm","transformer"}.issubset(t)]
            try:
                untrained = sorted(set(SYMBOLS) - set(trained_syms))
            except Exception:
                untrained = []
            if sum(types.values()) == 0: problems.append(f"{strat}: ëª¨ë¸ ì—†ìŒ")
            if sn + fn + pn_ + fnl + sv + fv + pv + fvl == 0: problems.append(f"{strat}: ì˜ˆì¸¡ ì—†ìŒ")
            if pn["total"] == 0: problems.append(f"{strat}: í‰ê°€ ë¯¸ì‘ë™")
            if pn["fail_rate"]  > 50: problems.append(f"{strat}: ì¼ë°˜ ì‹¤íŒ¨ìœ¨ {pn['fail_rate']:.1f}%")
            if pv_stats["fail_rate"] > 50: problems.append(f"{strat}: ë³€ë™ì„± ì‹¤íŒ¨ìœ¨ {pv_stats['fail_rate']:.1f}%")
            table = "<i style='color:gray'>ìµœê·¼ ì˜ˆì¸¡ ì—†ìŒ ë˜ëŠ” ì»¬ëŸ¼ ë¶€ì¡±</i>"
            required_cols = {"timestamp","symbol","strategy","direction","return","status"}
            if (pred.shape[0] > 0) and required_cols.issubset(set(pred.columns)):
                recent10 = pred.sort_values("timestamp").tail(10).copy()
                rows = []
                for _, r in recent10.iterrows():
                    rtn = r.get("return", 0.0) or r.get("rate", 0.0)
                    try: rtn_pct = f"{float(rtn) * 100:.2f}%"
                    except: rtn_pct = "0.00%"
                    s = str(r.get('status',''))
                    status_icon = 'âœ…' if s in ['success','v_success'] else 'âŒ' if s in ['fail','v_fail'] else 'â³' if s in ['pending','v_pending'] else 'ğŸ›‘'
                    rows.append(f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('direction','')}</td><td>{rtn_pct}</td><td>{status_icon}</td></tr>")
                table = "<table border='1' style='margin-top:4px'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ë°©í–¥</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th></tr>" + "".join(rows) + "</table>"
            last_train = train_log_q['timestamp'].iloc[-1] if (not train_log_q.empty and 'timestamp' in train_log_q) else 'ì—†ìŒ'
            last_pred  = pred['timestamp'].iloc[-1]  if (not pred.empty and 'timestamp' in pred)  else 'ì—†ìŒ'
            last_audit = audit['timestamp'].iloc[-1] if (not audit.empty and 'timestamp' in audit) else 'ì—†ìŒ'
            info_html = f"""<div style='border:1px solid #aaa;margin:16px 0;padding:10px;font-family:monospace;background:#f8f8f8;'>
<b style='font-size:16px;'>ğŸ“Œ ì „ëµ: {strat}</b><br>
- ëª¨ë¸ ìˆ˜: {sum(types.values())} (lstm={types['lstm']}, cnn={types['cnn_lstm']}, trans={types['transformer']})<br>
- ì‹¬ë³¼ ìˆ˜: {len(SYMBOLS)} | ì™„ì „í•™ìŠµ: {len(trained_syms)} | ë¯¸ì™„ì„±: {len(untrained)}<br>
- ìµœê·¼ í•™ìŠµ: {last_train}<br>
- ìµœê·¼ ì˜ˆì¸¡: {last_pred}<br>
- ìµœê·¼ í‰ê°€: {last_audit}<br>
- ì˜ˆì¸¡ (ì¼ë°˜): {sn + fn + pn_ + fnl}ê±´ (âœ…{sn} âŒ{fn} â³{pn_} ğŸ›‘{fnl})<br>
- ì˜ˆì¸¡ (ë³€ë™ì„±): {sv + fv + pv + fvl}ê±´ (âœ…{sv} âŒ{fv} â³{pv} ğŸ›‘{fvl})<br>
<b style='color:#000088'>ğŸ¯ ì¼ë°˜ ì˜ˆì¸¡</b>: {pn['total']}ê±´ | {pn['succ_rate']:.1f}% / {pn['fail_rate']:.1f}% / {pn['r_avg']:.2f}%<br>
<b style='color:#880000'>ğŸŒªï¸ ë³€ë™ì„± ì˜ˆì¸¡</b>: {pv_stats['total']}ê±´ | {pv_stats['succ_rate']:.1f}% / {pv_stats['fail_rate']:.1f}% / {pv_stats['r_avg']:.2f}%<br>
<b>ğŸ“‹ ìµœê·¼ ì˜ˆì¸¡ 10ê±´</b><br>{table}
</div>"""
            try:
                visual = generate_visuals_for_strategy(strat)
            except Exception as e:
                visual = f"<div style='color:red'>[ì‹œê°í™” ì‹¤íŒ¨: {e}]</div>"
            strategy_html.append(f"<div style='margin-bottom:30px'>{info_html}<div style='margin:20px 0'>{visual}</div><hr></div>")
        except Exception as e:
            strategy_html.append(f"<div style='color:red;'>âŒ {strat} ì‹¤íŒ¨: {type(e).__name__} â†’ {e}</div>")
    status = "ğŸŸ¢ ì „ì²´ ì „ëµ ì •ìƒ ì‘ë™ ì¤‘" if not problems else "ğŸ”´ ì¢…í•©ì§„ë‹¨ ìš”ì•½:<br>" + "<br>".join(problems)
    return f"<div style='font-family:monospace;line-height:1.6;font-size:15px;'><b>{status}</b><hr>" + "".join(strategy_html) + "</div>"

@app.route("/diag/e2e")
def diag_e2e():
    try:
        group = int(request.args.get("group", "-1"))
        # ğŸ”§ FIX: request.get â†’ request.args.get
        view = request.args.get("view", "json").lower()
        cumulative = request.args.get("cum", "0") == "1"
        symbols = request.args.get("symbols")
        out = diag_e2e_run(group=group, view=view, cumulative=cumulative, symbols=symbols)
        if isinstance(out, Response):
            return out
        if view == "html":
            return Response(out if isinstance(out, str) else str(out),
                            mimetype="text/html; charset=utf-8")
        return jsonify(out)
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/run")
def run():
    try:
        if os.path.exists(LOCK_PATH) or _is_training() or _is_group_active_file() or os.path.exists(GROUP_TRAIN_LOCK):
            return "â¸ï¸ í•™ìŠµ/ì´ˆê¸°í™”/ê·¸ë£¹í•™ìŠµ ì§„í–‰ ì¤‘: ì˜ˆì¸¡ ì‹œì‘ ì°¨ë‹¨ë¨", 423
        print("[RUN] ì „ëµë³„ ì˜ˆì¸¡ ì‹¤í–‰"); sys.stdout.flush()
        _pl_clear()
        _safe_open_gate("route_run")
        try:
            for strategy in ["ë‹¨ê¸°","ì¤‘ê¸°","ì¥ê¸°"]:
                main(strategy, force=True)
        finally:
            _safe_close_gate("route_run")
        return "Recommendation started"
    except Exception as e:
        traceback.print_exc(); return f"Error: {e}", 500

@app.route("/train-now")
def train_now():
    try:
        if os.path.exists(LOCK_PATH):
            return "â¸ï¸ ì´ˆê¸°í™” ì¤‘: í•™ìŠµ ì‹œì‘ ì°¨ë‹¨ë¨", 423
        force = request.args.get("force", "0") == "1"
        _safe_close_gate("train_now_start")
        started = _start_train_loop_safe(force_restart=force, sleep_sec=0)
        if started: return "âœ… ì „ì²´ ê·¸ë£¹ í•™ìŠµ ë£¨í”„ ì‹œì‘ë¨ (ë°±ê·¸ë¼ìš´ë“œ)"
        return "â³ ì´ë¯¸ ì‹¤í–‰ ì¤‘ (ì¬ê°€ë™ ìƒëµ)" if not force else "â³ ì¬ê°€ë™ ì‹œë„í–ˆìœ¼ë‚˜ ê¸°ì¡´ ë£¨í”„ ìœ ì§€ë¨"
    except Exception as e:
        return f"í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/train-log")
def train_log():
    try:
        log_path = get_TRAIN_LOG_PATH()
        if not os.path.exists(log_path):
            return f"í•™ìŠµ ë¡œê·¸ ì—†ìŒ<br><small>ê²½ë¡œ: <code>{log_path}</code></small>"
        df = pd.read_csv(log_path, encoding="utf-8-sig", on_bad_lines="skip")
        if df.empty or df.shape[1] == 0:
            return f"í•™ìŠµ ê¸°ë¡ ì—†ìŒ<br><small>ê²½ë¡œ: <code>{log_path}</code></small>"
        html = df.tail(200).to_html(index=False, border=1, justify='center')
        return f"<b>ğŸ“˜ í•™ìŠµ ë¡œê·¸ (ìµœê·¼ 200í–‰)</b><br><small>ê²½ë¡œ: <code>{log_path}</code></small><br><br>{html}"
    except Exception as e:
        return f"ì½ê¸° ì˜¤ë¥˜: {e}", 500

@app.route("/models")
def list_models():
    try:
        files = os.listdir(MODEL_DIR) if os.path.exists(MODEL_DIR) else []
        return "<pre>" + "\n".join(files) + "</pre>" if files else "models í´ë” ë¹„ì–´ ìˆìŒ"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 500

@app.route("/check-log-full")
def check_log_full():
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)
        return jsonify(latest.to_dict(orient="records"))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-log")
def check_log():
    try:
        if not os.path.exists(PREDICTION_LOG):
            return jsonify({"error": "prediction_log.csv ì—†ìŒ"})
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        if "timestamp" not in df:
            return jsonify([])
        df = df[df["timestamp"].notna()]
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-eval-log")
def check_eval_log():
    try:
        path = PREDICTION_LOG
        if not os.path.exists(path): return "ì˜ˆì¸¡ ë¡œê·¸ ì—†ìŒ"
        df = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
        if "status" not in df.columns: return "ìƒíƒœ ì»¬ëŸ¼ ì—†ìŒ"
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)
        def status_icon(s):
            return {"success":"âœ…","fail":"âŒ","v_success":"âœ…","v_fail":"âŒ","pending":"â³","v_pending":"â³"}.get(s,"â“")
        html = "<table border='1'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ì „ëµ</th><th>ëª¨ë¸</th><th>ì˜ˆì¸¡</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th><th>ì‚¬ìœ </th></tr>"
        for _, r in latest.iterrows():
            icon = status_icon(r.get("status",""))
            rv = r.get('return_value', None)
            if pd.isna(rv) or rv is None: rv = r.get('rate', 0)
            try: rv = float(rv)
            except Exception: rv = 0.0
            html += f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('strategy','')}</td><td>{r.get('model','')}</td><td>{r.get('direction','')}</td><td>{rv:.4f}</td><td>{icon}</td><td>{r.get('reason','')}</td></tr>"
        html += "</table>"
        return html
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜: {e}", 500

@app.route("/train-symbols", methods=["GET","POST"])
def train_symbols():
    try:
        if os.path.exists(LOCK_PATH):
            return f"â¸ï¸ ì´ˆê¸°í™” ì¤‘: ê·¸ë£¹/ì„ íƒ í•™ìŠµ ì‹œì‘ ì°¨ë‹¨ë¨", 423

        def _ensure_single_loop(force_flag: bool):
            if _is_training():
                if not force_flag:
                    return False, ("ğŸš« ì´ë¯¸ ë©”ì¸ í•™ìŠµ ë£¨í”„ ì‹¤í–‰ ì¤‘ (force=1 ë˜ëŠ” force=true ë¡œ ê°•ì œ êµì²´ ê°€ëŠ¥)", 409)
                try:
                    _request_stop_safe(); _stop_train_loop_safe(timeout=45)
                except Exception:
                    pass
            return True, None

        if request.method == "GET":
            group_idx = int(request.args.get("group", -1))
            force = request.args.get("force", "0") == "1"
            if group_idx < 0 or group_idx >= len(SYMBOL_GROUPS):
                return f"âŒ ì˜ëª»ëœ ê·¸ë£¹ ë²ˆí˜¸: {group_idx}", 400
            ok, resp = _ensure_single_loop(force)
            if not ok: return resp
            group_symbols = SYMBOL_GROUPS[group_idx]
            print(f"ğŸš€ ê·¸ë£¹ í•™ìŠµ ìš”ì²­ë¨ â†’ ê·¸ë£¹ #{group_idx} | ì‹¬ë³¼: {group_symbols}")
            # ê·¸ë£¹ ì‹œì‘: ê²Œì´íŠ¸ ë‹«ê¸° + GROUP_ACTIVE ìƒì„± + ê·¸ë£¹í•™ìŠµ ë½ ìƒì„±
            _safe_close_gate("train_group_start")
            _set_group_active(True, group_idx=group_idx, symbols=group_symbols)
            try:
                with open(GROUP_TRAIN_LOCK, "w", encoding="utf-8") as f:
                    f.write(f"group={group_idx} started={datetime.datetime.utcnow().isoformat()}\n")
                print("[GROUP-LOCK] created"); sys.stdout.flush()
            except Exception as e:
                print(f"[GROUP-LOCK] create failed: {e}"); sys.stdout.flush()

            def _worker():
                try:
                    _train_models_safe(group_symbols)
                    if not group_all_complete():
                        print("[GROUP-AFTER] ë¯¸ì™„ë£Œ: group_all_complete()=False â†’ ì˜ˆì¸¡ ìƒëµ"); return
                    if not ready_for_group_predict():
                        print("[GROUP-AFTER] ë¯¸ì™„ë£Œ: ready_for_group_predict()=False â†’ ì˜ˆì¸¡ ìƒëµ"); return
                    _predict_after_training(group_symbols, source_note=f"group{group_idx}_after_train")
                    try:
                        mark_group_predicted(); print("[GROUP-AFTER] mark_group_predicted() í˜¸ì¶œ ì™„ë£Œ")
                    except Exception as e:
                        print(f"[GROUP-AFTER] mark_group_predicted ì˜ˆì™¸: {e}")
                finally:
                    # ì¢…ë£Œ ì‹œì ì—ë§Œ GROUP_ACTIVE ì‚­ì œ + ê·¸ë£¹í•™ìŠµ ë½ ì œê±°
                    if group_all_complete() and ready_for_group_predict():
                        _set_group_active(False)
                    try:
                        if os.path.exists(GROUP_TRAIN_LOCK):
                            os.remove(GROUP_TRAIN_LOCK)
                            print("[GROUP-LOCK] removed"); sys.stdout.flush()
                    except Exception as e:
                        print(f"[GROUP-LOCK] remove failed: {e}"); sys.stdout.flush()

            threading.Thread(target=_worker, daemon=True).start()
            return f"âœ… ê·¸ë£¹ #{group_idx} í•™ìŠµ ì‹œì‘ë¨ (ì™„ë£Œ ê²€ì¦ í†µê³¼ ì‹œ í•™ìŠµ ì§í›„ ì˜ˆì¸¡, ì´í›„ mark_group_predicted)"
        else:
            body = request.get_json(silent=True) or {}
            symbols = body.get("symbols", [])
            force = bool(body.get("force", False))
            if not isinstance(symbols, list) or not symbols:
                return "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ symbols ë¦¬ìŠ¤íŠ¸", 400
            ok, resp = _ensure_single_loop(force)
            if not ok: return resp
            # ì„ íƒ í•™ìŠµì€ ê·¸ë£¹ ê²½ê³„ ì•„ë‹˜ â†’ GROUP_ACTIVE ë¹„ì¡°ì‘, ê·¸ë£¹ ë½ ë¹„ì‚¬ìš©
            _safe_close_gate("train_selected_start")
            def _worker():
                try:
                    _train_models_safe(symbols)
                    _predict_after_training(symbols, source_note="selected_after_train")
                finally:
                    pass
            threading.Thread(target=_worker, daemon=True).start()
            return f"âœ… {len(symbols)}ê°œ ì‹¬ë³¼ í•™ìŠµ ì‹œì‘ë¨ (í•™ìŠµ ì§í›„ ì˜ˆì¸¡ ìˆ˜í–‰ â€” ê·¸ë£¹ ë§ˆí‚¹ ì—†ìŒ)"
    except Exception as e:
        traceback.print_exc(); return f"âŒ ì˜¤ë¥˜: {e}", 500

@app.route("/meta-fix-now")
def meta_fix_now():
    try:
        maintenance_fix_meta.fix_all_meta_json()
        return "âœ… meta.json ì ê²€/ë³µêµ¬ ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì‹¤íŒ¨: {e}", 500

@app.route("/reset-all", methods=["GET","POST"])
@app.route("/reset-all/<key>", methods=["GET","POST"])
def reset_all(key=None):
    req_key = key or request.args.get("key") or (request.json.get("key") if request.is_json else None)
    if req_key != "3572":
        print(f"[RESET] ì¸ì¦ ì‹¤íŒ¨ from {request.remote_addr} path={request.path}"); sys.stdout.flush()
        return "âŒ ì¸ì¦ ì‹¤íŒ¨", 403
    ua = request.headers.get("User-Agent", "-")
    ip = request.headers.get("X-Forwarded-For", request.remote_addr)
    print(f"[RESET] ìš”ì²­ ìˆ˜ì‹  from {ip} UA={ua}"); sys.stdout.flush()
    _safe_close_gate("reset_enter")
    def _arm_reset_watchdog(seconds: int):
        seconds = max(30, int(seconds))
        def _kill():
            print(f"ğŸ›‘ [WATCHDOG] reset watchdog fired after {seconds}s â†’ os._exit(0)"); sys.stdout.flush()
            try: _release_global_lock()
            finally: os._exit(0)
        t = threading.Timer(seconds, _kill); t.daemon = True; t.start()
        return t
    def _do_reset_work():
        stop_timeout = int(os.getenv("RESET_STOP_TIMEOUT", "12"))
        max_wait     = int(os.getenv("RESET_MAX_WAIT_SEC", "120"))
        poll_sec     = max(1, int(os.getenv("RESET_POLL_SEC", "2")))
        watchdog_sec = int(os.getenv("RESET_WATCHDOG_SEC", str(stop_timeout + max_wait + 30)))
        qwipe_early  = os.getenv("RESET_QWIPE_EARLY", "1") == "1"
        _wd = _arm_reset_watchdog(watchdog_sec)
        try:
            from data.utils import _kline_cache, _feature_cache
            import importlib
            _acquire_global_lock()
            _stop_all_aux_schedulers()
            _pl_clear()
            PERSIST = PERSIST_DIR; LOGS = LOG_DIR; MODELS = MODEL_DIR
            def clear_csv(f, headers):
                os.makedirs(os.path.dirname(f), exist_ok=True)
                with open(f, "w", newline="", encoding="utf-8-sig") as wf:
                    wf.write(",".join(headers) + "\n")
            print("[RESET] ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹œì‘"); sys.stdout.flush()
            try:
                if hasattr(train, "request_stop"):
                    _request_stop_safe()
            except Exception: pass
            stopped = False
            try:
                print(f"[RESET] í•™ìŠµ ë£¨í”„ ì •ì§€ ì‹œë„(timeout={stop_timeout}s)"); sys.stdout.flush()
                stopped = _stop_train_loop_safe(timeout=stop_timeout)
            except Exception as e:
                print(f"âš ï¸ [RESET] stop_train_loop ì˜ˆì™¸: {e}"); sys.stdout.flush()
            print(f"[RESET] stop_train_loop ê²°ê³¼: {stopped}"); sys.stdout.flush()
            if (not stopped) and qwipe_early:
                try:
                    print("[RESET] ë¹ ë¥¸ ì •ì§€ ì‹¤íŒ¨ â†’ ì¡°ê¸° QWIPE ìˆ˜í–‰"); sys.stdout.flush()
                    _quarantine_wipe_persistent()
                    ensure_dirs()  # âœ… ì¡°ê¸° QWIPE ì§í›„ ì¦‰ì‹œ ë³µêµ¬
                except Exception as e:
                    print(f"âš ï¸ [RESET] ì¡°ê¸° QWIPE ì‹¤íŒ¨: {e}"); sys.stdout.flush()
            if not stopped:
                t0 = time.time()
                print(f"[RESET] ì •ì§€ ëŒ€ê¸° ì‹œì‘â€¦ ìµœëŒ€ {max_wait}s (í´ë§ {poll_sec}s)"); sys.stdout.flush()
                while time.time() - t0 < max_wait:
                    try:
                        if not _is_training(): stopped = True; break
                    except Exception: pass
                    try:
                        if _stop_train_loop_safe(timeout=2): stopped = True; break
                    except Exception: pass
                    time.sleep(poll_sec)
                print(f"[RESET] ì •ì§€ ëŒ€ê¸° ì™„ë£Œ â†’ stopped={stopped}"); sys.stdout.flush()
            if not stopped:
                print("ğŸ›‘ [RESET] ë£¨í”„ ë¯¸ì¢…ë£Œ â†’ QWIPE í›„ í•˜ë“œ ì¢…ë£Œ"); sys.stdout.flush()
                try:
                    _quarantine_wipe_persistent()
                    ensure_dirs()
                except Exception as e: print(f"âš ï¸ [RESET] QWIPE ì‹¤íŒ¨: {e}")
                try: _release_global_lock()
                finally:
                    try: _wd.cancel()
                    except Exception: pass
                    os._exit(0)
            try:
                done_path = os.path.join(PERSIST_DIR, "train_done.json")
                if os.path.exists(done_path): os.remove(done_path)
            except Exception: pass
            try:
                for d in [MODELS, LOGS, os.path.join(PERSIST_DIR, "ssl_models")]:
                    if os.path.exists(d): shutil.rmtree(d, ignore_errors=True)
                    os.makedirs(d, exist_ok=True)
                keep = {os.path.basename(LOCK_DIR)}
                for name in list(os.listdir(PERSIST_DIR)):
                    p = os.path.join(PERSIST_DIR, name)
                    if name in keep: continue
                    if os.path.isdir(p):
                        if name not in {"logs", "models", "ssl_models", "run"}: shutil.rmtree(p, ignore_errors=True)
                        if name == "run":
                            try:
                                for f in os.listdir(p):
                                    try: os.remove(os.path.join(p, f))
                                    except Exception: pass
                            except Exception: pass
                    else:
                        try: os.remove(p)
                        except Exception: pass
                suspect_prefixes = ("prediction_log","eval","message_log","train_log","wrong_predictions",
                                    "evaluation_audit","failure_count","diag","e2e","guan","ê´€ìš°")
                for root, dirs, files in os.walk(PERSIST_DIR, topdown=False):
                    for f in files:
                        low = f.lower()
                        if low.endswith((".csv",".db",".json",".txt")) or low.startswith(suspect_prefixes):
                            try: os.remove(os.path.join(root, f))
                            except Exception: pass
                    for d in dirs:
                        low = d.lower()
                        if low.startswith(suspect_prefixes) or ("ê´€ìš°" in d):
                            try: shutil.rmtree(os.path.join(root, d), ignore_errors=True)
                            except Exception: pass
                # âœ… í’€ì™€ì´í”„ ì´í›„ì—ë„ í•„ìˆ˜ ê²½ë¡œ ë³µêµ¬
                ensure_dirs()
            except Exception as e:
                print(f"âš ï¸ [RESET] í’€ì™€ì´í”„ ì˜ˆì™¸: {e}"); sys.stdout.flush()
            try: _kline_cache.clear()
            except Exception: pass
            try: _feature_cache.clear()
            except Exception: pass
            try:
                ensure_prediction_log_exists()
                ensure_train_log_exists()
                clear_csv(os.path.join(PERSIST_DIR, "wrong_predictions.csv"), PREDICTION_HEADERS)
                clear_csv(os.path.join(LOG_DIR, "evaluation_audit.csv"), ["timestamp","symbol","strategy","status","reason"])
                clear_csv(os.path.join(LOG_DIR, "message_log.csv"), ["timestamp","symbol","strategy","message"])
                clear_csv(os.path.join(LOG_DIR, "failure_count.csv"), ["symbol","strategy","failures"])
            except Exception as e:
                print(f"âš ï¸ [RESET] ë¡œê·¸ ì¬ìƒì„± ì˜ˆì™¸: {e}"); sys.stdout.flush()
            try:
                import diag_e2e as _diag_mod, importlib as _imp
                _imp.reload(_diag_mod)
            except Exception: pass
            try:
                maintenance_fix_meta.fix_all_meta_json()
            except Exception as e:
                print(f"[RESET] meta ë³´ì • ì‹¤íŒ¨: {e}")
            print("ğŸ”š [RESET] ì •ë¦¬ ì™„ë£Œ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ(os._exit)"); sys.stdout.flush()
            _release_global_lock()
            try: _wd.cancel()
            except Exception: pass
            os._exit(0)
        except Exception as e:
            print(f"âŒ [RESET] ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì˜ˆì™¸: {e}"); sys.stdout.flush()
        finally:
            _release_global_lock()
    threading.Thread(target=_do_reset_work, daemon=True).start()
    return Response(
        "âœ… ì´ˆê¸°í™” ìš”ì²­ ì ‘ìˆ˜ë¨. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì •ì§€â†’ì •ë¦¬ í›„ ì„œë²„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¬ì‹œì‘í•©ë‹ˆë‹¤.\n"
        "ë¡œê·¸ì—ì„œ [RESET]/[SCHED]/[LOCK]/[QWIPE] íƒœê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
        mimetype="text/plain; charset=utf-8"
    )

@app.route("/force-fix-prediction_log")
@app.route("/force-fix-prediction-log")
def force_fix_prediction_log():
    try:
        if os.path.exists(PREDICTION_LOG):
            os.remove(PREDICTION_LOG)
        ensure_prediction_log_exists()
        print("[FORCE-FIX] prediction_log.csv ì¬ìƒì„± ì™„ë£Œ"); sys.stdout.flush()
        return "âœ… prediction_log.csv ê°•ì œ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜: {e}", 500

# ì¦‰ì‹œ ì „ì²´ ì˜ˆì¸¡: í•™ìŠµ ì¼ì‹œì •ì§€ â†’ ì˜ˆì¸¡ â†’ í•™ìŠµ ì¬ê°œ
@app.route("/predict-now", methods=["POST","GET"])
def predict_now():
    try:
        was_running = _is_training()
        if was_running:
            print("[PREDICT-NOW] training detected â†’ stopping..."); sys.stdout.flush()
            try: _request_stop_safe()
            except Exception: pass
            stopped = _stop_train_loop_safe(timeout=45)
            if not stopped:
                return "âŒ í•™ìŠµ ì •ì§€ ì‹¤íŒ¨ë¡œ ì˜ˆì¸¡ ì·¨ì†Œë¨", 423

        if os.path.exists(LOCK_PATH) or _is_group_active_file() or os.path.exists(GROUP_TRAIN_LOCK):
            return "â¸ï¸ ì´ˆê¸°í™”/ê·¸ë£¹í•™ìŠµ ì¤‘: ì˜ˆì¸¡ ì‹œì‘ ì°¨ë‹¨ë¨", 423
        _pl_clear()
        _safe_open_gate("predict_now")

        total, done, skipped = 0, 0, 0
        try:
            for sym in SYMBOLS:
                for strat in ["ë‹¨ê¸°","ì¤‘ê¸°","ì¥ê¸°"]:
                    total += 1
                    if not _has_model_for(sym, strat):
                        skipped += 1
                        print(f"[PREDICT-NOW] skip {sym}-{strat}: model missing"); sys.stdout.flush()
                        continue
                    try:
                        result = predict(sym, strat, source="predict_now", model_type=None)
                        if not isinstance(result, dict):
                            try:
                                from predict import failed_result
                                failed_result(sym, strat, reason="invalid_return", source="predict_now")
                            except Exception: pass
                        done += 1
                        print(f"[PREDICT-NOW] ok {sym}-{strat}"); sys.stdout.flush()
                    except Exception as e:
                        print(f"[PREDICT-NOW] fail {sym}-{strat}: {e}"); sys.stdout.flush()
                        try:
                            from predict import failed_result
                            failed_result(sym, strat, reason=str(e), source="predict_now")
                        except Exception: pass
        finally:
            _safe_close_gate("predict_now_end")

        resumed = False
        if was_running:
            resumed = _start_train_loop_safe(force_restart=False, sleep_sec=0)
            print(f"[PREDICT-NOW] training resumed={resumed}"); sys.stdout.flush()

        return f"âœ… ì˜ˆì¸¡ ì™„ë£Œ | ì´:{total} ì„±ê³µ:{done} ìŠ¤í‚µ:{skipped} | í•™ìŠµì •ì§€:{'ì˜ˆ' if was_running else 'ì•„ë‹ˆì˜¤'} â†’ ì¬ê°œ:{'ì˜ˆ' if resumed else 'ì•„ë‹ˆì˜¤'}"
    except Exception as e:
        traceback.print_exc()
        return f"âŒ ì˜¤ë¥˜: {e}", 500


if __name__ == "__main__":
    try:
        port = int(os.environ.get("PORT", 5000))
    except ValueError:
        raise RuntimeError("âŒ Render í™˜ê²½ë³€ìˆ˜ PORTê°€ ì—†ìŠµë‹ˆë‹¤. Render ì„œë¹„ìŠ¤ íƒ€ì… í™•ì¸ í•„ìš”")
    _init_background_once()
    print(f"âœ… Flask ì„œë²„ ì‹¤í–‰ ì‹œì‘ (PORT={port})")
    app.run(host="0.0.0.0", port=port)
