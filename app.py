# app.py â€” single-source, deduped train loop (ONE concurrent loop only)

from flask import Flask, jsonify, request, Response
from recommend import main
import train, os, threading, datetime, pandas as pd, pytz, traceback, sys, shutil, csv, re
from apscheduler.schedulers.background import BackgroundScheduler
from telegram_bot import send_message
from predict_test import test_all_predictions
from predict_trigger import run as trigger_run
from data.utils import SYMBOLS, get_kline_by_strategy
from visualization import generate_visual_report, generate_visuals_for_strategy
from wrong_data_loader import load_training_prediction_data
from predict import evaluate_predictions
from train import train_symbol_group_loop
import maintenance_fix_meta
from logger import ensure_prediction_log_exists
from integrity_guard import run as _integrity_check; _integrity_check()

# âœ… ì¢…í•©ì ê²€ ëª¨ë“ˆ(HTML/JSON + ëˆ„ì  í†µê³„ ì§€ì›)
from diag_e2e import run as diag_e2e_run

# âœ… cleanup ëª¨ë“ˆ ê²½ë¡œ ë³´ì •
try:
    from scheduler_cleanup import start_cleanup_scheduler   # [KEEP]
    import safe_cleanup                                      # [KEEP]
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from scheduler_cleanup import start_cleanup_scheduler    # [KEEP]
    import safe_cleanup                                      # [KEEP]

# âœ… ì„œë²„ ì‹œì‘ ì§ì „ ìš©ëŸ‰ ì •ë¦¬
try:
    safe_cleanup.cleanup_logs_and_models()
except Exception as e:
    print(f"[ê²½ê³ ] startup cleanup ì‹¤íŒ¨: {e}")

# ===== ê²½ë¡œ í†µì¼ =====
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # â† ë£¨íŠ¸ íƒìƒ‰ìš©(ì´ˆê¸°í™” ê°•í™”ì—ë§Œ ì‚¬ìš©)
PERSIST_DIR = "/persistent"
LOG_DIR = os.path.join(PERSIST_DIR, "logs")
MODEL_DIR = os.path.join(PERSIST_DIR, "models")
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)  # âœ… ëª¨ë¸ ë””ë ‰í† ë¦¬ ë³´ì¥

# âœ… prediction_logì€ loggerì™€ ë™ì¼í•œ ìœ„ì¹˜/í—¤ë”ë¡œ ê´€ë¦¬
PREDICTION_LOG = os.path.join(PERSIST_DIR, "prediction_log.csv")

LOG_FILE         = os.path.join(LOG_DIR, "train_log.csv")
WRONG_PREDICTIONS= os.path.join(PERSIST_DIR, "wrong_predictions.csv")
AUDIT_LOG        = os.path.join(LOG_DIR, "evaluation_audit.csv")
MESSAGE_LOG      = os.path.join(LOG_DIR, "message_log.csv")
FAILURE_LOG      = os.path.join(LOG_DIR, "failure_count.csv")

# âœ… ë¡œê·¸ íŒŒì¼ ì¡´ì¬ ë³´ì¥(ì •í™• í—¤ë”)
ensure_prediction_log_exists()

now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

# -----------------------------
# í•™ìŠµ ë£¨í”„ ë™ì‹œ ì‹¤í–‰ ë°©ì§€(í•µì‹¬ ìˆ˜ì •)
# -----------------------------
TRAIN_LOOP_THREAD = None
TRAIN_LOOP_LOCK = threading.Lock()

def start_train_loop_once():
    """train_symbol_group_loopë¥¼ ë™ì‹œ 1ê°œë§Œ ì‹¤í–‰ë˜ê²Œ ë³´ì¥"""
    global TRAIN_LOOP_THREAD
    with TRAIN_LOOP_LOCK:
        if TRAIN_LOOP_THREAD is not None and TRAIN_LOOP_THREAD.is_alive():
            print("âš ï¸ í•™ìŠµ ë£¨í”„ ì´ë¯¸ ì‹¤í–‰ ì¤‘ â€” ì¬ì‹œì‘ ìƒëµ"); sys.stdout.flush()
            return False
        TRAIN_LOOP_THREAD = threading.Thread(target=train_symbol_group_loop, daemon=True)
        TRAIN_LOOP_THREAD.start()
        print("âœ… í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ ì‹œì‘"); sys.stdout.flush()
        return True

# -----------------------------
# ìŠ¤ì¼€ì¤„ëŸ¬ (í‰ê°€/íŠ¸ë¦¬ê±°/ë©”íƒ€ë³µêµ¬)
# -----------------------------
_sched = None
def start_scheduler():
    global _sched
    if _sched is not None:
        print("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë¯¸ ì‹¤í–‰ ì¤‘, ì¬ì‹œì‘ ìƒëµ"); sys.stdout.flush()
        return

    print(">>> ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"); sys.stdout.flush()
    sched = BackgroundScheduler(timezone=pytz.timezone("Asia/Seoul"))

    # âœ… ì „ëµë³„ í‰ê°€(30ë¶„ë§ˆë‹¤)
    def í‰ê°€ì‘ì—…(strategy):
        def wrapped():
            try:
                ts = now_kst().strftime("%Y-%m-%d %H:%M:%S")
                print(f"[EVAL][{ts}] ì „ëµ={strategy} ì‹œì‘"); sys.stdout.flush()
                evaluate_predictions(lambda sym, _: get_kline_by_strategy(sym, strategy))
            except Exception as e:
                print(f"[EVAL] {strategy} ì‹¤íŒ¨: {e}")
        threading.Thread(target=wrapped, daemon=True).start()

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        sched.add_job(lambda s=strat: í‰ê°€ì‘ì—…(s), trigger="interval", minutes=30, id=f"eval_{strat}", replace_existing=True)

    # âœ… ì˜ˆì¸¡ íŠ¸ë¦¬ê±°(ë©”íƒ€ì ìš© í¬í•¨) 30ë¶„
    sched.add_job(trigger_run, "interval", minutes=30, id="predict_trigger", replace_existing=True)

    # âœ… ë©”íƒ€ JSON ì •í•©ì„±/ë³µêµ¬ ì£¼ê¸°ì‘ì—… (30ë¶„)
    def meta_fix_job():
        try:
            maintenance_fix_meta.fix_all_meta_json()
        except Exception as e:
            print(f"[META-FIX] ì£¼ê¸°ì‘ì—… ì‹¤íŒ¨: {e}")
    sched.add_job(meta_fix_job, "interval", minutes=30, id="meta_fix", replace_existing=True)

    sched.start()
    _sched = sched
    print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ"); sys.stdout.flush()

# ===== Flask =====
app = Flask(__name__)
print(">>> Flask ì•± ìƒì„± ì™„ë£Œ"); sys.stdout.flush()

# -----------------------------
# ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™”(í•œ ë²ˆë§Œ)
# -----------------------------
_INIT_DONE = False
_INIT_LOCK = threading.Lock()

def _init_background_once():
    global _INIT_DONE
    with _INIT_LOCK:
        if _INIT_DONE:
            return
        try:
            from failure_db import ensure_failure_db
            print(">>> ì„œë²„ ì‹¤í–‰ ì¤€ë¹„")
            ensure_failure_db(); print("âœ… failure_patterns DB ì´ˆê¸°í™” ì™„ë£Œ")

            # í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ (ë™ì‹œ 1ê°œ ë³´ì¥)
            start_train_loop_once()

            # ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬(ê¸°ë³¸ 30ë¶„)
            start_cleanup_scheduler()
            print("âœ… cleanup ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

            # í‰ê°€/íŠ¸ë¦¬ê±°/ë©”íƒ€ë³µêµ¬ ìŠ¤ì¼€ì¤„ëŸ¬
            try:
                start_scheduler()
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")

            # ë©”íƒ€ ë³´ì •(ë¶€íŒ… ì‹œ 1íšŒ ì„  ì‹¤í–‰)
            threading.Thread(target=maintenance_fix_meta.fix_all_meta_json, daemon=True).start()
            print("âœ… maintenance_fix_meta ì´ˆê¸° ì‹¤í–‰ íŠ¸ë¦¬ê±°")

            # í…”ë ˆê·¸ë¨ ì•Œë¦¼
            try:
                send_message("[ì‹œì‘] YOPO ì„œë²„ ì‹¤í–‰ë¨")
                print("âœ… Telegram ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Telegram ë°œì†¡ ì‹¤íŒ¨: {e}")

            _INIT_DONE = True
            print("âœ… ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# Flask 3.1 í˜¸í™˜
if hasattr(app, "before_serving"):
    @app.before_serving
    def _boot_once():
        _init_background_once()
else:
    @app.before_request
    def _boot_once_compat():
        if not _INIT_DONE:
            _init_background_once()

# ===== ë¼ìš°íŠ¸ =====
@app.route("/yopo-health")
def yopo_health():
    percent = lambda v: f"{v:.1f}%" if pd.notna(v) else "0.0%"
    logs, strategy_html, problems = {}, [], []

    file_map = {"pred": PREDICTION_LOG, "train": LOG_FILE, "audit": AUDIT_LOG, "msg": MESSAGE_LOG}
    for name, path in file_map.items():
        try:
            logs[name] = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
            if "timestamp" in logs[name].columns:
                logs[name] = logs[name][logs[name]["timestamp"].notna()]
        except Exception:
            logs[name] = pd.DataFrame()

    # ëª¨ë¸ íŒŒì¼ íŒŒì‹±
    try:
        model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pt")]
    except Exception:
        model_files = []
    model_info = {}
    for f in model_files:
        m = re.match(r"(.+?)_(ë‹¨ê¸°|ì¤‘ê¸°|ì¥ê¸°)_(lstm|cnn_lstm|transformer)(?:_.*)?\.pt$")
        if m:
            symbol, strat, mtype = m.groups()
            model_info.setdefault(strat, {}).setdefault(symbol, set()).add(mtype)

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        try:
            pred  = logs.get("pred",  pd.DataFrame())
            train = logs.get("train", pd.DataFrame())
            audit = logs.get("audit", pd.DataFrame())
            pred  = pred.query(f"strategy == '{strat}'")  if not pred.empty  else pd.DataFrame()
            train = train.query(f"strategy == '{strat}'") if not train.empty else pd.DataFrame()
            audit = audit.query(f"strategy == '{strat}'") if not audit.empty else pd.DataFrame()

            if not pred.empty and "status" in pred.columns:
                pred["volatility"] = pred["status"].astype(str).str.startswith("v_")
            else:
                pred["volatility"] = False

            try:
                pred["return"] = pd.to_numeric(pred.get("return", pd.Series(dtype=float)), errors="coerce").fillna(0.0)
            except Exception:
                pred["return"] = 0.0

            nvol = pred[~pred["volatility"]] if not pred.empty else pd.DataFrame()
            vol  = pred[ pred["volatility"]] if not pred.empty else pd.DataFrame()

            stat = lambda df, s: int(((not df.empty) and ("status" in df.columns)) and (df["status"]==s).sum()) or 0
            sn, fn, pn_, fnl = map(lambda s: stat(nvol, s), ["success", "fail", "pending", "failed"])
            sv, fv, pv, fvl = map(lambda s: stat(vol,  s), ["v_success", "v_fail", "pending", "failed"])

            def perf(df, kind="ì¼ë°˜"):
                try:
                    s = stat(df, "v_success" if kind == "ë³€ë™ì„±" else "success")
                    f = stat(df, "v_fail"    if kind == "ë³€ë™ì„±" else "fail")
                    t = s + f
                    avg = float(df["return"].mean()) if ("return" in df) and (df.shape[0]>0) else 0.0
                    return {"succ": s, "fail": f, "succ_rate": s/t*100 if t else 0,
                            "fail_rate": f/t*100 if t else 0, "r_avg": avg, "total": t}
                except Exception:
                    return {"succ": 0, "fail": 0, "succ_rate": 0, "fail_rate": 0, "r_avg": 0, "total": 0}

            pn, pv_stats = perf(nvol, "ì¼ë°˜"), perf(vol, "ë³€ë™ì„±")

            strat_models = model_info.get(strat, {})
            types = {"lstm": 0, "cnn_lstm": 0, "transformer": 0}
            for mtypes in strat_models.values():
                for t in mtypes: types[t] += 1
            trained_syms = [s for s, t in strat_models.items() if {"lstm","cnn_lstm","transformer"}.issubset(t)]
            try:
                untrained = sorted(set(SYMBOLS) - set(trained_syms))
            except Exception:
                untrained = []

            if sum(types.values()) == 0: problems.append(f"{strat}: ëª¨ë¸ ì—†ìŒ")
            if sn + fn + pn_ + fnl + sv + fv + pv + fvl == 0: problems.append(f"{strat}: ì˜ˆì¸¡ ì—†ìŒ")
            if pn["total"] == 0: problems.append(f"{strat}: í‰ê°€ ë¯¸ì‘ë™")
            if pn["fail_rate"]  > 50: problems.append(f"{strat}: ì¼ë°˜ ì‹¤íŒ¨ìœ¨ {pn['fail_rate']:.1f}%")
            if pv_stats["fail_rate"] > 50: problems.append(f"{strat}: ë³€ë™ì„± ì‹¤íŒ¨ìœ¨ {pv_stats['fail_rate']:.1f}%")

            table = "<i style='color:gray'>ìµœê·¼ ì˜ˆì¸¡ ì—†ìŒ ë˜ëŠ” ì»¬ëŸ¼ ë¶€ì¡±</i>"
            required_cols = {"timestamp","symbol","strategy","direction","return","status"}
            if (pred.shape[0] > 0) and required_cols.issubset(set(pred.columns)):
                recent10 = pred.sort_values("timestamp").tail(10).copy()
                rows = []
                for _, r in recent10.iterrows():
                    rtn = r.get("return", 0.0) or r.get("rate", 0.0)
                    try: rtn_pct = f"{float(rtn) * 100:.2f}%"
                    except: rtn_pct = "0.00%"
                    s = str(r.get('status',''))
                    status_icon = 'âœ…' if s in ['success','v_success'] else 'âŒ' if s in ['fail','v_fail'] else 'â³' if s in ['pending','v_pending'] else 'ğŸ›‘'
                    rows.append(f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('direction','')}</td><td>{rtn_pct}</td><td>{status_icon}</td></tr>")
                table = "<table border='1' style='margin-top:4px'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ë°©í–¥</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th></tr>" + "".join(rows) + "</table>"

            last_train = train['timestamp'].iloc[-1] if (not train.empty and 'timestamp' in train) else 'ì—†ìŒ'
            last_pred  = pred['timestamp'].iloc[-1]  if (not pred.empty and 'timestamp' in pred)  else 'ì—†ìŒ'
            last_audit = audit['timestamp'].iloc[-1] if (not audit.empty and 'timestamp' in audit) else 'ì—†ìŒ'

            info_html = f"""<div style='border:1px solid #aaa;margin:16px 0;padding:10px;font-family:monospace;background:#f8f8f8;'>
<b style='font-size:16px;'>ğŸ“Œ ì „ëµ: {strat}</b><br>
- ëª¨ë¸ ìˆ˜: {sum(types.values())} (lstm={types['lstm']}, cnn={types['cnn_lstm']}, trans={types['transformer']})<br>
- ì‹¬ë³¼ ìˆ˜: {len(SYMBOLS)} | ì™„ì „í•™ìŠµ: {len(trained_syms)} | ë¯¸ì™„ì„±: {len(untrained)}<br>
- ìµœê·¼ í•™ìŠµ: {last_train}<br>
- ìµœê·¼ ì˜ˆì¸¡: {last_pred}<br>
- ìµœê·¼ í‰ê°€: {last_audit}<br>
- ì˜ˆì¸¡ (ì¼ë°˜): {sn + fn + pn_ + fnl}ê±´ (âœ…{sn} âŒ{fn} â³{pn_} ğŸ›‘{fnl})<br>
- ì˜ˆì¸¡ (ë³€ë™ì„±): {sv + fv + pv + fvl}ê±´ (âœ…{sv} âŒ{fv} â³{pv} ğŸ›‘{fvl})<br>
<b style='color:#000088'>ğŸ¯ ì¼ë°˜ ì˜ˆì¸¡</b>: {pn['total']}ê±´ | {pn['succ_rate']:.1f}% / {pn['fail_rate']:.1f}% / {pn['r_avg']:.2f}%<br>
<b style='color:#880000'>ğŸŒªï¸ ë³€ë™ì„± ì˜ˆì¸¡</b>: {pv_stats['total']}ê±´ | {pv_stats['succ_rate']:.1f}% / {pv_stats['fail_rate']:.1f}% / {pv_stats['r_avg']:.2f}%<br>
<b>ğŸ“‹ ìµœê·¼ ì˜ˆì¸¡ 10ê±´</b><br>{table}
</div>"""

            try:
                visual = generate_visuals_for_strategy(strat)
            except Exception as e:
                visual = f"<div style='color:red'>[ì‹œê°í™” ì‹¤íŒ¨: {e}]</div>"

            strategy_html.append(f"<div style='margin-bottom:30px'>{info_html}<div style='margin:20px 0'>{visual}</div><hr></div>")
        except Exception as e:
            strategy_html.append(f"<div style='color:red;'>âŒ {strat} ì‹¤íŒ¨: {type(e).__name__} â†’ {e}</div>")

    status = "ğŸŸ¢ ì „ì²´ ì „ëµ ì •ìƒ ì‘ë™ ì¤‘" if not problems else "ğŸ”´ ì¢…í•©ì§„ë‹¨ ìš”ì•½:<br>" + "<br>".join(problems)
    return f"<div style='font-family:monospace;line-height:1.6;font-size:15px;'><b>{status}</b><hr>" + "".join(strategy_html) + "</div>"

@app.route("/")
def index(): return "Yopo server is running"

@app.route("/ping")
def ping(): return "pong"

# âœ… ì¢…í•© ì ê²€ ë¼ìš°íŠ¸ (HTML/JSON + ëˆ„ì  ì˜µì…˜)
@app.route("/diag/e2e")
def diag_e2e():
    """
    ì‚¬ìš©ë²•:
      /diag/e2e?view=json         â†’ JSON(ê¸°ë³¸)
      /diag/e2e?view=html         â†’ í•œê¸€ HTML ë¦¬í¬íŠ¸
      /diag/e2e?group=0           â†’ ê·¸ë£¹ ì¸ë±ìŠ¤ ê¸°ì¤€ í†µê³„
      /diag/e2e?cum=1             â†’ ëˆ„ì  í†µê³„(ë©”ëª¨ë¦¬ ì•ˆì „ ìŠ¤íŠ¸ë¦¬ë°)
      /diag/e2e?symbols=BTCUSDT,ETHUSDT â†’ íŠ¹ì • ì‹¬ë³¼ë§Œ ì§‘ê³„
    """
    try:
        group = int(request.args.get("group", "-1"))
        view = request.args.get("view", "json").lower()
        cumulative = request.args.get("cum", "0") == "1"
        symbols = request.args.get("symbols")  # â† ì¶”ê°€: ì‹¬ë³¼ í•„í„° ë°›ê¸°

        # diag_e2e.runì€ (group, view, cumulative, symbols) ì‹œê·¸ë‹ˆì²˜ ì§€ì›
        out = diag_e2e_run(group=group, view=view, cumulative=cumulative, symbols=symbols)  # â† ì „ë‹¬

        # diag_e2e_runì´ Flask Responseë¥¼ ì§ì ‘ ë°˜í™˜í•  ìˆ˜ë„ ìˆìŒ
        if isinstance(out, Response):
            return out

        if view == "html":
            return Response(out if isinstance(out, str) else str(out),
                            mimetype="text/html; charset=utf-8")
        return jsonify(out)
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/run")
def run():
    try:
        print("[RUN] ì „ëµë³„ ì˜ˆì¸¡ ì‹¤í–‰"); sys.stdout.flush()
        for strategy in ["ë‹¨ê¸°","ì¤‘ê¸°","ì¥ê¸°"]:
            main(strategy, force=True)
        return "Recommendation started"
    except Exception as e:
        traceback.print_exc(); return f"Error: {e}", 500

@app.route("/train-now")
def train_now():
    try:
        started = start_train_loop_once()
        return "âœ… ì „ì²´ ê·¸ë£¹ í•™ìŠµ ë£¨í”„ ì‹œì‘ë¨ (ë°±ê·¸ë¼ìš´ë“œ)" if started else "â³ ì´ë¯¸ ì‹¤í–‰ ì¤‘ (ì¬ì‹œì‘ ìƒëµ)"
    except Exception as e:
        return f"í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/train-log")
def train_log():
    try:
        if not os.path.exists(LOG_FILE): return "í•™ìŠµ ë¡œê·¸ ì—†ìŒ"
        df = pd.read_csv(LOG_FILE, encoding="utf-8-sig", on_bad_lines="skip")
        if df.empty or df.shape[1] == 0: return "í•™ìŠµ ê¸°ë¡ ì—†ìŒ"
        return "<pre>" + df.to_csv(index=False) + "</pre>"
    except Exception as e:
        return f"ì½ê¸° ì˜¤ë¥˜: {e}", 500

@app.route("/models")
def list_models():
    try:
        if not os.path.exists(MODEL_DIR): return "models í´ë” ì—†ìŒ"
        files = os.listdir(MODEL_DIR)
        return "<pre>" + "\n".join(files) + "</pre>" if files else "models í´ë” ë¹„ì–´ ìˆìŒ"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 500

@app.route("/check-log-full")
def check_log_full():
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)
        return jsonify(latest.to_dict(orient="records"))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-log")
def check_log():
    try:
        if not os.path.exists(PREDICTION_LOG):
            return jsonify({"error": "prediction_log.csv ì—†ìŒ"})
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        if "timestamp" not in df:
            return jsonify([])
        df = df[df["timestamp"].notna()]
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-eval-log")
def check_eval_log():
    try:
        path = PREDICTION_LOG
        if not os.path.exists(path): return "ì˜ˆì¸¡ ë¡œê·¸ ì—†ìŒ"

        df = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
        if "status" not in df.columns: return "ìƒíƒœ ì»¬ëŸ¼ ì—†ìŒ"

        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)

        def status_icon(s):
            return {"success":"âœ…","fail":"âŒ","v_success":"âœ…","v_fail":"âŒ","pending":"â³","v_pending":"â³"}.get(s,"â“")

        html = "<table border='1'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ì „ëµ</th><th>ëª¨ë¸</th><th>ì˜ˆì¸¡</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th><th>ì‚¬ìœ </th></tr>"
        for _, r in latest.iterrows():
            icon = status_icon(r.get("status",""))
            html += f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('strategy','')}</td><td>{r.get('model','')}</td><td>{r.get('direction','')}</td><td>{float(r.get('return',0) or 0):.4f}</td><td>{icon}</td><td>{r.get('reason','')}</td></tr>"
        html += "</table>"
        return html
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜: {e}", 500

from data.utils import SYMBOL_GROUPS

@app.route("/train-symbols")
def train_symbols():
    try:
        group_idx = int(request.args.get("group", -1))
        if group_idx < 0 or group_idx >= len(SYMBOL_GROUPS):
            return f"âŒ ì˜ëª»ëœ ê·¸ë£¹ ë²ˆí˜¸: {group_idx}", 400
        group_symbols = SYMBOL_GROUPS[group_idx]
        print(f"ğŸš€ ê·¸ë£¹ í•™ìŠµ ìš”ì²­ë¨ â†’ ê·¸ë£¹ #{group_idx} | ì‹¬ë³¼: {group_symbols}")
        threading.Thread(target=lambda: train.train_models(group_symbols), daemon=True).start()
        return f"âœ… ê·¸ë£¹ #{group_idx} í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘ë¨"
    except Exception as e:
        traceback.print_exc(); return f"âŒ ì˜¤ë¥˜: {e}", 500

@app.route("/train-symbols", methods=["POST"])
def train_selected_symbols():
    try:
        symbols = request.json.get("symbols", [])
        if not isinstance(symbols, list) or not symbols:
            return "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ symbols ë¦¬ìŠ¤íŠ¸", 400
        train.train_models(symbols)
        return f"âœ… {len(symbols)}ê°œ ì‹¬ë³¼ í•™ìŠµ ì‹œì‘ë¨"
    except Exception as e:
        return f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/meta-fix-now")
def meta_fix_now():
    try:
        maintenance_fix_meta.fix_all_meta_json()
        return "âœ… meta.json ì ê²€/ë³µêµ¬ ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì‹¤íŒ¨: {e}", 500

@app.route("/reset-all")
def reset_all():
    if request.args.get("key") != "3572":
        return "âŒ ì¸ì¦ ì‹¤íŒ¨", 403
    try:
        # ==== ìš´ì˜/ê´€ìš° ë¡œê·¸ ì™„ì „ í†µì¼ì„ ìœ„í•œ í™•ì¥ ì´ˆê¸°í™” ====
        from data.utils import _kline_cache, _feature_cache
        import importlib

        def clear_csv(f, h):
            os.makedirs(os.path.dirname(f), exist_ok=True)
            with open(f, "w", newline="", encoding="utf-8-sig") as wf:
                wf.write(",".join(h) + "\n")

        # 1) ì§„í–‰ìƒíƒœ ë§ˆì»¤ ì œê±°
        done_path = os.path.join(PERSIST_DIR, "train_done.json")
        if os.path.exists(done_path): os.remove(done_path)

        # 2) ëª¨ë¸/ë¡œê·¸ ë””ë ‰í† ë¦¬ ì „ì‚­ì œ í›„ ì¬ìƒì„±
        if os.path.exists(MODEL_DIR): shutil.rmtree(MODEL_DIR)
        os.makedirs(MODEL_DIR, exist_ok=True)

        if os.path.exists(LOG_DIR): shutil.rmtree(LOG_DIR)
        os.makedirs(LOG_DIR, exist_ok=True)

        # 3) prediction_log.csv í¬í•¨, ë£¨íŠ¸ ì”ì—¬ ë¡œê·¸ ì œê±°
        if os.path.exists(PREDICTION_LOG):
            os.remove(PREDICTION_LOG)

        # 3-1) ì‘ì—… ë””ë ‰í† ë¦¬/ì½”ë“œ ë£¨íŠ¸ì— ë‚¨ì€ ë™ì¼ê³„ì—´ íŒŒì¼ê¹Œì§€ ì‹¹ ì •ë¦¬(í˜¼ì„  ë°©ì§€)
        suspect_names = {
            "prediction_log.csv", "wrong_predictions.csv",
            "evaluation_audit.csv", "message_log.csv",
            "failure_count.csv", "train_log.csv"
        }
        search_roots = {PERSIST_DIR, LOG_DIR, BASE_DIR, os.getcwd()}
        for root in list(search_roots):
            try:
                if not os.path.isdir(root): continue
                for fn in list(os.listdir(root)):
                    low = fn.lower()
                    if (fn in suspect_names) or low.startswith(("prediction_log", "eval", "message_log", "train_log", "wrong_predictions")):
                        try: os.remove(os.path.join(root, fn))
                        except Exception: pass
            except Exception:
                pass

        # 4) ê´€ìš°/diag ì¶”ì • ìºì‹œ ì „ë¶€ ì œê±° (íŒŒì¼/í´ë”)
        #    - ì´ë¦„ íŒ¨í„´: diag*, e2e*, guan*, ê´€ìš°*
        patterns = ("diag", "e2e", "guan", "ê´€ìš°")
        for root, dirs, files in os.walk(PERSIST_DIR, topdown=False):
            # ë””ë ‰í† ë¦¬ ì œê±°
            for d in list(dirs):
                name = d.lower()
                if name.startswith(patterns) or any(k in d for k in ("ê´€ìš°",)):
                    try: shutil.rmtree(os.path.join(root, d))
                    except Exception: pass
            # íŒŒì¼ ì œê±°
            for f in list(files):
                low = f.lower()
                if low.startswith(patterns) or ("ê´€ìš°" in f):
                    try: os.remove(os.path.join(root, f))
                    except Exception: pass

        # 5) in-memory ìºì‹œ ì´ˆê¸°í™”
        try: _kline_cache.clear()
        except Exception: pass
        try: _feature_cache.clear()
        except Exception: pass

        # 6) í‘œì¤€ ë¡œê·¸ ì¬ìƒì„±(ì •í™•í•œ í—¤ë”) â†’ ìš´ì˜/ê´€ìš°ê°€ ê°™ì€ ì†ŒìŠ¤ë§Œ ì½ë„ë¡ ê°•ì œ
        ensure_prediction_log_exists()
        clear_csv(WRONG_PREDICTIONS, ["timestamp","symbol","strategy","direction","entry_price","target_price","model","predicted_class","top_k","note","success","reason","rate","return_value","label","group_id","model_symbol","model_name","source","volatility","source_exchange"])
        clear_csv(LOG_FILE, ["timestamp","symbol","strategy","model","accuracy","f1","loss","note","source_exchange","status"])
        clear_csv(AUDIT_LOG, ["timestamp","symbol","strategy","result","status"])
        clear_csv(MESSAGE_LOG, ["timestamp","symbol","strategy","message"])
        clear_csv(FAILURE_LOG, ["symbol","strategy","failures"])

        # 7) diag_e2e ëª¨ë“ˆ ë©”ëª¨ë¦¬ ìºì‹œ ê°€ëŠ¥ì„± ëŒ€ë¹„ ê°•ì œ reload
        try:
            import diag_e2e as _diag_mod
            importlib.reload(_diag_mod)
        except Exception:
            pass

        # 8) ğŸ” ì´ˆê¸°í™” ì§í›„ í•™ìŠµ ë£¨í”„ ìë™ ì¬ì‹œì‘ (ê·¸ë£¹0ë¶€í„°, ì¤‘ë³µ ë°©ì§€)
        if start_train_loop_once():
            print("âœ… ì´ˆê¸°í™” ì´í›„ í•™ìŠµ ë£¨í”„ ì¬ì‹œì‘ë¨"); sys.stdout.flush()
        else:
            print("â³ ì´ˆê¸°í™” ì´í›„ì—ë„ í•™ìŠµ ë£¨í”„ê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë¼ ì¬ì‹œì‘ ìƒëµ"); sys.stdout.flush()

        return "âœ… ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", 500

@app.route("/force-fix-prediction_log")
def force_fix_prediction_log():
    """loggerì˜ í‘œì¤€ í—¤ë”ë¡œ prediction_log.csvë¥¼ ì•ˆì „í•˜ê²Œ ì¬ìƒì„±"""
    try:
        from logger import ensure_prediction_log_exists
        if os.path.exists(PREDICTION_LOG):
            os.remove(PREDICTION_LOG)
        ensure_prediction_log_exists()
        return "âœ… prediction_log.csv ê°•ì œ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜: {e}", 500

# ===== ë¡œì»¬ ê°œë°œ ì‹¤í–‰ìš© =====
if __name__ == "__main__":
    try:
        port = int(os.environ.get("PORT", 5000))
    except ValueError:
        raise RuntimeError("âŒ Render í™˜ê²½ë³€ìˆ˜ PORTê°€ ì—†ìŠµë‹ˆë‹¤. Render ì„œë¹„ìŠ¤ íƒ€ì… í™•ì¸ í•„ìš”")

    _init_background_once()
    print(f"âœ… Flask ì„œë²„ ì‹¤í–‰ ì‹œì‘ (PORT={port})")
    app.run(host="0.0.0.0", port=port)
```î¨0î¨‚
