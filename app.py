# app.py â€” single-source, deduped train loop via train.py (ONE concurrent loop only)

from flask import Flask, jsonify, request, Response
from recommend import main
import train, os, threading, datetime, pytz, traceback, sys, shutil, re, time  # time ì‚¬ìš©
import pandas as pd  # â† âœ… ë³„ì¹­ ì„í¬íŠ¸ëŠ” ë‹¨ë… ì¤„ë¡œ ë¶„ë¦¬í•´ì•¼ ë¬¸ë²• ì˜¤ë¥˜ ì—†ìŒ
from apscheduler.schedulers.background import BackgroundScheduler
from telegram_bot import send_message
from predict_trigger import run as trigger_run
from data.utils import SYMBOLS, get_kline_by_strategy
from visualization import generate_visual_report, generate_visuals_for_strategy
from wrong_data_loader import load_training_prediction_data
from predict import evaluate_predictions
from train import train_symbol_group_loop  # (í˜¸í™˜ìš©) ì§ì ‘ í˜¸ì¶œ ë£¨íŠ¸ ë‚¨ê¹€
import maintenance_fix_meta
from logger import ensure_prediction_log_exists

# ğŸ‘‡ ë¬´ê²°ì„± ì ê²€(ìˆìœ¼ë©´ ì‹¤í–‰)
try:
    from integrity_guard import run as _integrity_check
    _integrity_check()
except Exception as e:
    print(f"[WARN] integrity_guard skipped: {e}")

# âœ… ì¢…í•©ì ê²€ ëª¨ë“ˆ(HTML/JSON + ëˆ„ì  í†µê³„ ì§€ì›)
from diag_e2e import run as diag_e2e_run

# âœ… cleanup ëª¨ë“ˆ ê²½ë¡œ ë³´ì •
try:
    from scheduler_cleanup import start_cleanup_scheduler   # [KEEP]
    import safe_cleanup                                      # [KEEP]
    import scheduler_cleanup as _cleanup_mod                 # ğŸ†• stop ì§€ì›ìš© ì°¸ì¡°
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from scheduler_cleanup import start_cleanup_scheduler    # [KEEP]
    import safe_cleanup                                      # [KEEP]
    import scheduler_cleanup as _cleanup_mod                 # ğŸ†•

# ===== ê²½ë¡œ í†µì¼ =====
BASE_DIR   = os.path.dirname(os.path.abspath(__file__))  # â† ë£¨íŠ¸ íƒìƒ‰ìš©(ì´ˆê¸°í™” ê°•í™”ì—ë§Œ ì‚¬ìš©)
PERSIST_DIR= "/persistent"
LOG_DIR    = os.path.join(PERSIST_DIR, "logs")
MODEL_DIR  = os.path.join(PERSIST_DIR, "models")
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(MODEL_DIR, exist_ok=True)  # âœ… ëª¨ë¸ ë””ë ‰í„°ë¦¬ ë³´ì¥

# ===== ê¸€ë¡œë²Œ ë½ ìœ í‹¸(ì „ì²´ ì¼ì‹œì •ì§€) =====
LOCK_DIR   = getattr(safe_cleanup, "LOCK_DIR", os.path.join(PERSIST_DIR, "locks"))
LOCK_PATH  = getattr(safe_cleanup, "LOCK_PATH", os.path.join(LOCK_DIR, "train_or_predict.lock"))
os.makedirs(LOCK_DIR, exist_ok=True)

def _acquire_global_lock():
    try:
        os.makedirs(LOCK_DIR, exist_ok=True)
        with open(LOCK_PATH, "w", encoding="utf-8") as f:
            f.write(f"locked at {datetime.datetime.now().isoformat()}\n")
        print(f"[LOCK] created: {LOCK_PATH}"); sys.stdout.flush()
        return True
    except Exception as e:
        print(f"[LOCK] create failed: {e}"); sys.stdout.flush()
        return False

def _release_global_lock():
    try:
        if os.path.exists(LOCK_PATH):
            os.remove(LOCK_PATH)
            print(f"[LOCK] removed: {LOCK_PATH}"); sys.stdout.flush()
            return True
    except Exception as e:
        print(f"[LOCK] remove failed: {e}"); sys.stdout.flush()
    return False

# ---------- ğŸ†• ê³µí†µ ìœ í‹¸: ì¦‰ì‹œ ê²©ë¦¬-ì™€ì´í”„ ----------
def _quarantine_wipe_persistent():
    """
    /persistent ë‚´ë¶€ë¥¼ í†µì§¸ë¡œ ë¹„ìš°ë˜, ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´
    ë‚´ìš©ì„ /persistent/_trash_<ts>/ ë¡œ **ì›ìì ìœ¼ë¡œ ì´ë™** í›„
    ê¹¨ë—í•œ ê¸°ë³¸ ë””ë ‰í„°ë¦¬ êµ¬ì¡°ë¥¼ ì¬ìƒì„±í•œë‹¤.
    """
    ts = datetime.datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    trash_dir = os.path.join(PERSIST_DIR, f"_trash_{ts}")
    os.makedirs(trash_dir, exist_ok=True)
    keep_names = {os.path.basename(LOCK_DIR)}  # ë½ ë””ë ‰í„°ë¦¬ëŠ” ìœ ì§€

    moved = []
    for name in list(os.listdir(PERSIST_DIR)):
        if name in keep_names:
            continue
        src = os.path.join(PERSIST_DIR, name)
        dst = os.path.join(trash_dir, name)
        try:
            shutil.move(src, dst)
            moved.append(name)
        except Exception as e:
            print(f"âš ï¸ [QWIPE] move ì‹¤íŒ¨: {src} -> {dst} ({e})")
    # ê¹¨ë—í•œ ê¸°ë³¸ êµ¬ì¡° ì¬ìƒì„±
    for d in ["logs", "models", "ssl_models"]:
        os.makedirs(os.path.join(PERSIST_DIR, d), exist_ok=True)

    print(f"ğŸ§¨ [QWIPE] moved_to_trash={moved} trash_dir={trash_dir}"); sys.stdout.flush()
    return trash_dir

# ğŸ†˜ DB/SQLite ì—´ê¸° ì „, ë¬´ì¡°ê±´ 1íšŒ ì‘ê¸‰ ì •ë¦¬(ë½/ë³´í˜¸ì‹œê°„ ë¬´ì‹œ) â†’ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ìœ¼ë¡œ ë³€ê²½
def _async_emergency_purge():
    try:
        # ë¨¼ì € íŠ¸ë˜ì‹œ ë””ë ‰í„°ë¦¬ë“¤ ì œê±° (ì´ì „ ë¦¬ì…‹ ì”ì—¬ë¬¼ ì •ë¦¬)
        try:
            for name in list(os.listdir(PERSIST_DIR)):
                if name.startswith("_trash_"):
                    path = os.path.join(PERSIST_DIR, name)
                    shutil.rmtree(path, ignore_errors=True)
                    print(f"[BOOT-CLEANUP] trashed removed: {name}")
        except Exception as e:
            print(f"âš ï¸ [BOOT-CLEANUP] trash ì œê±° ì‹¤íŒ¨: {e}")

        # í•˜ë“œìº¡ ì´ˆê³¼ ì‹œì—ë§Œ EMERGENCY, ê·¸ ì™¸ì—ëŠ” ì˜µì…˜ì— ë”°ë¼ ì˜¨ê±´ ì •ë¦¬ ë˜ëŠ” ì•„ë¬´ê²ƒë„ ì•ˆ í•¨
        used_gb = safe_cleanup.get_directory_size_gb(PERSIST_DIR)
        hard_cap = getattr(safe_cleanup, "HARD_CAP_GB", 9.6)
        print(f"[BOOT-CLEANUP] used={used_gb:.2f}GB hard_cap={hard_cap:.2f}GB"); sys.stdout.flush()
        if used_gb >= hard_cap:
            print("[EMERGENCY] pre-DB purge ì‹œì‘ (í•˜ë“œìº¡ ì´ˆê³¼)"); sys.stdout.flush()
            safe_cleanup.run_emergency_purge()
            print("[EMERGENCY] pre-DB purge ì™„ë£Œ"); sys.stdout.flush()
        else:
            if os.getenv("CLEANUP_ON_BOOT", "0") == "1":
                print("[BOOT-CLEANUP] CLEANUP_ON_BOOT=1 â†’ ì˜¨ê±´ ì •ë¦¬ ì‹¤í–‰"); sys.stdout.flush()
                safe_cleanup.cleanup_logs_and_models()
                print("[BOOT-CLEANUP] ì™„ë£Œ"); sys.stdout.flush()
            else:
                print("[BOOT-CLEANUP] ë¹„í™œì„±í™”(CLEANUP_ON_BOOT=0)"); sys.stdout.flush()
    except Exception as e:
        print(f"[ê²½ê³ ] pre-DB purge/cleanup ê²°ì • ì‹¤íŒ¨: {e}"); sys.stdout.flush()

threading.Thread(target=_async_emergency_purge, daemon=True).start()

# âœ… prediction_logì€ loggerì™€ ë™ì¼í•œ ìœ„ì¹˜/í—¤ë”ë¡œ ê´€ë¦¬
PREDICTION_LOG = os.path.join(PERSIST_DIR, "prediction_log.csv")

LOG_FILE          = os.path.join(LOG_DIR, "train_log.csv")
WRONG_PREDICTIONS = os.path.join(PERSIST_DIR, "wrong_predictions.csv")
AUDIT_LOG         = os.path.join(LOG_DIR, "evaluation_audit.csv")
MESSAGE_LOG       = os.path.join(LOG_DIR, "message_log.csv")
FAILURE_LOG       = os.path.join(LOG_DIR, "failure_count.csv")

# âœ… ì„œë²„ ì‹œì‘ ì§ì „ ìš©ëŸ‰ ì •ë¦¬ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´)
try:
    if os.getenv("CLEANUP_ON_BOOT", "0") == "1":
        print("[BOOT-CLEANUP] CLEANUP_ON_BOOT=1 â†’ logs/models ì •ë¦¬ ì‹œì‘"); sys.stdout.flush()
        safe_cleanup.cleanup_logs_and_models()
        print("[BOOT-CLEANUP] ì™„ë£Œ"); sys.stdout.flush()
    else:
        print("[BOOT-CLEANUP] ë¹„í™œì„±í™”(CLEANUP_ON_BOOT=0)"); sys.stdout.flush()
except Exception as e:
    print(f"[ê²½ê³ ] startup cleanup ì‹¤íŒ¨: {e}"); sys.stdout.flush()

# âœ… ë¡œê·¸ íŒŒì¼ ì¡´ì¬ ë³´ì¥(ì •í™• í—¤ë”)
try:
    from logger import ensure_train_log_exists
    ensure_train_log_exists()
except Exception:
    pass
ensure_prediction_log_exists()

now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

# -----------------------------
# ìŠ¤ì¼€ì¤„ëŸ¬ (í‰ê°€/íŠ¸ë¦¬ê±°/ë©”íƒ€ë³µêµ¬)
# -----------------------------
_sched = None
def start_scheduler():
    global _sched
    if _sched is not None:
        print("âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì´ë¯¸ ì‹¤í–‰ ì¤‘, ì¬ì‹œì‘ ìƒëµ"); sys.stdout.flush()
        return

    # âœ… ë¦¬ì…‹ ì¤‘ì´ë©´ ì‹œì‘ ê¸ˆì§€
    if os.path.exists(LOCK_PATH):
        print("â¸ï¸ ë¦¬ì…‹ ë½ ê°ì§€ â†’ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì§€ì—°"); sys.stdout.flush()
        return

    print(">>> ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"); sys.stdout.flush()
    sched = BackgroundScheduler(timezone=pytz.timezone("Asia/Seoul"))

    # âœ… ì „ëµë³„ í‰ê°€(30ë¶„ë§ˆë‹¤) â€” ì‹¤í–‰ í•¨ìˆ˜ë¥¼ ì§ì ‘ ë“±ë¡í•´ì•¼ í•¨
    def í‰ê°€ì‘ì—…(strategy):
        def wrapped():
            try:
                ts = now_kst().strftime("%Y-%m-%d %H:%M:%S")
                print(f"[EVAL][{ts}] ì „ëµ={strategy} ì‹œì‘"); sys.stdout.flush()
                evaluate_predictions(lambda sym, _: get_kline_by_strategy(sym, strategy))
            except Exception as e:
                print(f"[EVAL] {strategy} ì‹¤íŒ¨: {e}")
        return wrapped

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        # â›ï¸ ë²„ê·¸ìˆ˜ì •: ì´ì „ ì½”ë“œ(lambda s=strat: í‰ê°€ì‘ì—…(s))ëŠ” callableì„ ë°˜í™˜í•˜ì§€ ì•Šì•„ ì‹¤í–‰ ì•ˆ ë¨
        sched.add_job(í‰ê°€ì‘ì—…(strat), trigger="interval", minutes=30,
                      id=f"eval_{strat}", replace_existing=True)

    # âœ… ì˜ˆì¸¡ íŠ¸ë¦¬ê±°(ë©”íƒ€ì ìš© í¬í•¨) 30ë¶„
    sched.add_job(trigger_run, "interval", minutes=30, id="predict_trigger", replace_existing=True)

    # âœ… ë©”íƒ€ JSON ì •í•©ì„±/ë³µêµ¬ ì£¼ê¸°ì‘ì—… (30ë¶„)
    def meta_fix_job():
        try:
            maintenance_fix_meta.fix_all_meta_json()
        except Exception as e:
            print(f"[META-FIX] ì£¼ê¸°ì‘ì—… ì‹¤íŒ¨: {e}")
    sched.add_job(meta_fix_job, "interval", minutes=30, id="meta_fix", replace_existing=True)

    sched.start()
    _sched = sched
    print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ"); sys.stdout.flush()

def _pause_and_clear_scheduler():
    """ì´ˆê¸°í™” ë™ì•ˆ ìŠ¤ì¼€ì¤„ëŸ¬ ì™„ì „ ì •ì§€(ì‘ì—… ì œê±°)"""
    global _sched
    try:
        if _sched is not None:
            print("[SCHED] pause + remove_all_jobs"); sys.stdout.flush()
            try:
                _sched.pause()
            except Exception:
                pass
            try:
                _sched.remove_all_jobs()
            except Exception:
                pass
            try:
                _sched.shutdown(wait=False)
            except Exception:
                pass
            _sched = None
    except Exception as e:
        print(f"[SCHED] ì •ì§€ ì‹¤íŒ¨: {e}"); sys.stdout.flush()

# ğŸ†• Cleanup ìŠ¤ì¼€ì¤„ëŸ¬ ë° ì ì¬ ìŠ¤ì¼€ì¤„ëŸ¬ê¹Œì§€ ì „ë¶€ ë„ê¸°
def _stop_all_aux_schedulers():
    try:
        # 1) ì•± ë‚´ë¶€ ìŠ¤ì¼€ì¤„ëŸ¬
        _pause_and_clear_scheduler()
    except Exception:
        pass
    try:
        # 2) cleanup ëª¨ë“ˆ ë‚´ ìŠ¤ì¼€ì¤„ëŸ¬
        if hasattr(_cleanup_mod, "stop_cleanup_scheduler"):
            try:
                _cleanup_mod.stop_cleanup_scheduler()
                print("ğŸ§¹ [SCHED] cleanup ìŠ¤ì¼€ì¤„ëŸ¬ stop í˜¸ì¶œ"); sys.stdout.flush()
            except Exception as e:
                print(f"âš ï¸ cleanup stop ì‹¤íŒ¨: {e}"); sys.stdout.flush()
        # fallback: ëª¨ë“ˆ ì† BackgroundScheduler íƒìƒ‰ í›„ shutdown
        for name in dir(_cleanup_mod):
            obj = getattr(_cleanup_mod, name, None)
            if isinstance(obj, BackgroundScheduler):
                try:
                    obj.shutdown(wait=False)
                    print(f"ğŸ§¹ [SCHED] cleanup.{name} shutdown"); sys.stdout.flush()
                except Exception:
                    pass
    except Exception as e:
        print(f"âš ï¸ cleanup ìŠ¤ì¼€ì¤„ëŸ¬ íƒì§€ ì‹¤íŒ¨: {e}"); sys.stdout.flush()

# ===== Flask =====
app = Flask(__name__)
print(">>> Flask ì•± ìƒì„± ì™„ë£Œ"); sys.stdout.flush()

# -----------------------------
# ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™”(í•œ ë²ˆë§Œ)
# -----------------------------
_INIT_DONE = False
_INIT_LOCK = threading.Lock()

def _init_background_once():
    global _INIT_DONE
    with _INIT_LOCK:
        if _INIT_DONE:
            return
        try:
            # ë¦¬ì…‹ ì¤‘ì´ë©´ ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘ ê¸ˆì§€
            if os.path.exists(LOCK_PATH):
                print("â¸ï¸ ë½ ê°ì§€ â†’ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì§€ì—°"); sys.stdout.flush()
                return

            from failure_db import ensure_failure_db
            print(">>> ì„œë²„ ì‹¤í–‰ ì¤€ë¹„")
            ensure_failure_db(); print("âœ… failure_patterns DB ì´ˆê¸°í™” ì™„ë£Œ")

            # í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ â€” train.pyì˜ ë‹¨ì¼ ë£¨í”„ ë³´ì¥ API ì‚¬ìš©
            train.start_train_loop(force_restart=False, sleep_sec=0)
            print("âœ… í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ ì‹œì‘")

            # ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬(ê¸°ë³¸ 30ë¶„)
            start_cleanup_scheduler()
            print("âœ… cleanup ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘")

            # í‰ê°€/íŠ¸ë¦¬ê±°/ë©”íƒ€ë³µêµ¬ ìŠ¤ì¼€ì¤„ëŸ¬
            try:
                start_scheduler()
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")

            # ë©”íƒ€ ë³´ì •(ë¶€íŒ… ì‹œ 1íšŒ ì„  ì‹¤í–‰)
            threading.Thread(target=maintenance_fix_meta.fix_all_meta_json, daemon=True).start()
            print("âœ… maintenance_fix_meta ì´ˆê¸° ì‹¤í–‰ íŠ¸ë¦¬ê±°")

            # í…”ë ˆê·¸ë¨ ì•Œë¦¼
            try:
                send_message("[ì‹œì‘] YOPO ì„œë²„ ì‹¤í–‰ë¨")
                print("âœ… Telegram ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ Telegram ë°œì†¡ ì‹¤íŒ¨: {e}")

            _INIT_DONE = True
            print("âœ… ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

# Flask 3.1 í˜¸í™˜
if hasattr(app, "before_serving"):
    @app.before_serving
    def _boot_once():
        _init_background_once()
else:
    @app.before_request
    def _boot_once_compat():
        if not _INIT_DONE:
            _init_background_once()

# ===== ë¼ìš°íŠ¸ =====
@app.route("/yopo-health")
def yopo_health():
    logs, strategy_html, problems = {}, [], []

    file_map = {"pred": PREDICTION_LOG, "train": LOG_FILE, "audit": AUDIT_LOG, "msg": MESSAGE_LOG}
    for name, path in file_map.items():
        try:
            logs[name] = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
            if "timestamp" in logs[name].columns:
                logs[name] = logs[name][logs[name]["timestamp"].notna()]
        except Exception:
            logs[name] = pd.DataFrame()

    # ëª¨ë¸ íŒŒì¼ íŒŒì‹± (.pt / .ptz / .safetensors ëª¨ë‘)
    try:
        model_files = [f for f in os.listdir(MODEL_DIR)
                       if f.endswith((".pt", ".ptz", ".safetensors"))]
    except Exception:
        model_files = []
    model_info = {}
    for f in model_files:
        m = re.match(r"(.+?)_(ë‹¨ê¸°|ì¤‘ê¸°|ì¥ê¸°)_(lstm|cnn_lstm|transformer)(?:_.*)?\.(pt|ptz|safetensors)$", f)
        if m:
            symbol, strat, mtype, _ext = m.groups()
            model_info.setdefault(strat, {}).setdefault(symbol, set()).add(mtype)

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        try:
            pred  = logs.get("pred",  pd.DataFrame())
            train_log_df = logs.get("train", pd.DataFrame())
            audit = logs.get("audit", pd.DataFrame())
            pred  = pred.query(f"strategy == '{strat}'")  if not pred.empty  else pd.DataFrame()
            train_log_q = train_log_df.query(f"strategy == '{strat}'") if not train_log_df.empty else pd.DataFrame()
            audit = audit.query(f"strategy == '{strat}'") if not audit.empty else pd.DataFrame()

            if not pred.empty and "status" in pred.columns:
                pred["volatility"] = pred["status"].astype(str).str.startswith("v_")
            else:
                pred["volatility"] = False

            try:
                pred["return"] = pd.to_numeric(pred.get("return", pd.Series(dtype=float)), errors="coerce").fillna(0.0)
            except Exception:
                pred["return"] = 0.0

            nvol = pred[~pred["volatility"]] if not pred.empty else pd.DataFrame()
            vol  = pred[ pred["volatility"]] if not pred.empty else pd.DataFrame()

            def stat(df, s):
                try:
                    return int(((not df.empty) and ("status" in df.columns)) and (df["status"] == s).sum()) or 0
                except Exception:
                    return 0

            sn, fn, pn_, fnl = map(lambda s: stat(nvol, s), ["success", "fail", "pending", "failed"])
            sv, fv, pv, fvl = map(lambda s: stat(vol,  s), ["v_success", "v_fail", "pending", "failed"])

            def perf(df, kind="ì¼ë°˜"):
                try:
                    s = stat(df, "v_success" if kind == "ë³€ë™ì„±" else "success")
                    f = stat(df, "v_fail"    if kind == "ë³€ë™ì„±" else "fail")
                    t = s + f
                    avg = float(df["return"].mean()) if ("return" in df) and (df.shape[0] > 0) else 0.0
                    return {"succ": s, "fail": f, "succ_rate": s/t*100 if t else 0,
                            "fail_rate": f/t*100 if t else 0, "r_avg": avg, "total": t}
                except Exception:
                    return {"succ": 0, "fail": 0, "succ_rate": 0, "fail_rate": 0, "r_avg": 0, "total": 0}

            pn, pv_stats = perf(nvol, "ì¼ë°˜"), perf(vol, "ë³€ë™ì„±")

            strat_models = model_info.get(strat, {})
            types = {"lstm": 0, "cnn_lstm": 0, "transformer": 0}
            for mtypes in strat_models.values():
                for t in mtypes: types[t] += 1
            trained_syms = [s for s, t in strat_models.items() if {"lstm","cnn_lstm","transformer"}.issubset(t)]
            try:
                untrained = sorted(set(SYMBOLS) - set(trained_syms))
            except Exception:
                untrained = []

            if sum(types.values()) == 0: problems.append(f"{strat}: ëª¨ë¸ ì—†ìŒ")
            if sn + fn + pn_ + fnl + sv + fv + pv + fvl == 0: problems.append(f"{strat}: ì˜ˆì¸¡ ì—†ìŒ")
            if pn["total"] == 0: problems.append(f"{strat}: í‰ê°€ ë¯¸ì‘ë™")
            if pn["fail_rate"]  > 50: problems.append(f"{strat}: ì¼ë°˜ ì‹¤íŒ¨ìœ¨ {pn['fail_rate']:.1f}%")
            if pv_stats["fail_rate"] > 50: problems.append(f"{strat}: ë³€ë™ì„± ì‹¤íŒ¨ìœ¨ {pv_stats['fail_rate']:.1f}%")

            table = "<i style='color:gray'>ìµœê·¼ ì˜ˆì¸¡ ì—†ìŒ ë˜ëŠ” ì»¬ëŸ¼ ë¶€ì¡±</i>"
            required_cols = {"timestamp","symbol","strategy","direction","return","status"}
            if (pred.shape[0] > 0) and required_cols.issubset(set(pred.columns)):
                recent10 = pred.sort_values("timestamp").tail(10).copy()
                rows = []
                for _, r in recent10.iterrows():
                    rtn = r.get("return", 0.0) or r.get("rate", 0.0)
                    try: rtn_pct = f"{float(rtn) * 100:.2f}%"
                    except: rtn_pct = "0.00%"
                    s = str(r.get('status',''))
                    status_icon = 'âœ…' if s in ['success','v_success'] else 'âŒ' if s in ['fail','v_fail'] else 'â³' if s in ['pending','v_pending'] else 'ğŸ›‘'
                    rows.append(f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('direction','')}</td><td>{rtn_pct}</td><td>{status_icon}</td></tr>")
                table = "<table border='1' style='margin-top:4px'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ë°©í–¥</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th></tr>" + "".join(rows) + "</table>"

            last_train = train_log_q['timestamp'].iloc[-1] if (not train_log_q.empty and 'timestamp' in train_log_q) else 'ì—†ìŒ'
            last_pred  = pred['timestamp'].iloc[-1]  if (not pred.empty and 'timestamp' in pred)  else 'ì—†ìŒ'
            last_audit = audit['timestamp'].iloc[-1] if (not audit.empty and 'timestamp' in audit) else 'ì—†ìŒ'

            info_html = f"""<div style='border:1px solid #aaa;margin:16px 0;padding:10px;font-family:monospace;background:#f8f8f8;'>
<b style='font-size:16px;'>ğŸ“Œ ì „ëµ: {strat}</b><br>
- ëª¨ë¸ ìˆ˜: {sum(types.values())} (lstm={types['lstm']}, cnn={types['cnn_lstm']}, trans={types['transformer']})<br>
- ì‹¬ë³¼ ìˆ˜: {len(SYMBOLS)} | ì™„ì „í•™ìŠµ: {len(trained_syms)} | ë¯¸ì™„ì„±: {len(untrained)}<br>
- ìµœê·¼ í•™ìŠµ: {last_train}<br>
- ìµœê·¼ ì˜ˆì¸¡: {last_pred}<br>
- ìµœê·¼ í‰ê°€: {last_audit}<br>
- ì˜ˆì¸¡ (ì¼ë°˜): {sn + fn + pn_ + fnl}ê±´ (âœ…{sn} âŒ{fn} â³{pn_} ğŸ›‘{fnl})<br>
- ì˜ˆì¸¡ (ë³€ë™ì„±): {sv + fv + pv + fvl}ê±´ (âœ…{sv} âŒ{fv} â³{pv} ğŸ›‘{fvl})<br>
<b style='color:#000088'>ğŸ¯ ì¼ë°˜ ì˜ˆì¸¡</b>: {pn['total']}ê±´ | {pn['succ_rate']:.1f}% / {pn['fail_rate']:.1f}% / {pn['r_avg']:.2f}%<br>
<b style='color:#880000'>ğŸŒªï¸ ë³€ë™ì„± ì˜ˆì¸¡</b>: {pv_stats['total']}ê±´ | {pv_stats['succ_rate']:.1f}% / {pv_stats['fail_rate']:.1f}% / {pv_stats['r_avg']:.2f}%<br>
<b>ğŸ“‹ ìµœê·¼ ì˜ˆì¸¡ 10ê±´</b><br>{table}
</div>"""

            try:
                visual = generate_visuals_for_strategy(strat)
            except Exception as e:
                visual = f"<div style='color:red'>[ì‹œê°í™” ì‹¤íŒ¨: {e}]</div>"

            strategy_html.append(f"<div style='margin-bottom:30px'>{info_html}<div style='margin:20px 0'>{visual}</div><hr></div>")
        except Exception as e:
            strategy_html.append(f"<div style='color:red;'>âŒ {strat} ì‹¤íŒ¨: {type(e).__name__} â†’ {e}</div>")

    status = "ğŸŸ¢ ì „ì²´ ì „ëµ ì •ìƒ ì‘ë™ ì¤‘" if not problems else "ğŸ”´ ì¢…í•©ì§„ë‹¨ ìš”ì•½:<br>" + "<br>".join(problems)
    return f"<div style='font-family:monospace;line-height:1.6;font-size:15px;'><b>{status}</b><hr>" + "".join(strategy_html) + "</div>"

@app.route("/")
def index(): return "Yopo server is running"

@app.route("/ping")
def ping(): return "pong"

# âœ… ì¢…í•© ì ê²€ ë¼ìš°íŠ¸ (HTML/JSON + ëˆ„ì  ì˜µì…˜)
@app.route("/diag/e2e")
def diag_e2e():
    """
    ì‚¬ìš©ë²•:
      /diag/e2e?view=json         â†’ JSON(ê¸°ë³¸)
      /diag/e2e?view=html         â†’ í•œê¸€ HTML ë¦¬í¬íŠ¸
      /diag/e2e?group=0           â†’ ê·¸ë£¹ ì¸ë±ìŠ¤ ê¸°ì¤€ í†µê³„
      /diag/e2e?cum=1             â†’ ëˆ„ì  í†µê³„(ë©”ëª¨ë¦¬ ì•ˆì „ ìŠ¤íŠ¸ë¦¬ë°)
      /diag/e2e?symbols=BTCUSDT,ETHUSDT â†’ íŠ¹ì • ì‹¬ë³¼ë§Œ ì§‘ê³„
    """
    try:
        group = int(request.args.get("group", "-1"))
        view = request.args.get("view", "json").lower()
        cumulative = request.args.get("cum", "0") == "1"
        symbols = request.args.get("symbols")

        out = diag_e2e_run(group=group, view=view, cumulative=cumulative, symbols=symbols)

        if isinstance(out, Response):
            return out
        if view == "html":
            return Response(out if isinstance(out, str) else str(out),
                            mimetype="text/html; charset=utf-8")
        return jsonify(out)
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route("/run")
def run():
    try:
        if os.path.exists(LOCK_PATH):
            return "â¸ï¸ ì´ˆê¸°í™” ì¤‘: ì˜ˆì¸¡ ì‹œì‘ ì°¨ë‹¨ë¨", 423
        print("[RUN] ì „ëµë³„ ì˜ˆì¸¡ ì‹¤í–‰"); sys.stdout.flush()
        for strategy in ["ë‹¨ê¸°","ì¤‘ê¸°","ì¥ê¸°"]:
            main(strategy, force=True)
        return "Recommendation started"
    except Exception as e:
        traceback.print_exc(); return f"Error: {e}", 500

@app.route("/train-now")
def train_now():
    """ì¿¼ë¦¬ force=1ì´ë©´ ê°•ì œ ì¬ê°€ë™, ì•„ë‹ˆë©´ ì•ˆì „ ì‹œì‘(ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ìŠ¤í‚µ ë©”ì‹œì§€)."""
    try:
        # ë¦¬ì…‹ ì¤‘ì´ë©´ ì‹œì‘ ê¸ˆì§€
        if os.path.exists(LOCK_PATH):
            return "â¸ï¸ ì´ˆê¸°í™” ì¤‘: í•™ìŠµ ì‹œì‘ ì°¨ë‹¨ë¨", 423
        force = request.args.get("force", "0") == "1"
        started = train.start_train_loop(force_restart=force, sleep_sec=0)
        if started:
            return "âœ… ì „ì²´ ê·¸ë£¹ í•™ìŠµ ë£¨í”„ ì‹œì‘ë¨ (ë°±ê·¸ë¼ìš´ë“œ)"
        else:
            return "â³ ì´ë¯¸ ì‹¤í–‰ ì¤‘ (ì¬ê°€ë™ ìƒëµ)" if not force else "â³ ì¬ê°€ë™ ì‹œë„í–ˆìœ¼ë‚˜ ê¸°ì¡´ ë£¨í”„ ìœ ì§€ë¨"
    except Exception as e:
        return f"í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/train-log")
def train_log():
    try:
        if not os.path.exists(LOG_FILE): return "í•™ìŠµ ë¡œê·¸ ì—†ìŒ"
        df = pd.read_csv(LOG_FILE, encoding="utf-8-sig", on_bad_lines="skip")
        if df.empty or df.shape[1] == 0: return "í•™ìŠµ ê¸°ë¡ ì—†ìŒ"
        return "<pre>" + df.to_csv(index=False) + "</pre>"
    except Exception as e:
        return f"ì½ê¸° ì˜¤ë¥˜: {e}", 500

@app.route("/models")
def list_models():
    try:
        if not os.path.exists(MODEL_DIR): return "models í´ë” ì—†ìŒ"
        files = os.listdir(MODEL_DIR)
        return "<pre>" + "\n".join(files) + "</pre>" if files else "models í´ë” ë¹„ì–´ ìˆìŒ"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 500

@app.route("/check-log-full")
def check_log_full():
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)
        return jsonify(latest.to_dict(orient="records"))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-log")
def check_log():
    try:
        if not os.path.exists(PREDICTION_LOG):
            return jsonify({"error": "prediction_log.csv ì—†ìŒ"})
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        if "timestamp" not in df:
            return jsonify([])
        df = df[df["timestamp"].notna()]
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-eval-log")
def check_eval_log():
    try:
        path = PREDICTION_LOG
        if not os.path.exists(path): return "ì˜ˆì¸¡ ë¡œê·¸ ì—†ìŒ"

        df = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
        if "status" not in df.columns: return "ìƒíƒœ ì»¬ëŸ¼ ì—†ìŒ"

        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)

        def status_icon(s):
            return {"success":"âœ…","fail":"âŒ","v_success":"âœ…","v_fail":"âŒ","pending":"â³","v_pending":"â³"}.get(s,"â“")

        html = "<table border='1'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ì „ëµ</th><th>ëª¨ë¸</th><th>ì˜ˆì¸¡</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th><th>ì‚¬ìœ </th></tr>"
        for _, r in latest.iterrows():
            icon = status_icon(r.get("status",""))
            html += f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('strategy','')}</td><td>{r.get('model','')}</td><td>{r.get('direction','')}</td><td>{float(r.get('return',0) or 0):.4f}</td><td>{icon}</td><td>{r.get('reason','')}</td></tr>"
        html += "</table>"
        return html
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜: {e}", 500

from data.utils import SYMBOL_GROUPS

@app.route("/train-symbols")
def train_symbols():
    try:
        if os.path.exists(LOCK_PATH):
            return f"â¸ï¸ ì´ˆê¸°í™” ì¤‘: ê·¸ë£¹ í•™ìŠµ ì‹œì‘ ì°¨ë‹¨ë¨", 423

        group_idx = int(request.args.get("group", -1))
        force = request.args.get("force", "0") == "1"
        if group_idx < 0 or group_idx >= len(SYMBOL_GROUPS):
            return f"âŒ ì˜ëª»ëœ ê·¸ë£¹ ë²ˆí˜¸: {group_idx}", 400
        group_symbols = SYMBOL_GROUPS[group_idx]

        # ë‹¨ì¼ ë£¨í”„ ë³´ì¥
        if train.is_loop_running():
            if not force:
                return "ğŸš« ì´ë¯¸ ë©”ì¸ í•™ìŠµ ë£¨í”„ ì‹¤í–‰ ì¤‘ (force=1 ë¡œ ê°•ì œ êµì²´ ê°€ëŠ¥)", 409
            train.stop_train_loop(timeout=45)

        print(f"ğŸš€ ê·¸ë£¹ í•™ìŠµ ìš”ì²­ë¨ â†’ ê·¸ë£¹ #{group_idx} | ì‹¬ë³¼: {group_symbols}")
        threading.Thread(target=lambda: train.train_models(group_symbols), daemon=True).start()
        return f"âœ… ê·¸ë£¹ #{group_idx} í•™ìŠµ ì‹œì‘ë¨ (ë‹¨ì¼ ë£¨í”„ ë³´ì¥)"
    except Exception as e:
        traceback.print_exc(); return f"âŒ ì˜¤ë¥˜: {e}", 500

@app.route("/train-symbols", methods=["POST"])
def train_selected_symbols():
    try:
        if os.path.exists(LOCK_PATH):
            return "â¸ï¸ ì´ˆê¸°í™” ì¤‘: ì„ íƒ í•™ìŠµ ì‹œì‘ ì°¨ë‹¨ë¨", 423

        body = request.get_json(silent=True) or {}
        symbols = body.get("symbols", [])
        force = bool(body.get("force", False))
        if not isinstance(symbols, list) or not symbols:
            return "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ symbols ë¦¬ìŠ¤íŠ¸", 400

        if train.is_loop_running():
            if not force:
                return "ğŸš« ì´ë¯¸ ë©”ì¸ í•™ìŠµ ë£¨í”„ ì‹¤í–‰ ì¤‘ (force=true ë¡œ ê°•ì œ êµì²´ ê°€ëŠ¥)", 409
            train.stop_train_loop(timeout=45)

        threading.Thread(target=lambda: train.train_models(symbols), daemon=True).start()
        return f"âœ… {len(symbols)}ê°œ ì‹¬ë³¼ í•™ìŠµ ì‹œì‘ë¨ (ë‹¨ì¼ ë£¨í”„ ë³´ì¥)"
    except Exception as e:
        return f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/meta-fix-now")
def meta_fix_now():
    try:
        maintenance_fix_meta.fix_all_meta_json()
        return "âœ… meta.json ì ê²€/ë³µêµ¬ ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì‹¤íŒ¨: {e}", 500

# =========================
# âœ… ì´ˆê¸°í™”(ë¹„ë™ê¸°): GET/POST/íŒ¨ìŠ¤/ì¿¼ë¦¬ ëª¨ë‘ í—ˆìš© + ì¦‰ì‹œ 200 ì‘ë‹µ
# =========================
@app.route("/reset-all", methods=["GET","POST"])
@app.route("/reset-all/<key>", methods=["GET","POST"])
def reset_all(key=None):
    # í‚¤ ì¶”ì¶œ (path â†’ query â†’ json ìˆœ)
    req_key = key or request.args.get("key") or (request.json.get("key") if request.is_json else None)
    if req_key != "3572":
        print(f"[RESET] ì¸ì¦ ì‹¤íŒ¨ from {request.remote_addr} path={request.path}"); sys.stdout.flush()
        return "âŒ ì¸ì¦ ì‹¤íŒ¨", 403

    # ì¦‰ì‹œ ë¡œê·¸
    ua = request.headers.get("User-Agent", "-")
    ip = request.headers.get("X-Forwarded-For", request.remote_addr)
    print(f"[RESET] ìš”ì²­ ìˆ˜ì‹  from {ip} UA={ua}"); sys.stdout.flush()

    # ğŸ›¡ï¸ ì›Œì¹˜ë…: ì´ˆê¸°í™”ê°€ ì–´ë–¤ ì´ìœ ë¡œë“  ê±¸ë ¤ë„ ë°˜ë“œì‹œ ë‚´ë ¤ê°€ë„ë¡ íƒ€ì´ë¨¸ ë¬´ì¥
    def _arm_reset_watchdog(seconds: int):
        seconds = max(30, int(seconds))
        def _kill():
            print(f"ğŸ›‘ [WATCHDOG] reset watchdog fired after {seconds}s â†’ os._exit(0)"); sys.stdout.flush()
            try:
                _release_global_lock()
            finally:
                os._exit(0)
        t = threading.Timer(seconds, _kill)
        t.daemon = True
        t.start()
        return t

    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì •ì˜
    def _do_reset_work():
        # ---- í™˜ê²½ì„¤ì •(ì‹œê°„) ë¨¼ì € íŒŒì‹±í•˜ê³  ì›Œì¹˜ë… ë¬´ì¥ ----
        stop_timeout = int(os.getenv("RESET_STOP_TIMEOUT", "30"))
        max_wait     = int(os.getenv("RESET_MAX_WAIT_SEC", "600"))
        poll_sec     = max(1, int(os.getenv("RESET_POLL_SEC", "3")))
        # ì›Œì¹˜ë…ì€ ì „ì²´ ì˜ˆìƒ ì‹œê°„ë³´ë‹¤ ì¡°ê¸ˆ ê¸¸ê²Œ(ì—¬ìœ  60s)
        watchdog_sec = int(os.getenv("RESET_WATCHDOG_SEC", str(stop_timeout + max_wait + 60)))
        _wd = _arm_reset_watchdog(watchdog_sec)

        try:
            from data.utils import _kline_cache, _feature_cache
            import importlib

            # ===== 0) ê¸€ë¡œë²Œ ë½ ON + ìŠ¤ì¼€ì¤„ëŸ¬ ì™„ì „ì •ì§€ =====
            _acquire_global_lock()
            _stop_all_aux_schedulers()  # ğŸ†• ë‚´ë¶€/ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬ ëª¨ë‘ ì •ì§€

            # ê²½ë¡œ ìƒìˆ˜ ë¡œì»¬ ë°”ì¸ë”©
            BASE = BASE_DIR
            PERSIST = PERSIST_DIR
            LOGS = LOG_DIR
            MODELS = MODEL_DIR
            PRED_LOG = PREDICTION_LOG
            WRONG = WRONG_PREDICTIONS
            AUDIT = AUDIT_LOG
            MSG = MESSAGE_LOG
            FAIL = FAILURE_LOG

            def clear_csv(f, h):
                os.makedirs(os.path.dirname(f), exist_ok=True)
                with open(f, "w", newline="", encoding="utf-8-sig") as wf:
                    wf.write(",".join(h) + "\n")

            print("[RESET] ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹œì‘"); sys.stdout.flush()

            # 1) í•™ìŠµ ë£¨í”„ ì •ì§€
            try:
                if hasattr(train, "request_stop"):
                    train.request_stop()
            except Exception:
                pass

            stopped = False
            try:
                print(f"[RESET] í•™ìŠµ ë£¨í”„ ì •ì§€ ì‹œë„(timeout={stop_timeout}s)"); sys.stdout.flush()
                stopped = train.stop_train_loop(timeout=stop_timeout)
            except Exception as e:
                print(f"âš ï¸ [RESET] stop_train_loop ì˜ˆì™¸: {e}"); sys.stdout.flush()
            print(f"[RESET] stop_train_loop ê²°ê³¼: {stopped}"); sys.stdout.flush()

            # ğŸ†• 1-1) ë¯¸ì •ì§€ ì‹œ í´ë§ ëŒ€ê¸°(ìµœëŒ€ max_wait)
            if not stopped:
                t0 = time.time()
                print(f"[RESET] ì •ì§€ ëŒ€ê¸° ì‹œì‘â€¦ ìµœëŒ€ {max_wait}s (í´ë§ {poll_sec}s)"); sys.stdout.flush()
                while time.time() - t0 < max_wait:
                    try:
                        if hasattr(train, "is_loop_running"):
                            running = bool(train.is_loop_running())
                            if not running:
                                stopped = True
                                break
                    except Exception:
                        pass
                    # ì§§ì€ ì¬ì‹œë„
                    try:
                        if hasattr(train, "stop_train_loop") and train.stop_train_loop(timeout=2):
                            stopped = True
                            break
                    except Exception:
                        pass
                    time.sleep(poll_sec)
                print(f"[RESET] ì •ì§€ ëŒ€ê¸° ì™„ë£Œ â†’ stopped={stopped}"); sys.stdout.flush()

            # ğŸ†• 1-2) ê·¸ë˜ë„ ì•ˆ ë©ˆì¶”ë©´ **ê²©ë¦¬-ì™€ì´í”„ í›„ í•˜ë“œ ì¢…ë£Œ**
            if not stopped:
                print("ğŸ›‘ [RESET] ë£¨í”„ê°€ ì¢…ë£Œë˜ì§€ ì•ŠìŒ â†’ QWIPE í›„ í•˜ë“œ ì¢…ë£Œ(os._exit)"); sys.stdout.flush()
                try:
                    _quarantine_wipe_persistent()
                except Exception as e:
                    print(f"âš ï¸ [RESET] QWIPE ì‹¤íŒ¨: {e}")
                try:
                    _release_global_lock()
                finally:
                    try:
                        _wd.cancel()
                    except Exception:
                        pass
                    os._exit(0)  # í”„ë¡œì„¸ìŠ¤ ì¦‰ì‹œ ì¢…ë£Œ â†’ í”Œë«í¼ì´ ì¬ê¸°ë™

            # 2) ì§„í–‰ìƒíƒœ ë§ˆì»¤ ì œê±°
            try:
                done_path = os.path.join(PERSIST, "train_done.json")
                if os.path.exists(done_path): os.remove(done_path)
            except Exception:
                pass

            # 3) íŒŒì¼ ì •ë¦¬ â€” ë¬´ì¡°ê±´ í’€ì™€ì´í”„(ssl_models í¬í•¨)
            try:
                # ëŒ€ìƒ ë””ë ‰í„°ë¦¬ ì „ë¶€ ì œê±°
                for d in [MODELS, LOGS, os.path.join(PERSIST, "ssl_models")]:
                    if os.path.exists(d):
                        shutil.rmtree(d, ignore_errors=True)
                    os.makedirs(d, exist_ok=True)

                # ë£¨íŠ¸ ì§ì† íŒŒì¼/ì”ì—¬ë¬¼ ì „ë¶€ ì œê±° (ë½/ì•±í•„ìˆ˜ ì œì™¸)
                keep = {os.path.basename(LOCK_DIR)}
                for name in list(os.listdir(PERSIST)):
                    p = os.path.join(PERSIST, name)
                    if name in keep:
                        continue
                    if os.path.isdir(p):
                        # ìœ„ì—ì„œ ë§Œë“  ê¸°ë³¸ ë””ë ‰í„°ë¦¬( logs / models / ssl_models )ëŠ” ìœ ì§€
                        if name not in {"logs", "models", "ssl_models"}:
                            shutil.rmtree(p, ignore_errors=True)
                    else:
                        try:
                            os.remove(p)
                        except Exception:
                            pass

                # ì˜ì‹¬ CSV/DB/ìºì‹œ ì „ë¶€ ì œê±°(ì•ˆì „ë§)
                suspect_prefixes = ("prediction_log", "eval", "message_log", "train_log",
                                    "wrong_predictions", "evaluation_audit", "failure_count",
                                    "diag", "e2e", "guan", "ê´€ìš°")
                for root, dirs, files in os.walk(PERSIST, topdown=False):
                    for f in files:
                        low = f.lower()
                        if low.endswith((".csv", ".db", ".json", ".txt")) or low.startswith(suspect_prefixes):
                            try: os.remove(os.path.join(root, f))
                            except Exception: pass
                    for d in dirs:
                        low = d.lower()
                        if low.startswith(suspect_prefixes) or ("ê´€ìš°" in d):
                            try: shutil.rmtree(os.path.join(root, d), ignore_errors=True)
                            except Exception: pass
            except Exception as e:
                print(f"âš ï¸ [RESET] í’€ì™€ì´í”„ ì˜ˆì™¸: {e}"); sys.stdout.flush()

            # 4) in-memory ìºì‹œ ì´ˆê¸°í™”
            try: _kline_cache.clear()
            except Exception: pass
            try: _feature_cache.clear()
            except Exception: pass

            # 5) í‘œì¤€ ë¡œê·¸ ì¬ìƒì„±(ì •í™• í—¤ë”)
            try:
                ensure_prediction_log_exists()
                def clear_csv(f, h):
                    os.makedirs(os.path.dirname(f), exist_ok=True)
                    with open(f, "w", newline="", encoding="utf-8-sig") as wf:
                        wf.write(",".join(h) + "\n")
                clear_csv(WRONG, ["timestamp","symbol","strategy","direction","entry_price","target_price","model","predicted_class","top_k","note","success","reason","rate","return_value","label","group_id","model_symbol","model_name","source","volatility","source_exchange"])
                clear_csv(LOG_FILE, ["timestamp","symbol","strategy","model","accuracy","f1","loss","note","source_exchange","status"])
                clear_csv(AUDIT, ["timestamp","symbol","strategy","result","status"])
                clear_csv(MESSAGE_LOG, ["timestamp","symbol","strategy","message"])
                clear_csv(FAILURE_LOG, ["symbol","strategy","failures"])
            except Exception as e:
                print(f"âš ï¸ [RESET] ë¡œê·¸ ì¬ìƒì„± ì˜ˆì™¸: {e}"); sys.stdout.flush()

            # 6) diag_e2e reload
            try:
                import diag_e2e as _diag_mod
                import importlib as _imp
                _imp.reload(_diag_mod)
            except Exception:
                pass

            # 7) ë©”íƒ€ ë³´ì • 1íšŒ
            try:
                maintenance_fix_meta.fix_all_meta_json()
            except Exception as e:
                print(f"[RESET] meta ë³´ì • ì‹¤íŒ¨: {e}")

            # âœ… ì •ë¦¬ ì™„ë£Œ â†’ ë½ í•´ì œ í›„ ì¦‰ì‹œ ì¢…ë£Œ(í”Œë«í¼ì´ ì¬ë¶€íŒ…)
            print("ğŸ”š [RESET] ì •ë¦¬ ì™„ë£Œ â†’ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ(os._exit)ë¡œ ì¬ë¶€íŒ… ì§„í–‰"); sys.stdout.flush()
            _release_global_lock()
            try:
                _wd.cancel()
            except Exception:
                pass
            os._exit(0)

        except Exception as e:
            print(f"âŒ [RESET] ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì˜ˆì™¸: {e}"); sys.stdout.flush()
        finally:
            # (ì´ì¤‘ í˜¸ì¶œì´ì–´ë„ ì•ˆì „) í˜¹ì‹œ ëª» í’€ì—ˆìœ¼ë©´ í’€ê¸°
            _release_global_lock()

    # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ í›„ ì¦‰ì‹œ ì‘ë‹µ
    threading.Thread(target=_do_reset_work, daemon=True).start()
    return Response(
        "âœ… ì´ˆê¸°í™” ìš”ì²­ ì ‘ìˆ˜ë¨. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì •ì§€â†’ì •ë¦¬ í›„ ì„œë²„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¬ì‹œì‘í•©ë‹ˆë‹¤.\n"
        "ë¡œê·¸ì—ì„œ [RESET]/[SCHED]/[LOCK]/[QWIPE] íƒœê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.",
        mimetype="text/plain; charset=utf-8"
    )

# í•˜ì´í”ˆ/ì–¸ë”ìŠ¤ì½”ì–´ ëª¨ë‘ í—ˆìš©
@app.route("/force-fix-prediction_log")
@app.route("/force-fix-prediction-log")
def force_fix_prediction_log():
    """loggerì˜ í‘œì¤€ í—¤ë”ë¡œ prediction_log.csvë¥¼ ì•ˆì „í•˜ê²Œ ì¬ìƒì„±"""
    try:
        from logger import ensure_prediction_log_exists
        if os.path.exists(PREDICTION_LOG):
            os.remove(PREDICTION_LOG)
        ensure_prediction_log_exists()
        print("[FORCE-FIX] prediction_log.csv ì¬ìƒì„± ì™„ë£Œ"); sys.stdout.flush()
        return "âœ… prediction_log.csv ê°•ì œ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜: {e}", 500

# ===== ë¡œì»¬ ê°œë°œ ì‹¤í–‰ìš© =====
if __name__ == "__main__":
    try:
        port = int(os.environ.get("PORT", 5000))
    except ValueError:
        raise RuntimeError("âŒ Render í™˜ê²½ë³€ìˆ˜ PORTê°€ ì—†ìŠµë‹ˆë‹¤. Render ì„œë¹„ìŠ¤ íƒ€ì… í™•ì¸ í•„ìš”")

    _init_background_once()
    print(f"âœ… Flask ì„œë²„ ì‹¤í–‰ ì‹œì‘ (PORT={port})")
    app.run(host="0.0.0.0", port=port)
