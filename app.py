# === app.py ìµœì¢…ë³¸ ===
from flask import Flask, jsonify, request
from recommend import main
import train, os, threading, datetime, pandas as pd, pytz, traceback, sys, shutil, csv, re
from apscheduler.schedulers.background import BackgroundScheduler
from telegram_bot import send_message
from predict_test import test_all_predictions
from predict_trigger import run as trigger_run
from data.utils import SYMBOLS, get_kline_by_strategy
from visualization import generate_visual_report, generate_visuals_for_strategy
from wrong_data_loader import load_training_prediction_data
from predict import evaluate_predictions
from train import train_symbol_group_loop
import maintenance_fix_meta
from logger import ensure_prediction_log_exists

# âœ… cleanup ëª¨ë“ˆ ê²½ë¡œ ë³´ì • (src/ì—ì„œ ì‹¤í–‰í•˜ë“ , ë£¨íŠ¸ì—ì„œ ì‹¤í–‰í•˜ë“  ë™ì‘)
try:
    from scheduler_cleanup import start_cleanup_scheduler   # [ADD]
    import safe_cleanup                                      # [ADD]
except ImportError:
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from scheduler_cleanup import start_cleanup_scheduler    # [ADD]
    import safe_cleanup                                      # [ADD]

# âœ… ì„œë²„ ì‹œì‘ ì§ì „ ìš©ëŸ‰ ì •ë¦¬ (ì˜ˆì™¸ ê°€ë“œ)
try:
    safe_cleanup.cleanup_logs_and_models()
except Exception as e:
    print(f"[ê²½ê³ ] startup cleanup ì‹¤íŒ¨: {e}")

# ===== ê²½ë¡œ í†µì¼ =====
PERSIST_DIR = "/persistent"
LOG_DIR = os.path.join(PERSIST_DIR, "logs")
MODEL_DIR = os.path.join(PERSIST_DIR, "models")
os.makedirs(LOG_DIR, exist_ok=True)

# âœ… prediction_logì€ loggerì™€ ë™ì¼í•œ ìœ„ì¹˜/í—¤ë”ë¡œ ê´€ë¦¬ (logs/ì•„ë‹˜!)
PREDICTION_LOG = os.path.join(PERSIST_DIR, "prediction_log.csv")

LOG_FILE         = os.path.join(LOG_DIR, "train_log.csv")
WRONG_PREDICTIONS= os.path.join(PERSIST_DIR, "wrong_predictions.csv")
AUDIT_LOG        = os.path.join(LOG_DIR, "evaluation_audit.csv")
MESSAGE_LOG      = os.path.join(LOG_DIR, "message_log.csv")
FAILURE_LOG      = os.path.join(LOG_DIR, "failure_count.csv")

# âœ… ë¡œê·¸ íŒŒì¼ ì¡´ì¬ ë³´ì¥(ì •í™• í—¤ë”)
ensure_prediction_log_exists()

now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

def start_scheduler():
    print(">>> ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"); sys.stdout.flush()
    sched = BackgroundScheduler(timezone=pytz.timezone("Asia/Seoul"))

    # âœ… ì „ëµë³„ í‰ê°€(30ë¶„ë§ˆë‹¤)
    def í‰ê°€ì‘ì—…(strategy):
        def wrapped():
            evaluate_predictions(lambda sym, _: get_kline_by_strategy(sym, strategy))
        threading.Thread(target=wrapped, daemon=True).start()

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        sched.add_job(lambda s=strat: í‰ê°€ì‘ì—…(s), trigger="interval", minutes=30)

    # âœ… ê¸°íƒ€ íŠ¸ë¦¬ê±°
    sched.add_job(trigger_run, "interval", minutes=30)
    sched.start()

# ===== Flask =====
app = Flask(__name__)
print(">>> Flask ì•± ìƒì„± ì™„ë£Œ"); sys.stdout.flush()

@app.route("/yopo-health")
def yopo_health():
    percent = lambda v: f"{v:.1f}%" if pd.notna(v) else "0.0%"
    logs, strategy_html, problems = {}, [], []

    file_map = {"pred": PREDICTION_LOG, "train": LOG_FILE, "audit": AUDIT_LOG, "msg": MESSAGE_LOG}
    for name, path in file_map.items():
        try:
            logs[name] = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
            logs[name] = logs[name][logs[name]["timestamp"].notna()] if "timestamp" in logs[name] else logs[name]
        except:
            logs[name] = pd.DataFrame()

    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pt")]
    model_info = {}
    for f in model_files:
        # âœ… ì ‘ë¯¸ì‚¬ í—ˆìš© ì •ê·œì‹ìœ¼ë¡œ ë³´ì •
        m = re.match(r"(.+?)_(ë‹¨ê¸°|ì¤‘ê¸°|ì¥ê¸°)_(lstm|cnn_lstm|transformer)(?:_.*)?\.pt$", f)
        if m:
            symbol, strat, mtype = m.groups()
            model_info.setdefault(strat, {}).setdefault(symbol, set()).add(mtype)

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        try:
            pred, train, audit = logs["pred"], logs["train"], logs["audit"]
            pred  = pred.query(f"strategy == '{strat}'")  if not pred.empty  else pd.DataFrame()
            train = train.query(f"strategy == '{strat}'") if not train.empty else pd.DataFrame()
            audit = audit.query(f"strategy == '{strat}'") if not audit.empty else pd.DataFrame()

            if "status" in pred.columns:
                pred["volatility"] = pred["status"].astype(str).str.startswith("v_")
            else:
                pred["volatility"] = False

            pred["return"] = pd.to_numeric(pred.get("return", pd.Series()), errors="coerce").fillna(0)
            nvol = pred[~pred["volatility"]] if not pred.empty else pd.DataFrame()
            vol  = pred[ pred["volatility"]] if not pred.empty else pd.DataFrame()

            stat = lambda df, s: len(df[df["status"] == s]) if not df.empty and "status" in df.columns else 0
            sn, fn, pn_, fnl = map(lambda s: stat(nvol, s), ["success", "fail", "pending", "failed"])
            sv, fv, pv, fvl = map(lambda s: stat(vol,  s), ["v_success", "v_fail", "pending", "failed"])

            def perf(df, kind="ì¼ë°˜"):
                try:
                    s = stat(df, "v_success" if kind == "ë³€ë™ì„±" else "success")
                    f = stat(df, "v_fail"    if kind == "ë³€ë™ì„±" else "fail")
                    t = s + f
                    avg = df["return"].mean()
                    return {"succ": s, "fail": f, "succ_rate": s/t*100 if t else 0,
                            "fail_rate": f/t*100 if t else 0, "r_avg": avg if pd.notna(avg) else 0, "total": t}
                except:
                    return {"succ": 0, "fail": 0, "succ_rate": 0, "fail_rate": 0, "r_avg": 0, "total": 0}

            pn, pv_stats = perf(nvol, "ì¼ë°˜"), perf(vol, "ë³€ë™ì„±")

            strat_models = model_info.get(strat, {})
            types = {"lstm": 0, "cnn_lstm": 0, "transformer": 0}
            for mtypes in strat_models.values():
                for t in mtypes: types[t] += 1
            trained_syms = [s for s, t in strat_models.items() if {"lstm","cnn_lstm","transformer"}.issubset(t)]
            untrained = sorted(set(SYMBOLS) - set(trained_syms))

            if sum(types.values()) == 0: problems.append(f"{strat}: ëª¨ë¸ ì—†ìŒ")
            if sn + fn + pn_ + fnl + sv + fv + pv + fvl == 0: problems.append(f"{strat}: ì˜ˆì¸¡ ì—†ìŒ")
            if pn["succ"] + pn["fail"] == 0: problems.append(f"{strat}: í‰ê°€ ë¯¸ì‘ë™")
            if pn["fail_rate"]  > 50: problems.append(f"{strat}: ì¼ë°˜ ì‹¤íŒ¨ìœ¨ {pn['fail_rate']:.1f}%")
            if pv_stats["fail_rate"] > 50: problems.append(f"{strat}: ë³€ë™ì„± ì‹¤íŒ¨ìœ¨ {pv_stats['fail_rate']:.1f}%")

            table = "<i style='color:gray'>ìµœê·¼ ì˜ˆì¸¡ ì—†ìŒ ë˜ëŠ” ì»¬ëŸ¼ ë¶€ì¡±</i>"
            required_cols = {"timestamp","symbol","direction","return","rate","status"}
            if pred.shape[0] > 0 and required_cols.issubset(set(pred.columns)):
                recent10 = pred.sort_values("timestamp").tail(10).copy()
                rows = []
                for _, r in recent10.iterrows():
                    rtn = r.get("return", 0.0) or r.get("rate", 0.0)
                    try: rtn_pct = f"{float(rtn) * 100:.2f}%"
                    except: rtn_pct = "0.00%"
                    status_icon = 'âœ…' if r['status'] in ['success','v_success'] else 'âŒ' if r['status'] in ['fail','v_fail'] else 'â³' if r['status']=='pending' else 'ğŸ›‘'
                    rows.append(f"<tr><td>{r['timestamp']}</td><td>{r['symbol']}</td><td>{r['direction']}</td><td>{rtn_pct}</td><td>{status_icon}</td></tr>")
                table = "<table border='1' style='margin-top:4px'><tr><th>ì‹œê°</th><th>ì¢…ëª©</th><th>ë°©í–¥</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th></tr>" + "".join(rows) + "</table>"

            info_html = f"""<div style='border:1px solid #aaa;margin:16px 0;padding:10px;font-family:monospace;background:#f8f8f8;'>
<b style='font-size:16px;'>ğŸ“Œ ì „ëµ: {strat}</b><br>
- ëª¨ë¸ ìˆ˜: {sum(types.values())} (lstm={types['lstm']}, cnn={types['cnn_lstm']}, trans={types['transformer']})<br>
- ì‹¬ë³¼ ìˆ˜: {len(SYMBOLS)} | ì™„ì „í•™ìŠµ: {len(trained_syms)} | ë¯¸ì™„ì„±: {len(untrained)}<br>
- ìµœê·¼ í•™ìŠµ: {train['timestamp'].iloc[-1] if not train.empty else 'ì—†ìŒ'}<br>
- ìµœê·¼ ì˜ˆì¸¡: {pred['timestamp'].iloc[-1] if not pred.empty else 'ì—†ìŒ'}<br>
- ìµœê·¼ í‰ê°€: {audit['timestamp'].iloc[-1] if not audit.empty else 'ì—†ìŒ'}<br>
- ì˜ˆì¸¡ (ì¼ë°˜): {sn + fn + pn_ + fnl}ê±´ (âœ…{sn} âŒ{fn} â³{pn_} ğŸ›‘{fnl})<br>
- ì˜ˆì¸¡ (ë³€ë™ì„±): {sv + fv + pv + fvl}ê±´ (âœ…{sv} âŒ{fv} â³{pv} ğŸ›‘{fvl})<br>
<b style='color:#000088'>ğŸ¯ ì¼ë°˜ ì˜ˆì¸¡</b>: {pn['total']}ê±´ | {percent(pn['succ_rate'])} / {percent(pn['fail_rate'])} / {pn['r_avg']:.2f}%<br>
<b style='color:#880000'>ğŸŒªï¸ ë³€ë™ì„± ì˜ˆì¸¡</b>: {pv_stats['total']}ê±´ | {percent(pv_stats['succ_rate'])} / {percent(pv_stats['fail_rate'])} / {pv_stats['r_avg']:.2f}%<br>
<b>ğŸ“‹ ìµœê·¼ ì˜ˆì¸¡ 10ê±´</b><br>{table}
</div>"""

            try:
                visual = generate_visuals_for_strategy(strat)
            except Exception as e:
                visual = f"<div style='color:red'>[ì‹œê°í™” ì‹¤íŒ¨: {e}]</div>"

            strategy_html.append(f"<div style='margin-bottom:30px'>{info_html}<div style='margin:20px 0'>{visual}</div><hr></div>")
        except Exception as e:
            strategy_html.append(f"<div style='color:red;'>âŒ {strat} ì‹¤íŒ¨: {type(e).__name__} â†’ {e}</div>")

    status = "ğŸŸ¢ ì „ì²´ ì „ëµ ì •ìƒ ì‘ë™ ì¤‘" if not problems else "ğŸ”´ ì¢…í•©ì§„ë‹¨ ìš”ì•½:<br>" + "<br>".join(problems)
    return f"<div style='font-family:monospace;line-height:1.6;font-size:15px;'><b>{status}</b><hr>" + "".join(strategy_html) + "</div>"

@app.route("/")
def index(): return "Yopo server is running"

@app.route("/ping")
def ping(): return "pong"

@app.route("/run")
def run():
    try:
        print("[RUN] ì „ëµë³„ ì˜ˆì¸¡ ì‹¤í–‰"); sys.stdout.flush()
        for strategy in ["ë‹¨ê¸°","ì¤‘ê¸°","ì¥ê¸°"]:
            main(strategy, force=True)
        return "Recommendation started"
    except Exception as e:
        traceback.print_exc(); return f"Error: {e}", 500

@app.route("/train-now")
def train_now():
    try:
        train.train_all_models()
        return "âœ… ëª¨ë“  ì „ëµ í•™ìŠµ ì‹œì‘ë¨"
    except Exception as e:
        return f"í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/train-log")
def train_log():
    try:
        if not os.path.exists(LOG_FILE): return "í•™ìŠµ ë¡œê·¸ ì—†ìŒ"
        df = pd.read_csv(LOG_FILE, encoding="utf-8-sig", on_bad_lines="skip")
        if df.empty or df.shape[1] == 0: return "í•™ìŠµ ê¸°ë¡ ì—†ìŒ"
        return "<pre>" + df.to_csv(index=False) + "</pre>"
    except Exception as e:
        return f"ì½ê¸° ì˜¤ë¥˜: {e}", 500

@app.route("/models")
def list_models():
    try:
        if not os.path.exists(MODEL_DIR): return "models í´ë” ì—†ìŒ"
        files = os.listdir(MODEL_DIR)
        return "<pre>" + "\n".join(files) + "</pre>" if files else "models í´ë” ë¹„ì–´ ìˆìŒ"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 500

@app.route("/check-log-full")
def check_log_full():
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)
        return jsonify(latest.to_dict(orient="records"))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-log")
def check_log():
    try:
        if not os.path.exists(PREDICTION_LOG):
            return jsonify({"error": "prediction_log.csv ì—†ìŒ"})
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        df = df[df["timestamp"].notna()]
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})

@app.route("/check-eval-log")
def check_eval_log():
    try:
        path = PREDICTION_LOG
        if not os.path.exists(path): return "ì˜ˆì¸¡ ë¡œê·¸ ì—†ìŒ"

        df = pd.read_csv(path, encoding="utf-8-sig")
        if "status" not in df.columns: return "ìƒíƒœ ì»¬ëŸ¼ ì—†ìŒ"

        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)

        def status_icon(s):
            return {"success":"âœ…","fail":"âŒ","v_success":"âœ…","v_fail":"âŒ","pending":"â³","v_pending":"â³"}.get(s,"â“")

        html = "<table border='1'><tr><th>ì‹œê°</th><th>ì‹¬ë³¼</th><th>ì „ëµ</th><th>ëª¨ë¸</th><th>ì˜ˆì¸¡</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th><th>ì‚¬ìœ </th></tr>"
        for _, r in latest.iterrows():
            icon = status_icon(r.get("status",""))
            html += f"<tr><td>{r.get('timestamp','')}</td><td>{r.get('symbol','')}</td><td>{r.get('strategy','')}</td><td>{r.get('model','')}</td><td>{r.get('direction','')}</td><td>{float(r.get('return',0) or 0):.4f}</td><td>{icon}</td><td>{r.get('reason','')}</td></tr>"
        html += "</table>"
        return html
    except Exception as e:
        return f"âŒ ì˜¤ë¥˜: {e}", 500

from data.utils import SYMBOL_GROUPS

@app.route("/train-symbols")
def train_symbols():
    try:
        group_idx = int(request.args.get("group", -1))
        if group_idx < 0 or group_idx >= len(SYMBOL_GROUPS):
            return f"âŒ ì˜ëª»ëœ ê·¸ë£¹ ë²ˆí˜¸: {group_idx}", 400
        group_symbols = SYMBOL_GROUPS[group_idx]
        print(f"ğŸš€ ê·¸ë£¹ í•™ìŠµ ìš”ì²­ë¨ â†’ ê·¸ë£¹ #{group_idx} | ì‹¬ë³¼: {group_symbols}")
        threading.Thread(target=lambda: train.train_models(group_symbols), daemon=True).start()
        return f"âœ… ê·¸ë£¹ #{group_idx} í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘ë¨"
    except Exception as e:
        traceback.print_exc(); return f"âŒ ì˜¤ë¥˜: {e}", 500

@app.route("/train-symbols", methods=["POST"])
def train_selected_symbols():
    try:
        symbols = request.json.get("symbols", [])
        if not isinstance(symbols, list) or not symbols:
            return "âŒ ìœ íš¨í•˜ì§€ ì•Šì€ symbols ë¦¬ìŠ¤íŠ¸", 400
        train.train_models(symbols)
        return f"âœ… {len(symbols)}ê°œ ì‹¬ë³¼ í•™ìŠµ ì‹œì‘ë¨"
    except Exception as e:
        return f"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/reset-all")
def reset_all():
    if request.args.get("key") != "3572":
        return "âŒ ì¸ì¦ ì‹¤íŒ¨", 403
    try:
        from data.utils import _kline_cache, _feature_cache
        def clear_csv(f, h):
            os.makedirs(os.path.dirname(f), exist_ok=True)
            with open(f, "w", newline="", encoding="utf-8-sig") as wf:
                wf.write(",".join(h) + "\n")

        done_path = os.path.join(PERSIST_DIR, "train_done.json")
        if os.path.exists(done_path): os.remove(done_path)

        if os.path.exists(MODEL_DIR): shutil.rmtree(MODEL_DIR)
        os.makedirs(MODEL_DIR, exist_ok=True)

        if os.path.exists(LOG_DIR): shutil.rmtree(LOG_DIR)
        os.makedirs(LOG_DIR, exist_ok=True)

        _kline_cache.clear(); _feature_cache.clear()

        ensure_prediction_log_exists()
        clear_csv(WRONG_PREDICTIONS, ["timestamp","symbol","strategy","direction","entry_price","target_price","model","predicted_class","top_k","note","success","reason","rate","return_value","label","group_id","model_symbol","model_name","source","volatility","source_exchange"])
        clear_csv(LOG_FILE, ["timestamp","symbol","strategy","model","accuracy","f1","loss","note","source_exchange","status"])
        clear_csv(AUDIT_LOG, ["timestamp","symbol","strategy","result","status"])
        clear_csv(MESSAGE_LOG, ["timestamp","symbol","strategy","message"])
        clear_csv(FAILURE_LOG, ["symbol","strategy","failures"])
        return "âœ… ì™„ì „ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", 500

@app.route("/force-fix-prediction-log")
def force_fix_prediction_log():
    """loggerì˜ í‘œì¤€ í—¤ë”ë¡œ prediction_log.csvë¥¼ ì•ˆì „í•˜ê²Œ ì¬ìƒì„±"""
    try:
        from logger import ensure_prediction_log_exists
        if os.path.exists(PREDICTION_LOG):
            os.remove(PREDICTION_LOG)
        ensure_prediction_log_exists()
        return "âœ… prediction_log.csv ê°•ì œ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜: {e}", 500

# ===== main =====
if __name__ == "__main__":
    from failure_db import ensure_failure_db
    print(">>> ì„œë²„ ì‹¤í–‰ ì¤€ë¹„")

    ensure_failure_db(); print("âœ… failure_patterns DB ì´ˆê¸°í™” ì™„ë£Œ")

    try:
        port = int(os.environ.get("PORT", 5000))
    except ValueError:
        raise RuntimeError("âŒ Render í™˜ê²½ë³€ìˆ˜ PORTê°€ ì—†ìŠµë‹ˆë‹¤. Render ì„œë¹„ìŠ¤ íƒ€ì… í™•ì¸ í•„ìš”")

    print("ğŸš€ ì²« í•™ìŠµ ê°•ì œ ì‹¤í–‰ ì‹œì‘")
    try:
        train_symbol_group_loop(); print("âœ… ì²« í•™ìŠµ ì™„ë£Œ")
    except Exception as e:
        print(f"âŒ ì²« í•™ìŠµ ì˜¤ë¥˜: {e}")

    def run_flask():
        print(f"âœ… Flask ì„œë²„ ì‹¤í–‰ ì‹œì‘ (PORT={port})")
        app.run(host="0.0.0.0", port=port)
    threading.Thread(target=run_flask, daemon=True).start()

    def background_tasks():
        try:
            threading.Thread(target=train_symbol_group_loop, daemon=True).start()
            print("âœ… í•™ìŠµ ë£¨í”„ ìŠ¤ë ˆë“œ ì‹œì‘")

            # âœ… ì •ë¦¬ ìŠ¤ì¼€ì¤„ëŸ¬(ê¸°ë³¸ 30ë¶„) ì‹œì‘ â€” í‰ê°€ ìŠ¤ì¼€ì¤„ëŸ¬ë³´ë‹¤ ë¨¼ì €
            start_cleanup_scheduler()  # [ADD]

            try:
                start_scheduler(); print("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì‹¤íŒ¨: {e}")
            threading.Thread(target=maintenance_fix_meta.fix_all_meta_json, daemon=True).start()
            print("âœ… maintenance_fix_meta ì‹¤í–‰ ì™„ë£Œ")
            send_message("[ì‹œì‘] YOPO ì„œë²„ ì‹¤í–‰ë¨"); print("âœ… Telegram ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹¤íŒ¨: {e}")

    threading.Thread(target=background_tasks, daemon=True).start()

    import time
    while True: time.sleep(3600)
