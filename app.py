from flask import Flask, jsonify, request
from recommend import main
import train, os, threading, datetime, pandas as pd, pytz, traceback, sys, shutil, csv, re, functools
from apscheduler.schedulers.background import BackgroundScheduler
from telegram_bot import send_message
from predict_test import test_all_predictions
from predict_trigger import run as trigger_run
from data.utils import SYMBOLS, get_kline_by_strategy
from visualization import generate_visual_report, generate_visuals_for_strategy
from wrong_data_loader import load_training_prediction_data
from predict import evaluate_predictions

PERSIST_DIR = "/persistent"
LOG_DIR, MODEL_DIR = os.path.join(PERSIST_DIR, "logs"), os.path.join(PERSIST_DIR, "models")
LOG_FILE, PREDICTION_LOG = os.path.join(LOG_DIR, "train_log.csv"), os.path.join(PERSIST_DIR, "prediction_log.csv")
WRONG_PREDICTIONS, AUDIT_LOG = os.path.join(PERSIST_DIR, "wrong_predictions.csv"), os.path.join(LOG_DIR, "evaluation_audit.csv")
MESSAGE_LOG, FAILURE_LOG = os.path.join(LOG_DIR, "message_log.csv"), os.path.join(LOG_DIR, "failure_count.csv")
os.makedirs(LOG_DIR, exist_ok=True)
now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

def start_scheduler():
    print(">>> ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘"); sys.stdout.flush()
    sched = BackgroundScheduler(timezone=pytz.timezone("Asia/Seoul"))

    # âœ… ì „ëµë³„ í•™ìŠµ ìŠ¤ì¼€ì¤„
    í•™ìŠµ = [
        (1, 30, "ë‹¨ê¸°"), (3, 30, "ì¥ê¸°"), (6, 0, "ì¤‘ê¸°"), (9, 0, "ë‹¨ê¸°"),
        (11, 0, "ì¤‘ê¸°"), (13, 0, "ì¥ê¸°"), (15, 0, "ë‹¨ê¸°"),
        (17, 0, "ì¤‘ê¸°"), (19, 0, "ì¥ê¸°"), (22, 30, "ë‹¨ê¸°")
    ]

    # âœ… ì „ëµë³„ ì˜ˆì¸¡ ìŠ¤ì¼€ì¤„
    ì˜ˆì¸¡ = [
        (7, 30, s) for s in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]
    ] + [
        (10, 30, "ë‹¨ê¸°"), (10, 30, "ì¤‘ê¸°"),
        (12, 30, "ì¤‘ê¸°"), (14, 30, "ì¥ê¸°"),
        (16, 30, "ë‹¨ê¸°"), (18, 30, "ì¤‘ê¸°")
    ] + [
        (21, 0, s) for s in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]
    ] + [
        (0, 0, "ë‹¨ê¸°"), (0, 0, "ì¤‘ê¸°")
    ]

    # âœ… í•™ìŠµ ë“±ë¡
    def í•™ìŠµì‘ì—…(s):
        threading.Thread(target=train.train_model_loop, args=(s,), daemon=True).start()

    for h, m, s in í•™ìŠµ:
        sched.add_job(lambda s=s: í•™ìŠµì‘ì—…(s), trigger="cron", hour=h, minute=m)

    # âœ… ì˜ˆì¸¡ ë“±ë¡
    def ì˜ˆì¸¡ì‘ì—…(s):
        threading.Thread(target=main, kwargs={"strategy": s, "force": True}, daemon=True).start()

    for h, m, s in ì˜ˆì¸¡:
        sched.add_job(lambda s=s: ì˜ˆì¸¡ì‘ì—…(s), trigger="cron", hour=h, minute=m)

    # âœ… ì „ëµë³„ í‰ê°€ ë“±ë¡ (30ë¶„ë§ˆë‹¤ ë°˜ë³µ)
    def í‰ê°€ì‘ì—…(strategy):
        def wrapped():
            evaluate_predictions(lambda sym, _: get_kline_by_strategy(sym, strategy))
        threading.Thread(target=wrapped, daemon=True).start()

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        sched.add_job(lambda s=strat: í‰ê°€ì‘ì—…(s), trigger="interval", minutes=30)

    # âœ… ê¸°íƒ€ íŠ¸ë¦¬ê±° ìœ ì§€
    sched.add_job(trigger_run, "interval", minutes=30)

    sched.start()



# ì´í•˜ ê¸°ì¡´ app.routeë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ (ìƒëµ ê°€ëŠ¥)

app = Flask(__name__)
print(">>> Flask ì•± ìƒì„± ì™„ë£Œ"); sys.stdout.flush()
@app.route("/yopo-health")
def yopo_health():
    percent = lambda v: f"{v:.1f}%" if pd.notna(v) else "0.0%"
    logs, strategy_html, problems = {}, [], []

    file_map = {
        "pred": "/persistent/prediction_log.csv",
        "train": LOG_FILE,
        "audit": AUDIT_LOG,
        "msg": MESSAGE_LOG
    }

    for name, path in file_map.items():
        try:
            logs[name] = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
            logs[name] = logs[name][logs[name]["timestamp"].notna()] if "timestamp" in logs[name] else logs[name]
        except:
            logs[name] = pd.DataFrame()

    model_files = [f for f in os.listdir(MODEL_DIR) if f.endswith(".pt")]
    model_info = {}
    for f in model_files:
        match = re.match(r"(.+?)_(ë‹¨ê¸°|ì¤‘ê¸°|ì¥ê¸°)_(lstm|cnn_lstm|transformer)\.pt", f)
        if match:
            symbol, strat, mtype = match.groups()
            model_info.setdefault(strat, {}).setdefault(symbol, set()).add(mtype)

    for strat in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
        try:
            pred, train, audit = logs["pred"], logs["train"], logs["audit"]
            pred = pred.query(f"strategy == '{strat}'") if not pred.empty else pd.DataFrame()
            train = train.query(f"strategy == '{strat}'") if not train.empty else pd.DataFrame()
            audit = audit.query(f"strategy == '{strat}'") if not audit.empty else pd.DataFrame()

            if "status" in pred.columns:
                pred["volatility"] = pred["status"].astype(str).str.startswith("v_")
            else:
                pred["volatility"] = False

            pred["return"] = pd.to_numeric(pred.get("return", pd.Series()), errors="coerce").fillna(0)
            nvol = pred[~pred["volatility"]] if not pred.empty else pd.DataFrame()
            vol = pred[pred["volatility"]] if not pred.empty else pd.DataFrame()

            stat = lambda df, s: len(df[df["status"] == s]) if not df.empty and "status" in df.columns else 0
            sn, fn, pn_, fnl = map(lambda s: stat(nvol, s), ["success", "fail", "pending", "failed"])
            sv, fv, pv, fvl = map(lambda s: stat(vol, s), ["v_success", "v_fail", "pending", "failed"])

            def perf(df, kind="ì¼ë°˜"):
                try:
                    s = stat(df, "v_success" if kind == "ë³€ë™ì„±" else "success")
                    f = stat(df, "v_fail" if kind == "ë³€ë™ì„±" else "fail")
                    t = s + f
                    avg = df["return"].mean()
                    return {"succ": s, "fail": f, "succ_rate": s / t * 100 if t else 0,
                            "fail_rate": f / t * 100 if t else 0, "r_avg": avg if pd.notna(avg) else 0, "total": t}
                except:
                    return {"succ": 0, "fail": 0, "succ_rate": 0, "fail_rate": 0, "r_avg": 0, "total": 0}

            pn, pv_stats = perf(nvol, "ì¼ë°˜"), perf(vol, "ë³€ë™ì„±")

            strat_models = model_info.get(strat, {})
            types = {"lstm": 0, "cnn_lstm": 0, "transformer": 0}
            for mtypes in strat_models.values():
                for t in mtypes:
                    types[t] += 1
            trained_syms = [s for s, t in strat_models.items() if {"lstm", "cnn_lstm", "transformer"}.issubset(t)]
            untrained = sorted(set(SYMBOLS) - set(trained_syms))

            if sum(types.values()) == 0: problems.append(f"{strat}: ëª¨ë¸ ì—†ìŒ")
            if sn + fn + pn_ + fnl + sv + fv + pv + fvl == 0: problems.append(f"{strat}: ì˜ˆì¸¡ ì—†ìŒ")
            if pn["succ"] + pn["fail"] == 0: problems.append(f"{strat}: í‰ê°€ ë¯¸ì‘ë™")
            if pn["fail_rate"] > 50: problems.append(f"{strat}: ì¼ë°˜ ì‹¤íŒ¨ìœ¨ {pn['fail_rate']:.1f}%")
            if pv_stats["fail_rate"] > 50: problems.append(f"{strat}: ë³€ë™ì„± ì‹¤íŒ¨ìœ¨ {pv_stats['fail_rate']:.1f}%")

            table = "<i style='color:gray'>ìµœê·¼ ì˜ˆì¸¡ ì—†ìŒ ë˜ëŠ” ì»¬ëŸ¼ ë¶€ì¡±</i>"
            required_cols = {"timestamp", "symbol", "direction", "return", "rate", "status"}
            if pred.shape[0] > 0 and required_cols.issubset(set(pred.columns)):
                recent10 = pred.sort_values("timestamp").tail(10).copy()
                rows = []
                for _, r in recent10.iterrows():
                    rtn = r.get("return", 0.0) or r.get("rate", 0.0)
                    try: rtn_pct = f"{float(rtn) * 100:.2f}%"
                    except: rtn_pct = "0.00%"
                    status_icon = 'âœ…' if r['status'] in ['success','v_success'] else 'âŒ' if r['status'] in ['fail','v_fail'] else 'â³' if r['status']=='pending' else 'ğŸ›‘'
                    rows.append(f"<tr><td>{r['timestamp']}</td><td>{r['symbol']}</td><td>{r['direction']}</td><td>{rtn_pct}</td><td>{status_icon}</td></tr>")
                table = "<table border='1' style='margin-top:4px'><tr><th>ì‹œê°</th><th>ì¢…ëª©</th><th>ë°©í–¥</th><th>ìˆ˜ìµë¥ </th><th>ìƒíƒœ</th></tr>" + "".join(rows) + "</table>"

            info_html = f"""<div style='border:1px solid #aaa;margin:16px 0;padding:10px;font-family:monospace;background:#f8f8f8;'>
<b style='font-size:16px;'>ğŸ“Œ ì „ëµ: {strat}</b><br>
- ëª¨ë¸ ìˆ˜: {sum(types.values())} (lstm={types['lstm']}, cnn={types['cnn_lstm']}, trans={types['transformer']})<br>
- ì‹¬ë³¼ ìˆ˜: {len(SYMBOLS)} | ì™„ì „í•™ìŠµ: {len(trained_syms)} | ë¯¸ì™„ì„±: {len(untrained)}<br>
- ìµœê·¼ í•™ìŠµ: {train['timestamp'].iloc[-1] if not train.empty else 'ì—†ìŒ'}<br>
- ìµœê·¼ ì˜ˆì¸¡: {pred['timestamp'].iloc[-1] if not pred.empty else 'ì—†ìŒ'}<br>
- ìµœê·¼ í‰ê°€: {audit['timestamp'].iloc[-1] if not audit.empty else 'ì—†ìŒ'}<br>
- ì˜ˆì¸¡ (ì¼ë°˜): {sn + fn + pn_ + fnl}ê±´ (âœ…{sn} âŒ{fn} â³{pn_} ğŸ›‘{fnl})<br>
- ì˜ˆì¸¡ (ë³€ë™ì„±): {sv + fv + pv + fvl}ê±´ (âœ…{sv} âŒ{fv} â³{pv} ğŸ›‘{fvl})<br>
<b style='color:#000088'>ğŸ¯ ì¼ë°˜ ì˜ˆì¸¡</b>: {pn['total']}ê±´ | {percent(pn['succ_rate'])} / {percent(pn['fail_rate'])} / {pn['r_avg']:.2f}%<br>
<b style='color:#880000'>ğŸŒªï¸ ë³€ë™ì„± ì˜ˆì¸¡</b>: {pv_stats['total']}ê±´ | {percent(pv_stats['succ_rate'])} / {percent(pv_stats['fail_rate'])} / {pv_stats['r_avg']:.2f}%<br>
<b>ğŸ“‹ ìµœê·¼ ì˜ˆì¸¡ 10ê±´</b><br>{table}
</div>"""

            try:
                visual = generate_visuals_for_strategy(strat)
            except Exception as e:
                visual = f"<div style='color:red'>[ì‹œê°í™” ì‹¤íŒ¨: {e}]</div>"

            strategy_html.append(f"<div style='margin-bottom:30px'>{info_html}<div style='margin:20px 0'>{visual}</div><hr></div>")

        except Exception as e:
            strategy_html.append(f"<div style='color:red;'>âŒ {strat} ì‹¤íŒ¨: {type(e).__name__} â†’ {e}</div>")

    status = "ğŸŸ¢ ì „ì²´ ì „ëµ ì •ìƒ ì‘ë™ ì¤‘" if not problems else "ğŸ”´ ì¢…í•©ì§„ë‹¨ ìš”ì•½:<br>" + "<br>".join(problems)
    return f"<div style='font-family:monospace;line-height:1.6;font-size:15px;'><b>{status}</b><hr>" + "".join(strategy_html) + "</div>"



@app.route("/")
def index():
    return "Yopo server is running"

@app.route("/ping")
def ping():
    return "pong"

@app.route("/run")
def run():
    try:
        print("[RUN] ì „ëµë³„ ì˜ˆì¸¡ ì‹¤í–‰")
        sys.stdout.flush()
        for strategy in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
            main(strategy, force=True)  # âœ… ê°•ì œ ì˜ˆì¸¡ ì‹¤í–‰
        return "Recommendation started"
    except Exception as e:
        traceback.print_exc()
        return f"Error: {e}", 500



@app.route("/train-now")
def train_now():
    try:
        threading.Thread(target=train.train_all_models, daemon=True).start()
        return "âœ… ëª¨ë“  ì „ëµ í•™ìŠµ ì‹œì‘ë¨"
    except Exception as e:
        return f"í•™ìŠµ ì‹¤íŒ¨: {e}", 500

@app.route("/train-log")
def train_log():
    try:
        if not os.path.exists(LOG_FILE):
            return "í•™ìŠµ ë¡œê·¸ ì—†ìŒ"
        df = pd.read_csv(LOG_FILE, encoding="utf-8-sig", on_bad_lines="skip")
        if df.empty or df.shape[1] == 0:
            return "í•™ìŠµ ê¸°ë¡ ì—†ìŒ"
        return "<pre>" + df.to_csv(index=False) + "</pre>"
    except Exception as e:
        return f"ì½ê¸° ì˜¤ë¥˜: {e}", 500

@app.route("/models")
def list_models():
    try:
        if not os.path.exists(MODEL_DIR):
            return "models í´ë” ì—†ìŒ"
        files = os.listdir(MODEL_DIR)
        return "<pre>" + "\n".join(files) + "</pre>" if files else "models í´ë” ë¹„ì–´ ìˆìŒ"
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 500

@app.route("/check-log-full")
def check_log_full():
    try:
        import pandas as pd
        path = "/persistent/logs/prediction_{}.csv".format(datetime.datetime.now().strftime("%Y-%m-%d"))
        df = pd.read_csv(path, encoding="utf-8-sig")
        latest = df.sort_values(by="timestamp", ascending=False).head(100)
        return jsonify(latest.to_dict(orient="records"))
    except Exception as e:
        return jsonify({"error": str(e)})


@app.route("/check-log")
def check_log():
    try:
        if not os.path.exists(PREDICTION_LOG):
            return jsonify({"error": "prediction_log.csv ì—†ìŒ"})
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        df = df[df["timestamp"].notna()]  # âœ… ë¹ˆ timestamp ì œê±°
        return jsonify(df.tail(10).to_dict(orient='records'))
    except Exception as e:
        return jsonify({"error": str(e)})


@app.route("/reset-all")
def reset_all():
    if request.args.get("key") != "3572":
        return "âŒ ì¸ì¦ ì‹¤íŒ¨", 403
    try:
        def clear(f, h): open(f, "w", newline="", encoding="utf-8-sig").write(",".join(h) + "\n")
        if os.path.exists(MODEL_DIR):
            shutil.rmtree(MODEL_DIR)
        os.makedirs(MODEL_DIR, exist_ok=True)
        clear(PREDICTION_LOG, ["timestamp", "symbol", "strategy", "direction", "entry_price", "target_price", "model", "rate", "status", "reason", "return", "volatility"])
        clear(WRONG_PREDICTIONS, ["timestamp", "symbol", "strategy", "direction", "entry_price", "target_price", "gain"])
        clear(LOG_FILE, ["timestamp", "symbol", "strategy", "model", "accuracy", "f1", "loss"])
        clear(AUDIT_LOG, ["timestamp", "symbol", "strategy", "result", "status"])
        clear(MESSAGE_LOG, ["timestamp", "symbol", "strategy", "message"])
        clear(FAILURE_LOG, ["symbol", "strategy", "failures"])
        return "âœ… ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", 500

@app.route("/force-fix-prediction-log")
def force_fix_prediction_log():
    try:
        headers = ["timestamp", "symbol", "strategy", "direction", "entry_price", "target_price", "model", "rate", "status", "reason", "return", "volatility"]
        with open(PREDICTION_LOG, "w", newline="", encoding="utf-8-sig") as f:
            csv.DictWriter(f, fieldnames=headers).writeheader()
        return "âœ… prediction_log.csv ê°•ì œ ì´ˆê¸°í™” ì™„ë£Œ"
    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜: {e}", 500

if __name__ == "__main__":
    print(">>> ì„œë²„ ì‹¤í–‰ ì¤€ë¹„")
    sys.stdout.flush()
    threading.Thread(target=start_scheduler, daemon=True).start()
    threading.Thread(target=lambda: send_message("[ì‹œì‘] YOPO ì„œë²„ ì‹¤í–‰ë¨"), daemon=True).start()
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 10000)))

