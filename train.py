import os, json, time, traceback
from datetime import datetime
import pytz
import numpy as np
import pandas as pd  # â¬… ì¶”ê°€: ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°ì— í•„ìš”
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import MinMaxScaler

from data.utils import SYMBOLS, get_kline_by_strategy, compute_features, create_dataset
from model.base_model import get_model
from model_weight_loader import get_model_weight
from feature_importance import compute_feature_importance, save_feature_importance
from failure_db import insert_failure_record, ensure_failure_db
from logger import log_training_result
from window_optimizer import find_best_window
from config import get_NUM_CLASSES, get_FEATURE_INPUT_SIZE, get_class_groups, get_class_ranges, set_NUM_CLASSES
from data_augmentation import balance_classes

# âœ… SSL í”„ë¦¬íŠ¸ë ˆì¸ (íŒŒì¼ëª…: ssl_pretrain.py)
from ssl_pretrain import masked_reconstruction

# âœ… ì§„í™”í˜• ë©”íƒ€ ëŸ¬ë„ˆ: ë£¨í”„ í˜¸ì¶œë¡œ í†µì¼
from evo_meta_learner import train_evo_meta_loop

NUM_CLASSES = get_NUM_CLASSES()
FEATURE_INPUT_SIZE = get_FEATURE_INPUT_SIZE()

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_DIR = "/persistent/models"
os.makedirs(MODEL_DIR, exist_ok=True)

now_kst = lambda: datetime.now(pytz.timezone("Asia/Seoul"))
training_in_progress = {"ë‹¨ê¸°": False, "ì¤‘ê¸°": False, "ì¥ê¸°": False}

# --------------------------------------------------
# ìœ í‹¸
# --------------------------------------------------
def get_feature_hash_from_tensor(x, use_full=False, precision=3):
    import hashlib
    if x.ndim != 2 or x.shape[0] == 0:
        return "invalid"
    try:
        flat = x.flatten() if use_full else x[-1]
        rounded = [round(float(val), precision) for val in flat]
        return hashlib.sha1(",".join(map(str, rounded)).encode()).hexdigest()
    except Exception:
        return "invalid"


def _log_skip(symbol, strategy, reason):
    log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                        loss=0.0, note=reason, status="skipped")
    insert_failure_record({
        "symbol": symbol, "strategy": strategy, "model": "all",
        "predicted_class": -1, "success": False, "rate": "", "reason": reason
    }, feature_vector=[])


def _log_fail(symbol, strategy, reason):
    log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                        loss=0.0, note=reason, status="failed")
    insert_failure_record({
        "symbol": symbol, "strategy": strategy, "model": "all",
        "predicted_class": -1, "success": False, "rate": "", "reason": reason
    }, feature_vector=[])


def _strategy_horizon_hours(strategy: str) -> int:
    """ì „ëµë³„ í‰ê°€ êµ¬ê°„(ì‹œê°„). predict/evaluateì™€ í•©ì¹˜ê¸° ìœ„í•´ ë™ì¼ ê¸°ì¤€ ì‚¬ìš©."""
    return {"ë‹¨ê¸°": 4, "ì¤‘ê¸°": 24, "ì¥ê¸°": 168}.get(strategy, 24)


def _future_returns_by_timestamp(df: pd.DataFrame, horizon_hours: int) -> np.ndarray:
    """
    ê° ì‹œì  tì— ëŒ€í•´ [t, t+horizon] êµ¬ê°„ì˜ 'max(high)'ë¥¼ ì‚¬ìš©í•˜ì—¬
    ë¯¸ë˜ ìµœëŒ€ ìˆ˜ìµë¥ ì„ ê³„ì‚° ( (max_high - close_t) / close_t ).
    ê¸¸ì´ëŠ” dfì™€ ë™ì¼í•˜ê²Œ ë§ì¶¤. ë§ˆì§€ë§‰ êµ¬ê°„ì€ ë°ì´í„° ë¶€ì¡± ì‹œ 0ìœ¼ë¡œ ì±„ì›€.
    """
    if df is None or df.empty or "timestamp" not in df.columns:
        return np.zeros(len(df), dtype=np.float32)

    ts = pd.to_datetime(df["timestamp"], errors="coerce")
    close = df["close"].astype(float).values
    high = (df["high"] if "high" in df.columns else df["close"]).astype(float).values

    # íƒ€ì„ì¡´ ì •ê·œí™”
    if ts.dt.tz is None:
        ts = ts.dt.tz_localize("UTC").dt.tz_convert("Asia/Seoul")
    else:
        ts = ts.dt.tz_convert("Asia/Seoul")

    out = np.zeros(len(df), dtype=np.float32)
    horizon = pd.Timedelta(hours=horizon_hours)

    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹(ê°„ë‹¨ êµ¬í˜„)
    j_start = 0
    for i in range(len(df)):
        t0 = ts.iloc[i]
        t1 = t0 + horizon
        # j ì»¤ì„œ ì•ìœ¼ë¡œ ì´ë™
        j = max(j_start, i)
        max_h = high[i]
        while j < len(df) and ts.iloc[j] <= t1:
            if high[j] > max_h:
                max_h = high[j]
            j += 1
        j_start = max(j_start, i)  # ì»¤ì„œ ê´€ë¦¬(ìµœì í™” ë¯¸ì„¸)
        base = close[i] if close[i] > 0 else (close[i] + 1e-6)
        out[i] = float((max_h - base) / (base + 1e-12))
    return out.astype(np.float32)

# --------------------------------------------------
# ë‹¨ì¼ (symbol, strategy, group_id) ëª¨ë¸ í•™ìŠµ
# --------------------------------------------------
def train_one_model(symbol, strategy, group_id=None, max_epochs=20):
    """
    - SSL ì‚¬ì „í•™ìŠµ ì‹¤í–‰ (ì‹¤íŒ¨í•´ë„ ê³„ì†)
    - ê°€ê²©/í”¼ì²˜ ë¡œë“œ â†’ (ë¯¸ë˜ ìˆ˜ìµë¥  ê¸°ë°˜) ë¼ë²¨ë§ â†’ ìœˆë„ìš° ì‹œí€€ìŠ¤ êµ¬ì„±
    - find_best_window()ë¡œ ë™ì  ìœˆë„ìš° ì„ íƒ
    - í•„ìš” ì‹œ í´ë˜ìŠ¤ ë°¸ëŸ°ì‹± ë° ë§ˆì§€ë§‰ ì•ˆì „ ë³´ê°•(fallback)ìœ¼ë¡œ ìŠ¤í‚µ ìµœì†Œí™”
    - [lstm, cnn_lstm, transformer] ê°ê° í•™ìŠµ/í‰ê°€/ì €ì¥
    - ë©”íƒ€íŒŒì¼(.meta.json) ë™ì‹œ ì €ì¥
    """
    try:
        print(f"âœ… [train_one_model ì‹œì‘] {symbol}-{strategy}-group{group_id}")
        ensure_failure_db()

        # 0) SSL í”„ë¦¬íŠ¸ë ˆì¸ (ì‹¤íŒ¨í•´ë„ í†µê³¼)
        try:
            masked_reconstruction(symbol, strategy, FEATURE_INPUT_SIZE)
        except Exception as e:
            print(f"[âš ï¸ SSL ì‚¬ì „í•™ìŠµ ì‹¤íŒ¨] {e}")

        # 1) ë°ì´í„° ë¡œë“œ
        df = get_kline_by_strategy(symbol, strategy)
        if df is None or df.empty:
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ ë°ì´í„° ì—†ìŒ")
            _log_skip(symbol, strategy, "ë°ì´í„° ì—†ìŒ")
            return

        feat = compute_features(symbol, df, strategy)
        if feat is None or feat.empty or feat.isnull().any().any():
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ í”¼ì²˜ ì—†ìŒ/NaN")
            _log_skip(symbol, strategy, "í”¼ì²˜ ì—†ìŒ")
            return

        # 2) í´ë˜ìŠ¤ ê²½ê³„/ë¼ë²¨ë§ (âœ… ë¯¸ë˜ ìˆ˜ìµë¥  ê¸°ë°˜)
        try:
            class_ranges = get_class_ranges(symbol=symbol, strategy=strategy, group_id=group_id)
        except Exception as e:
            print(f"[âŒ í´ë˜ìŠ¤ ë²”ìœ„ ê³„ì‚° ì‹¤íŒ¨] {e}")
            _log_fail(symbol, strategy, "í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨")
            return

        num_classes = len(class_ranges)
        set_NUM_CLASSES(num_classes)

        # ë¯¸ë˜ ìˆ˜ìµë¥ 
        horizon_hours = _strategy_horizon_hours(strategy)
        future_gains = _future_returns_by_timestamp(df, horizon_hours=horizon_hours)

        # í´ë˜ìŠ¤ ë§¤í•‘
        labels = []
        for r in future_gains:
            idx = 0
            for i, (lo, hi) in enumerate(class_ranges):
                if lo <= r <= hi:
                    idx = i
                    break
            labels.append(idx)
        labels = np.array(labels, dtype=np.int64)

        # 3) ë™ì  ìœˆë„ìš° ì„ íƒ
        try:
            best_window = find_best_window(symbol, strategy, window_list=[10, 20, 30, 40, 60])
        except Exception as e:
            print(f"[âš ï¸ find_best_window ì‹¤íŒ¨] {e}")
            best_window = 60
        window = int(max(5, best_window))
        print(f"[ğŸ”§ ì„ íƒëœ WINDOW] {symbol}-{strategy} â†’ {window}")

        # 4) ì‹œí€€ìŠ¤ ìƒì„± (ê¸°ë³¸ ê²½ë¡œ)
        features_only = feat.drop(columns=["timestamp", "strategy"], errors="ignore")
        feat_scaled = MinMaxScaler().fit_transform(features_only)

        X, y = [], []
        # ìœˆë„ìš° ë ì‹œì ì˜ 'ë¯¸ë˜ ìˆ˜ìµë¥  ë¼ë²¨'ì„ ì •ë‹µìœ¼ë¡œ ì‚¬ìš©
        for i in range(len(feat_scaled) - window):
            X.append(feat_scaled[i:i+window])
            y_idx = i + window - 1  # ìœˆë„ìš° ë ì‹œì  ì¸ë±ìŠ¤
            y.append(labels[y_idx] if 0 <= y_idx < len(labels) else 0)
        X, y = np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)
        print(f"[ğŸ“Š ì´ˆê¸° ì‹œí€€ìŠ¤] {symbol}-{strategy} â†’ {len(y)}ê±´")

        # 4-1) ë§ˆì§€ë§‰ ì•ˆì „ ë³´ê°•: ìƒ˜í”Œ ë„ˆë¬´ ì ìœ¼ë©´ create_dataset fallback
        if len(X) < 20:
            print("[â„¹ï¸ ì•ˆì „ ë³´ê°•: create_dataset fallback ì‚¬ìš©]")
            feat_records = feat.to_dict(orient="records")
            try:
                # create_datasetì€ ë¯¸ë˜ ìˆ˜ìµë¥  ê¸°ë°˜(look-ahead) ë¡œì§ì„ ë‚´ì¥
                res = create_dataset(feat_records, window=window, strategy=strategy, input_size=FEATURE_INPUT_SIZE)
                if isinstance(res, tuple) and len(res) >= 2:
                    X_fb, y_fb = res[0], res[1]
                else:
                    X_fb, y_fb = res
                if isinstance(X_fb, np.ndarray) and len(X_fb) > 0:
                    X, y = X_fb.astype(np.float32), y_fb.astype(np.int64)
                    print(f"[âœ… fallback ì ìš©] ìµœì¢… ìƒ˜í”Œ: {len(y)}")
            except Exception as e:
                print(f"[âš ï¸ fallback ì‹¤íŒ¨] {e}")

        if len(X) < 10:
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ ìµœì¢… ìƒ˜í”Œ ë¶€ì¡±({len(X)})")
            _log_skip(symbol, strategy, "ìµœì¢… ìƒ˜í”Œ ë¶€ì¡±")
            return

        # 5) ë°¸ëŸ°ì‹±(í•„ìš” ì‹œ)
        try:
            if len(X) < 200:  # ê·œëª¨ê°€ ì‘ì„ ë•Œë§Œ ê³¼ë„í•œ ì¦ê°• ë°©ì§€
                X, y = balance_classes(X, y, num_classes=num_classes)
                print(f"[âœ… ì¦ê°•/ë°¸ëŸ°ì‹± ì™„ë£Œ] ì´ ìƒ˜í”Œ: {len(X)}")
        except Exception as e:
            print(f"[âš ï¸ ë°¸ëŸ°ì‹± ì‹¤íŒ¨] {e}")

        # 6) í•™ìŠµ/í‰ê°€/ì €ì¥ (ëª¨ë¸ 3ì¢…)
        for model_type in ["lstm", "cnn_lstm", "transformer"]:
            print(f"[ğŸ§  í•™ìŠµ ì‹œì‘] {model_type} | {symbol}-{strategy}-group{group_id}")
            model = get_model(model_type, input_size=FEATURE_INPUT_SIZE, output_size=num_classes).to(DEVICE)
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
            criterion = nn.CrossEntropyLoss()

            # train/val split
            val_len = max(1, int(len(X) * 0.2))
            if len(X) - val_len < 1:
                val_len = len(X) - 1
            train_X, val_X = X[:-val_len], X[-val_len:]
            train_y, val_y = y[:-val_len], y[-val_len:]

            train_loader = DataLoader(TensorDataset(
                torch.tensor(train_X), torch.tensor(train_y)), batch_size=64, shuffle=True)
            val_loader = DataLoader(TensorDataset(
                torch.tensor(val_X), torch.tensor(val_y)), batch_size=64)

            total_loss = 0.0
            for epoch in range(max_epochs):
                model.train()
                for xb, yb in train_loader:
                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)
                    logits = model(xb)
                    loss = criterion(logits, yb)
                    if not torch.isfinite(loss):
                        continue
                    optimizer.zero_grad(); loss.backward(); optimizer.step()
                    total_loss += loss.item()
                if (epoch + 1) % 5 == 0 or epoch == max_epochs - 1:
                    print(f"[ğŸ“ˆ {model_type}] Epoch {epoch+1}/{max_epochs} | loss={loss.item():.4f}")

            # í‰ê°€
            model.eval()
            all_preds, all_labels = [], []
            with torch.no_grad():
                for xb, yb in val_loader:
                    preds = torch.argmax(model(xb.to(DEVICE)), dim=1).cpu().numpy()
                    all_preds.extend(preds); all_labels.extend(yb.numpy())
            acc = accuracy_score(all_labels, all_preds)
            f1 = f1_score(all_labels, all_preds, average="macro")
            print(f"[ğŸ¯ {model_type}] acc={acc:.4f}, f1={f1:.4f}")

            # ì €ì¥
            os.makedirs(MODEL_DIR, exist_ok=True)
            model_name = f"{symbol}_{strategy}_{model_type}_group{group_id}_cls{num_classes}.pt"
            model_path = os.path.join(MODEL_DIR, model_name)
            torch.save(model.state_dict(), model_path)

            meta = {
                "symbol": symbol, "strategy": strategy, "model": model_type,
                "group_id": int(group_id) if group_id is not None else 0,
                "num_classes": int(num_classes),
                "input_size": int(FEATURE_INPUT_SIZE),
                "timestamp": now_kst().isoformat(),
                "model_name": model_name
            }
            with open(model_path.replace(".pt", ".meta.json"), "w", encoding="utf-8") as f:
                json.dump(meta, f, ensure_ascii=False, indent=2)

            log_training_result(
                symbol=symbol,
                strategy=strategy,
                model=model_name,
                accuracy=float(acc),
                f1=float(f1),
                loss=float(total_loss),
                note=f"train_one_model(window={window})",
                source_exchange="BYBIT",
                status="success",
            )

        print(f"[âœ… train_one_model ì™„ë£Œ] {symbol}-{strategy}-group{group_id}")

    except Exception as e:
        print(f"[âŒ train_one_model ì‹¤íŒ¨] {symbol}-{strategy}-group{group_id} â†’ {e}")
        traceback.print_exc()
        log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                            loss=0.0, note=str(e), status="failed")
        insert_failure_record({
            "symbol": symbol, "strategy": strategy, "model": "all",
            "predicted_class": -1, "success": False, "rate": "", "reason": str(e)
        }, feature_vector=[])

# --------------------------------------------------
# ì „ì²´ í•™ìŠµ ë£¨í‹´
# --------------------------------------------------
def train_models(symbol_list):
    """
    - ì‹¬ë³¼ Ã— (ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°) Ã— ì „ ê·¸ë£¹ í•™ìŠµ
    - ë©”íƒ€ ë³´ì •/ì‹¤íŒ¨í•™ìŠµ/ì§„í™”í˜• ë©”íƒ€ ë£¨í”„ í˜¸ì¶œ
    """
    strategies = ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]
    print(f"ğŸš€ [train_models] ì‹¬ë³¼ í•™ìŠµ ì‹œì‘: {symbol_list}")

    for symbol in symbol_list:
        print(f"\nğŸ” [ì‹¬ë³¼] {symbol}")
        for strategy in strategies:
            print(f"â–¶ {symbol}-{strategy} ì „ì²´ ê·¸ë£¹ í•™ìŠµ")
            # group_id ëª©ë¡ ê³„ì‚°
            try:
                class_ranges = get_class_ranges(symbol=symbol, strategy=strategy)
                if not class_ranges:
                    raise ValueError("ë¹ˆ í´ë˜ìŠ¤ ê²½ê³„")
                num_classes = len(class_ranges)
                groups = get_class_groups(num_classes=num_classes)  # ë¦¬ìŠ¤íŠ¸ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
                max_gid = len(groups) - 1
            except Exception as e:
                print(f"[âŒ í´ë˜ìŠ¤ ê²½ê³„ ê³„ì‚° ì‹¤íŒ¨] {symbol}-{strategy}: {e}")
                _log_fail(symbol, strategy, f"í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
                continue

            for gid in range(max_gid + 1):
                train_one_model(symbol, strategy, group_id=gid)
                time.sleep(0.5)

    # ë©”íƒ€ ë³´ì •
    try:
        import maintenance_fix_meta
        maintenance_fix_meta.fix_all_meta_json()
    except Exception as e:
        print(f"[âš ï¸ meta ë³´ì • ì‹¤íŒ¨] {e}")

    # ì‹¤íŒ¨í•™ìŠµ ë£¨í”„
    try:
        import failure_trainer
        failure_trainer.run_failure_training()
    except Exception as e:
        print(f"[âš ï¸ ì‹¤íŒ¨í•™ìŠµ ë£¨í”„ ì˜ˆì™¸] {e}")

    # âœ… ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ë£¨í”„ í˜¸ì¶œ(ë‹¨ë°œ)
    try:
        train_evo_meta_loop()
    except Exception as e:
        print(f"[âš ï¸ ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ì‹¤íŒ¨] {e}")

    print("âœ… train_models ì™„ë£Œ")

def train_all_models():
    """SYMBOLS ì „ì²´ ë°˜ë³µ í•™ìŠµ (ê°„ë‹¨ ë²„ì „)"""
    train_models(SYMBOLS)

# --------------------------------------------------
# ê°œë³„ ì „ëµ ë¬´í•œ ë£¨í”„ (ì˜µì…˜)
# --------------------------------------------------
def train_model_loop(strategy):
    global training_in_progress
    if training_in_progress.get(strategy, False):
        print(f"âš ï¸ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: {strategy}")
        return
    training_in_progress[strategy] = True
    print(f"ğŸš€ {strategy} ë¬´í•œ í•™ìŠµ ë£¨í”„ ì‹œì‘")

    try:
        for symbol in SYMBOLS:
            train_one_model(symbol, strategy, group_id=0)
    finally:
        training_in_progress[strategy] = False
        print(f"âœ… {strategy} ë£¨í”„ ì¢…ë£Œ")

if __name__ == "__main__":
    # ì˜ˆì‹œ: ì „ ì‹¬ë³¼ í•™ìŠµ
    train_all_models()
