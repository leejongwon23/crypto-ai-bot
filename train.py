import os, json, torch, torch.nn as nn, numpy as np, datetime, pytz, sys, pandas as pd
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score
from data.utils import SYMBOLS, get_kline_by_strategy, compute_features, create_dataset
from model.base_model import get_model
from model_weight_loader import get_model_weight
from feature_importance import compute_feature_importance, save_feature_importance
from wrong_data_loader import load_training_prediction_data
from failure_db import load_existing_failure_hashes
from logger import log_training_result, strategy_stats, load_failure_count
from window_optimizer import find_best_window
import hashlib
from collections import Counter
import sqlite3
from config import NUM_CLASSES


DEVICE = torch.device("cpu")
MODEL_DIR = "/persistent/models"
os.makedirs(MODEL_DIR, exist_ok=True)
now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))
STRATEGY_WRONG_REP = {"ë‹¨ê¸°": 4, "ì¤‘ê¸°": 6, "ì¥ê¸°": 8}


def get_feature_hash_from_tensor(x):
    """
    âœ… [ì„¤ëª…] ë§ˆì§€ë§‰ timestep featureë¥¼ ë°˜ì˜¬ë¦¼ í›„ sha1 í•´ì‹œê°’ìœ¼ë¡œ ë³€í™˜
    - ì¤‘ë³µëœ feature í•™ìŠµì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì‚¬ìš©
    """
    if x.ndim != 2 or x.shape[0] == 0:
        return "invalid"
    last = x[-1].tolist()
    rounded = [round(float(val), 2) for val in last]
    return hashlib.sha1(",".join(map(str, rounded)).encode()).hexdigest()

def get_frequent_failures(min_count=5):
    """
    âœ… [ì„¤ëª…] failure_patterns.dbì—ì„œ ë™ì¼ ì‹¤íŒ¨ê°€ min_count ì´ìƒì´ë©´ ë°˜í™˜
    - ì‹¤íŒ¨ ì§‘ì¤‘ í•™ìŠµ(targeted fine-tuning)ì— ì‚¬ìš©
    """
    counter = Counter()
    try:
        with sqlite3.connect("/persistent/logs/failure_patterns.db") as conn:
            rows = conn.execute("SELECT hash FROM failure_patterns").fetchall()
            for row in rows:
                counter[row[0]] += 1
    except:
        return set()
    return {h for h, cnt in counter.items() if cnt >= min_count}

def save_model_metadata(symbol, strategy, model_type, acc, f1, loss, input_size=None, class_counts=None):
    """
    âœ… [ì„¤ëª…] ëª¨ë¸ ë©”íƒ€ì •ë³´ë¥¼ jsonìœ¼ë¡œ ì €ì¥
    - acc, f1, loss, input_size, í´ë˜ìŠ¤ë¶„í¬ ë“± ê¸°ë¡
    """
    meta = {
        "symbol": symbol,
        "strategy": strategy,
        "model": model_type or "unknown",
        "input_size": int(input_size) if input_size else 11,
        "accuracy": float(round(acc, 4)),
        "f1_score": float(round(f1, 4)),
        "loss": float(round(loss, 6)),
        "timestamp": now_kst().strftime("%Y-%m-%d %H:%M:%S")
    }

    if class_counts:
        meta["class_counts"] = {str(k): int(v) for k, v in class_counts.items()}

    path = f"{MODEL_DIR}/{symbol}_{strategy}_{model_type}.meta.json"
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(meta, f, indent=2, ensure_ascii=False)
        print(f"ğŸ—˜ ì €ì¥ë¨: {path} (model={model_type}, input_size={meta['input_size']})")
    except Exception as e:
        print(f"[ERROR] meta ì €ì¥ ì‹¤íŒ¨: {e}")

def train_one_model(symbol, strategy, max_epochs=20):
    """
    âœ… [ì„¤ëª…] YOPOì˜ í•µì‹¬ í•™ìŠµ í•¨ìˆ˜
    - feature ìƒì„± â†’ dataset ìƒì„± â†’ ëª¨ë¸ í•™ìŠµ â†’ ë©”íƒ€ì €ì¥ê¹Œì§€ ìˆ˜í–‰
    """
    import os, gc
    import numpy as np
    import pandas as pd
    import torch
    import datetime, pytz
    from collections import Counter
    from model.base_model import get_model
    from feature_importance import compute_feature_importance, save_feature_importance
    from failure_db import load_existing_failure_hashes
    from focal_loss import FocalLoss
    from sklearn.metrics import accuracy_score, f1_score
    from torch.utils.data import TensorDataset, DataLoader
    from config import NUM_CLASSES
    from wrong_data_loader import load_training_prediction_data
    from logger import log_training_result, get_feature_hash_from_tensor
    from window_optimizer import find_best_window
    from data.utils import get_kline_by_strategy, compute_features, create_dataset

    print(f"â–¶ í•™ìŠµ ì‹œì‘: {symbol}-{strategy}")
    MODEL_DIR = "/persistent/models"
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

    try:
        df = get_kline_by_strategy(symbol, strategy)
        if df is None or df.empty:
            print("â›” ì¤‘ë‹¨: get_kline_by_strategy() â†’ ë°ì´í„° ì—†ìŒ")
            return

        df_feat = compute_features(symbol, df, strategy)
        if df_feat is None or df_feat.empty or df_feat.isnull().any().any():
            print("â›” ì¤‘ë‹¨: compute_features ê²°ê³¼ ë¶€ì¡± ë˜ëŠ” NaN")
            return

        if "timestamp" not in df_feat.columns:
            df_feat["timestamp"] = df_feat.get("datetime", pd.Timestamp.now())
        df_feat = df_feat.dropna().reset_index(drop=True)
        features = df_feat.to_dict(orient="records")
                window = find_best_window(symbol, strategy)
        if not isinstance(window, int) or window <= 0:
            print(f"â›” ì¤‘ë‹¨: find_best_window ì‹¤íŒ¨ â†’ {window}")
            return

        if df_feat.shape[0] < window + 1:
            print(f"â›” ì¤‘ë‹¨: feature ìˆ˜ ë¶€ì¡± â†’ í•„ìš” {window + 1}, í˜„ì¬ {df_feat.shape[0]}")
            return

        X_raw, y_raw = create_dataset(features, window=window, strategy=strategy)
        if X_raw is None or y_raw is None or len(X_raw) < 5:
            print("â›” ì¤‘ë‹¨: í•™ìŠµ ë°ì´í„° ìƒì„± ì‹¤íŒ¨")
            return

        # âœ… ë¼ë²¨ í•„í„°ë§
        y_raw = np.array(y_raw)
        X_raw = np.array(X_raw, dtype=np.float32)
        mask = (y_raw >= 0) & (y_raw < NUM_CLASSES)
        y_raw = y_raw[mask]
        X_raw = X_raw[mask]

        if len(X_raw) < 5:
            print(f"â›” ì¤‘ë‹¨: ìœ íš¨ í•™ìŠµ ìƒ˜í”Œ ë¶€ì¡± ({len(X_raw)})")
            return

        if len(set(y_raw)) < 2:
            print(f"â›” ì¤‘ë‹¨: í´ë˜ìŠ¤ ë‹¤ì–‘ì„± ë¶€ì¡± ({len(set(y_raw))}ì¢…)")
            return

        input_size = X_raw.shape[2]
        val_len = max(5, int(len(X_raw) * 0.2))
        X_train, y_train = X_raw[:-val_len], y_raw[:-val_len]
        X_val, y_val = X_raw[-val_len:], y_raw[-val_len:]

        class_counts = Counter(y_train)

        # âœ… ëª¨ë¸ í•™ìŠµ ë£¨í”„
        for model_type in ["lstm", "cnn_lstm", "transformer"]:
            model = get_model(model_type, input_size=input_size, output_size=NUM_CLASSES).to(DEVICE).train()
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
            lossfn = FocalLoss(gamma=2)

            train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                     torch.tensor(y_train, dtype=torch.long))
            train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=2)

            for _ in range(max_epochs):
                model.train()
                for xb, yb in train_loader:
                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)
                    logits = model(xb)
                    loss = lossfn(logits, yb)
                    if torch.isfinite(loss):
                        optimizer.zero_grad(); loss.backward(); optimizer.step()

            # âœ… ê²€ì¦
            model.eval()
            with torch.no_grad():
                xb = torch.tensor(X_val, dtype=torch.float32).to(DEVICE)
                yb = torch.tensor(y_val, dtype=torch.long).to(DEVICE)
                logits = model(xb)
                preds = torch.argmax(logits, dim=1).cpu().numpy()
                acc = accuracy_score(y_val, preds)
                f1 = f1_score(y_val, preds, average="macro")
                val_loss = lossfn(logits, yb).item()
                print(f"[ê²€ì¦ ì„±ëŠ¥] {model_type} acc={acc:.4f}, f1={f1:.4f}, loss={val_loss:.4f}")

            # âœ… ë©”íƒ€ ì €ì¥ ë° feature importance ì €ì¥
            log_training_result(symbol, strategy, model_type, acc, f1, val_loss)
            torch.save(model.state_dict(), f"{MODEL_DIR}/{symbol}_{strategy}_{model_type}.pt")
            save_model_metadata(symbol, strategy, model_type, acc, f1, val_loss,
                                input_size=input_size, class_counts=class_counts)

            try:
                imps = compute_feature_importance(model, xb, yb, list(df_feat.drop(columns=["timestamp"]).columns))
                save_feature_importance(imps, symbol, strategy, model_type)
            except:
                pass

            del model, xb, yb, logits
            torch.cuda.empty_cache()
            gc.collect()

    except Exception as e:
        print(f"[ì˜¤ë¥˜] {symbol}-{strategy} â†’ {e}")
        try:
            log_training_result(symbol, strategy, f"ì‹¤íŒ¨({str(e)})", 0.0, 0.0, 0.0)
        except:
            print("âš ï¸ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨")

def balance_classes(X, y, min_samples=20, target_classes=None):
    """
    âœ… [ì„¤ëª…] í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ê° í´ë˜ìŠ¤ë³„ ìµœì†Œ ìƒ˜í”Œìˆ˜ë¥¼ ë§ì¶¤
    - ì—†ëŠ” í´ë˜ìŠ¤ëŠ” noise augmentation ìœ¼ë¡œ 1ê°œ ìƒì„±
    """
    from collections import Counter
    import random
    import numpy as np

    if target_classes is None:
        target_classes = range(NUM_CLASSES)

    class_counts = Counter(y)
    max_count = max(class_counts.values()) if class_counts else 0
    X_balanced, y_balanced = list(X), list(y)
    original_counts = dict(class_counts)

    for cls in target_classes:
        count = class_counts.get(cls, 0)

        if count == 0:
            if len(X) > 0:
                sample_shape = X[0].shape
                noise_sample = np.random.normal(loc=0.0, scale=1.0, size=sample_shape).astype(np.float32)
                X_balanced.append(noise_sample)
                y_balanced.append(cls)
                class_counts[cls] = 1
                print(f"âš ï¸ zero sample í´ë˜ìŠ¤ {cls}: random noise ìƒ˜í”Œ 1ê°œ ìƒì„±")

        existing = [(x, y_val) for x, y_val in zip(X, y) if y_val == cls]
        while class_counts[cls] < max(min_samples, int(max_count * 0.8)) and existing:
            x_dup, y_dup = random.choice(existing)
            X_balanced.append(x_dup)
            y_balanced.append(y_dup)
            class_counts[cls] += 1

    print("ğŸ“Š í´ë˜ìŠ¤ ë³µì œ í˜„í™©:")
    for cls in target_classes:
        before = original_counts.get(cls, 0)
        after = class_counts.get(cls, 0)
        if after > before:
            print(f"  - í´ë˜ìŠ¤ {cls}: {before}ê°œ â†’ {after}ê°œ (ë³µì œë¨)")

    return np.array(X_balanced), np.array(y_balanced)

def train_all_models():
    """
    âœ… [ì„¤ëª…] SYMBOLS ì „ì²´ì— ëŒ€í•´ ë‹¨ê¸°, ì¤‘ê¸°, ì¥ê¸° í•™ìŠµ ìˆ˜í–‰
    - Telegram ì™„ë£Œ ë©”ì‹œì§€ ì „ì†¡ í¬í•¨
    """
    from telegram_bot import send_message
    strategies = ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]

    for strategy in strategies:
        if training_in_progress.get(strategy, False):
            print(f"âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘: {strategy} í•™ìŠµ ì¤‘ë³µ ë°©ì§€")
            continue

        print(f"\nğŸš€ ì „ëµ í•™ìŠµ ì‹œì‘: {strategy}")
        training_in_progress[strategy] = True

        try:
            for symbol in SYMBOLS:
                try:
                    print(f"â–¶ í•™ìŠµ ì‹œì‘: {symbol}-{strategy}")
                    train_one_model(symbol, strategy)
                except Exception as e:
                    print(f"[ì˜¤ë¥˜] {symbol}-{strategy} í•™ìŠµ ì‹¤íŒ¨ â†’ {e}")
        except Exception as e:
            print(f"[ì¹˜ëª… ì˜¤ë¥˜] {strategy} ì „ì²´ í•™ìŠµ ì¤‘ë‹¨ â†’ {type(e).__name__}: {e}")
        finally:
            training_in_progress[strategy] = False
            print(f"âœ… ì „ëµ í•™ìŠµ ì™„ë£Œ: {strategy}\n")

        # âœ… í•™ìŠµ í›„ prediction_log.csv ì¶œë ¥
        try:
            df = pd.read_csv("/persistent/prediction_log.csv", encoding="utf-8-sig")
            print("[âœ… prediction_log.csv ìƒìœ„ 20ì¤„ ì¶œë ¥]")
            print(df.head(20))
        except Exception as e:
            print(f"[ì˜¤ë¥˜] prediction_log.csv ë¡œë“œ ì‹¤íŒ¨ â†’ {e}")

        time.sleep(5)  # ë³‘ë ¬ ë°©ì§€

    send_message("âœ… ì „ì²´ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì˜ˆì¸¡ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

def train_models(symbol_list):
    """
    âœ… [ì„¤ëª…] íŠ¹ì • symbol_listì— ëŒ€í•´ ë‹¨ê¸°, ì¤‘ê¸°, ì¥ê¸° í•™ìŠµ ìˆ˜í–‰
    - meta ë³´ì • í›„ ì˜ˆì¸¡ê¹Œì§€ ìë™ ì‹¤í–‰
    """
    from telegram_bot import send_message
    from predict_test import main as run_prediction
    import maintenance_fix_meta

    strategies = ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]

    for strategy in strategies:
        if training_in_progress.get(strategy, False):
            print(f"âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘: {strategy} í•™ìŠµ ì¤‘ë³µ ë°©ì§€"); continue

        print(f"\nğŸš€ ì „ëµ í•™ìŠµ ì‹œì‘: {strategy}")
        training_in_progress[strategy] = True

        try:
            for symbol in symbol_list:
                try:
                    print(f"â–¶ í•™ìŠµ ì‹œì‘: {symbol}-{strategy}")
                    train_one_model(symbol, strategy)
                except Exception as e:
                    print(f"[ì˜¤ë¥˜] {symbol}-{strategy} í•™ìŠµ ì‹¤íŒ¨ â†’ {e}")
        except Exception as e:
            print(f"[ì¹˜ëª… ì˜¤ë¥˜] {strategy} ì „ì²´ í•™ìŠµ ì¤‘ë‹¨ â†’ {type(e).__name__}: {e}")
        finally:
            training_in_progress[strategy] = False
            print(f"âœ… ì „ëµ í•™ìŠµ ì™„ë£Œ: {strategy}\n")

        time.sleep(5)  # ë³‘ë ¬ ë°©ì§€

        try:
            maintenance_fix_meta.fix_all_meta_json()
        except Exception as e:
            print(f"[âš ï¸ meta ë³´ì • ì‹¤íŒ¨] {e}")

        try:
            run_prediction(strategy, symbols=symbol_list)
        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {strategy} â†’ {e}")

    send_message("âœ… í•™ìŠµ ë° ì˜ˆì¸¡ ë£¨í‹´ ì™„ë£Œ (í•´ë‹¹ ì‹¬ë³¼ ê·¸ë£¹)")

def train_model_loop(strategy):
    """
    âœ… [ì„¤ëª…] íŠ¹ì • strategy í•™ìŠµì„ ë¬´í•œ ë£¨í”„ë¡œ ì‹¤í–‰
    - training_in_progress ìƒíƒœ ê´€ë¦¬ í¬í•¨
    """
    if training_in_progress.get(strategy, False):
        print(f"âš ï¸ ì´ë¯¸ ì‹¤í–‰ ì¤‘: {strategy} í•™ìŠµ ì¤‘ë³µ ë°©ì§€")
        return

    training_in_progress[strategy] = True
    print(f"ğŸ“Œ ìƒíƒœ ì§„ì… â†’ {training_in_progress}")

    try:
        for symbol in SYMBOLS:
            try:
                print(f"â–¶ í•™ìŠµ ì‹œì‘: {symbol}-{strategy}")
                train_one_model(symbol, strategy)
            except Exception as e:
                print(f"[í•™ìŠµ ì‹¤íŒ¨] {symbol}-{strategy} â†’ {e}")
    finally:
        training_in_progress[strategy] = False
        print(f"ğŸ“Œ ìƒíƒœ ì¢…ë£Œ â†’ {training_in_progress}")

def train_symbol_group_loop(delay_minutes=5):
    """
    âœ… [ì„¤ëª…] SYMBOL_GROUPS ë‹¨ìœ„ë¡œ ì „ì²´ ê·¸ë£¹ í•™ìŠµ ë£¨í”„ ì‹¤í–‰
    - ê° ê·¸ë£¹ í•™ìŠµ í›„ meta ë³´ì •, ì˜ˆì¸¡ ì‹¤í–‰ í¬í•¨
    """
    import time
    import maintenance_fix_meta
    from data.utils import SYMBOL_GROUPS
    group_count = len(SYMBOL_GROUPS)
    print(f"[ìë™ ë£¨í”„] ì „ì²´ {group_count}ê°œ ê·¸ë£¹ í•™ìŠµ ë£¨í”„ ì‹œì‘ë¨")

    while True:
        for idx, group in enumerate(SYMBOL_GROUPS):
            try:
                print(f"\nğŸš€ [ê·¸ë£¹ {idx}] í•™ìŠµ ì‹œì‘ â†’ {group}")

                train_models(group)

                try:
                    maintenance_fix_meta.fix_all_meta_json()
                    print(f"âœ… meta ë³´ì • ì™„ë£Œ (ê·¸ë£¹ {idx})")
                except Exception as e:
                    print(f"[âš ï¸ meta ë³´ì • ì‹¤íŒ¨] {e}")

                print(f"âœ… [ê·¸ë£¹ {idx}] í•™ìŠµ + ë³´ì • ì™„ë£Œ â†’ ì˜ˆì¸¡ ì‹œì‘")
                for symbol in group:
                    for strategy in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
                        try:
                            from recommend import main
                            main(symbol=symbol, strategy=strategy, force=True)
                        except Exception as e:
                            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨: {symbol}-{strategy} â†’ {e}")

                print(f"ğŸ•’ [ê·¸ë£¹ {idx}] ë‹¤ìŒ ê·¸ë£¹ê¹Œì§€ {delay_minutes}ë¶„ ëŒ€ê¸°")
                time.sleep(delay_minutes * 60)

            except Exception as e:
                print(f"âŒ ê·¸ë£¹ {idx} ë£¨í”„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue


