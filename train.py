# === train.py (final, drop-in) ===
import os, json, time, traceback, tempfile, io, errno
from datetime import datetime
import pytz
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import MinMaxScaler

from data.utils import SYMBOLS, get_kline_by_strategy, compute_features, create_dataset, SYMBOL_GROUPS
from model.base_model import get_model
from feature_importance import compute_feature_importance, save_feature_importance  # (ë¯¸ì‚¬ìš©ì‹œì—ë„ í˜¸í™˜ ìœ ì§€)
from failure_db import insert_failure_record, ensure_failure_db
from logger import log_training_result
from config import (
    get_NUM_CLASSES, get_FEATURE_INPUT_SIZE, get_class_groups,
    get_class_ranges, set_NUM_CLASSES
)
from data_augmentation import balance_classes

# --- window_optimizer: ì •ì‹ API ì§ì ‘ ì„í¬íŠ¸ ---
from window_optimizer import find_best_window

# --- ssl_pretrain: ì—†ìœ¼ë©´ no-op ---
try:
    from ssl_pretrain import masked_reconstruction
except Exception:
    def masked_reconstruction(symbol, strategy, input_size):
        return None

# --- evo meta learner: í•™ìŠµ ë£¨í”„ (ì—†ì–´ë„ ì•±ì´ ì£½ì§€ ì•Šë„ë¡) ---
try:
    from evo_meta_learner import train_evo_meta_loop
except Exception:
    def train_evo_meta_loop(*args, **kwargs):
        return None

NUM_CLASSES = get_NUM_CLASSES()
FEATURE_INPUT_SIZE = get_FEATURE_INPUT_SIZE()

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_DIR = "/persistent/models"
os.makedirs(MODEL_DIR, exist_ok=True)

now_kst = lambda: datetime.now(pytz.timezone("Asia/Seoul"))
training_in_progress = {"ë‹¨ê¸°": False, "ì¤‘ê¸°": False, "ì¥ê¸°": False}

# --------------------------------------------------
# ìœ í‹¸
# --------------------------------------------------
def _atomic_write(path: str, bytes_or_str, mode: str = "wb"):
    """ì“°ê¸° ì‹¤íŒ¨/ì¤‘ë‹¨ ëŒ€ë¹„ ì›ìì  ì €ì¥."""
    dirpath = os.path.dirname(path)
    os.makedirs(dirpath, exist_ok=True)
    fd, tmppath = tempfile.mkstemp(dir=dirpath, prefix=".tmp_", suffix=".swap")
    try:
        with os.fdopen(fd, mode) as f:
            if "b" in mode:
                data = bytes_or_str if isinstance(bytes_or_str, (bytes, bytearray)) else bytes_or_str.encode("utf-8")
                f.write(data)
            else:
                f.write(bytes_or_str)
            f.flush()
            os.fsync(f.fileno())
        os.replace(tmppath, path)
    finally:
        try:
            if os.path.exists(tmppath):
                os.remove(tmppath)
        except Exception:
            pass

def _log_skip(symbol, strategy, reason):
    log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                        loss=0.0, note=reason, status="skipped")
    insert_failure_record({
        "symbol": symbol, "strategy": strategy, "model": "all",
        "predicted_class": -1, "success": False, "rate": "", "reason": reason
    }, feature_vector=[])

def _log_fail(symbol, strategy, reason):
    log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                        loss=0.0, note=reason, status="failed")
    insert_failure_record({
        "symbol": symbol, "strategy": strategy, "model": "all",
        "predicted_class": -1, "success": False, "rate": "", "reason": reason
    }, feature_vector=[])

def _strategy_horizon_hours(strategy: str) -> int:
    return {"ë‹¨ê¸°": 4, "ì¤‘ê¸°": 24, "ì¥ê¸°": 168}.get(strategy, 24)

def _future_returns_by_timestamp(df: pd.DataFrame, horizon_hours: int) -> np.ndarray:
    # ì•ˆì „ ì¡°ê¸° ë°˜í™˜ (ê¸°ì¡´ len(df or []) íŒ¨í„´ ì œê±°)
    if df is None or len(df) == 0 or "timestamp" not in df.columns:
        return np.zeros(0 if df is None else len(df), dtype=np.float32)

    ts = pd.to_datetime(df["timestamp"], errors="coerce")
    close = df["close"].astype(float).values
    high = (df["high"] if "high" in df.columns else df["close"]).astype(float).values

    if ts.dt.tz is None:
        ts = ts.dt.tz_localize("UTC").dt.tz_convert("Asia/Seoul")
    else:
        ts = ts.dt.tz_convert("Asia/Seoul")

    out = np.zeros(len(df), dtype=np.float32)
    horizon = pd.Timedelta(hours=horizon_hours)

    j_start = 0
    for i in range(len(df)):
        t0 = ts.iloc[i]; t1 = t0 + horizon
        j = max(j_start, i)
        max_h = high[i]
        while j < len(df) and ts.iloc[j] <= t1:
            if high[j] > max_h: max_h = high[j]
            j += 1
        j_start = max(j_start, i)
        base = close[i] if close[i] > 0 else (close[i] + 1e-6)
        out[i] = float((max_h - base) / (base + 1e-12))
    return out.astype(np.float32)

def _save_model_and_meta(model: nn.Module, path_pt: str, meta: dict):
    """ëª¨ë¸(.pt)ê³¼ ë©”íƒ€(.meta.json)ì„ í•­ìƒ ìŒìœ¼ë¡œ, ì›ìì ìœ¼ë¡œ ì €ì¥."""
    # 1) ëª¨ë¸ ì €ì¥ (to bytes -> atomic)
    buffer = io.BytesIO()
    torch.save(model.state_dict(), buffer)
    _atomic_write(path_pt, buffer.getvalue(), mode="wb")

    # 2) ë©”íƒ€ ì €ì¥ (atomic)
    meta_json = json.dumps(meta, ensure_ascii=False, indent=2)
    _atomic_write(path_pt.replace(".pt", ".meta.json"), meta_json, mode="w")

# --------------------------------------------------
# ë‹¨ì¼ (symbol, strategy, group_id) ëª¨ë¸ í•™ìŠµ
# --------------------------------------------------
def train_one_model(symbol, strategy, group_id=None, max_epochs=20):
    result = {
        "symbol": symbol, "strategy": strategy, "group_id": int(group_id or 0),
        "models": []  # ê° ëª¨ë¸ë³„ {type, acc, f1, loss, pt, meta}
    }
    try:
        print(f"âœ… [train_one_model ì‹œì‘] {symbol}-{strategy}-group{group_id}")
        ensure_failure_db()

        # 0) SSL í”„ë¦¬íŠ¸ë ˆì¸ (ì‹¤íŒ¨í•´ë„ ê³„ì†)
        try:
            masked_reconstruction(symbol, strategy, FEATURE_INPUT_SIZE)
        except Exception as e:
            print(f"[âš ï¸ SSL ì‚¬ì „í•™ìŠµ ì‹¤íŒ¨] {e}")

        # 1) ë°ì´í„° ë¡œë“œ
        df = get_kline_by_strategy(symbol, strategy)
        if df is None or df.empty:
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ ë°ì´í„° ì—†ìŒ")
            _log_skip(symbol, strategy, "ë°ì´í„° ì—†ìŒ"); return result

        feat = compute_features(symbol, df, strategy)
        if feat is None or feat.empty or feat.isnull().any().any():
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ í”¼ì²˜ ì—†ìŒ/NaN")
            _log_skip(symbol, strategy, "í”¼ì²˜ ì—†ìŒ"); return result

        # 2) í´ë˜ìŠ¤ ê²½ê³„/ë¼ë²¨ë§
        try:
            class_ranges = get_class_ranges(symbol=symbol, strategy=strategy, group_id=group_id)
        except Exception as e:
            print(f"[âŒ í´ë˜ìŠ¤ ë²”ìœ„ ê³„ì‚° ì‹¤íŒ¨] {e}")
            _log_fail(symbol, strategy, "í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨"); return result

        num_classes = len(class_ranges)
        set_NUM_CLASSES(num_classes)

        horizon_hours = _strategy_horizon_hours(strategy)
        future_gains = _future_returns_by_timestamp(df, horizon_hours=horizon_hours)

        labels = []
        for r in future_gains:
            idx = 0
            for i, (lo, hi) in enumerate(class_ranges):
                if lo <= r <= hi:
                    idx = i; break
            labels.append(idx)
        labels = np.array(labels, dtype=np.int64)

        # 3) ë™ì  ìœˆë„ìš°
        features_only = feat.drop(columns=["timestamp", "strategy"], errors="ignore")
        feat_scaled = MinMaxScaler().fit_transform(features_only)

        try:
            window_list = [10, 20, 30, 40, 60]
            best_window = find_best_window(symbol, strategy, window_list=window_list, group_id=group_id)
        except Exception as e:
            print(f"[âš ï¸ find_best_window ì‹¤íŒ¨] {e}"); best_window = 60
        window = int(max(5, best_window))
        print(f"[ğŸ”§ ì„ íƒëœ WINDOW] {symbol}-{strategy} â†’ {window}")

        # 4) ì‹œí€€ìŠ¤ ìƒì„±
        X, y = [], []
        for i in range(len(feat_scaled) - window):
            X.append(feat_scaled[i:i+window])
            y_idx = i + window - 1
            y.append(labels[y_idx] if 0 <= y_idx < len(labels) else 0)
        X, y = np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)
        print(f"[ğŸ“Š ì´ˆê¸° ì‹œí€€ìŠ¤] {symbol}-{strategy} â†’ {len(y)}ê±´")

        # fallback: ìƒ˜í”Œ ì ì„ ë•Œ
        if len(X) < 20:
            print("[â„¹ï¸ ì•ˆì „ ë³´ê°•: create_dataset fallback ì‚¬ìš©]")
            feat_records = feat.to_dict(orient="records")
            try:
                res = create_dataset(feat_records, window=window, strategy=strategy, input_size=FEATURE_INPUT_SIZE)
                if isinstance(res, tuple) and len(res) >= 2: X_fb, y_fb = res[0], res[1]
                else: X_fb, y_fb = res
                if isinstance(X_fb, np.ndarray) and len(X_fb) > 0:
                    X, y = X_fb.astype(np.float32), y_fb.astype(np.int64)
                    print(f"[âœ… fallback ì ìš©] ìµœì¢… ìƒ˜í”Œ: {len(y)}")
            except Exception as e:
                print(f"[âš ï¸ fallback ì‹¤íŒ¨] {e}")

        if len(X) < 10:
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ ìµœì¢… ìƒ˜í”Œ ë¶€ì¡±({len(X)})")
            _log_skip(symbol, strategy, "ìµœì¢… ìƒ˜í”Œ ë¶€ì¡±"); return result

        # 5) ë°¸ëŸ°ì‹±
        try:
            if len(X) < 200:
                X, y = balance_classes(X, y, num_classes=num_classes)
                print(f"[âœ… ì¦ê°•/ë°¸ëŸ°ì‹± ì™„ë£Œ] ì´ ìƒ˜í”Œ: {len(X)}")
        except Exception as e:
            print(f"[âš ï¸ ë°¸ëŸ°ì‹± ì‹¤íŒ¨] {e}")

        # 6) í•™ìŠµ/í‰ê°€/ì €ì¥
        for model_type in ["lstm", "cnn_lstm", "transformer"]:
            print(f"[ğŸ§  í•™ìŠµ ì‹œì‘] {model_type} | {symbol}-{strategy}-group{group_id}")
            model = get_model(model_type, input_size=FEATURE_INPUT_SIZE, output_size=num_classes).to(DEVICE)
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
            criterion = nn.CrossEntropyLoss()

            val_len = max(1, int(len(X) * 0.2))
            if len(X) - val_len < 1: val_len = len(X) - 1
            train_X, val_X = X[:-val_len], X[-val_len:]
            train_y, val_y = y[:-val_len], y[-val_len:]

            train_loader = DataLoader(TensorDataset(torch.tensor(train_X), torch.tensor(train_y)), batch_size=64, shuffle=True)
            val_loader = DataLoader(TensorDataset(torch.tensor(val_X), torch.tensor(val_y)), batch_size=64)

            total_loss = 0.0
            last_loss = 0.0
            for epoch in range(max_epochs):
                model.train()
                for xb, yb in train_loader:
                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)
                    logits = model(xb)
                    loss = criterion(logits, yb)
                    if not torch.isfinite(loss): continue
                    optimizer.zero_grad(); loss.backward(); optimizer.step()
                    total_loss += float(loss.item()); last_loss = float(loss.item())
                if (epoch + 1) % 5 == 0 or epoch == max_epochs - 1:
                    print(f"[ğŸ“ˆ {model_type}] Epoch {epoch+1}/{max_epochs} | loss={last_loss:.4f}")

            model.eval()
            all_preds, all_labels = [], []
            with torch.no_grad():
                for xb, yb in val_loader:
                    preds = torch.argmax(model(xb.to(DEVICE)), dim=1).cpu().numpy()
                    all_preds.extend(preds); all_labels.extend(yb.numpy())
            acc = float(accuracy_score(all_labels, all_preds))
            f1 = float(f1_score(all_labels, all_preds, average="macro"))
            print(f"[ğŸ¯ {model_type}] acc={acc:.4f}, f1={f1:.4f}")

            # íŒŒì¼ ì €ì¥(ì›ìì )
            model_name = f"{symbol}_{strategy}_{model_type}_group{group_id}_cls{num_classes}.pt"
            model_path = os.path.join(MODEL_DIR, model_name)
            meta = {
                "symbol": symbol,
                "strategy": strategy,
                "model": model_type,
                "group_id": int(group_id) if group_id is not None else 0,
                "num_classes": int(num_classes),
                "input_size": int(FEATURE_INPUT_SIZE),
                "metrics": {"val_acc": acc, "val_f1": f1, "train_loss_sum": float(total_loss)},
                "timestamp": now_kst().isoformat(),
                "model_name": model_name
            }
            _save_model_and_meta(model, model_path, meta)

            log_training_result(
                symbol=symbol, strategy=strategy, model=model_name,
                accuracy=acc, f1=f1, loss=float(total_loss),
                note=f"train_one_model(window={window})",
                source_exchange="BYBIT", status="success",
            )

            result["models"].append({
                "type": model_type, "acc": acc, "f1": f1,
                "loss_sum": float(total_loss), "pt": model_path,
                "meta": model_path.replace(".pt", ".meta.json")
            })

            # GPU ë©”ëª¨ë¦¬ ì²­ì†Œ
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

        print(f"[âœ… train_one_model ì™„ë£Œ] {symbol}-{strategy}-group{group_id}")
        return result

    except Exception as e:
        print(f"[âŒ train_one_model ì‹¤íŒ¨] {symbol}-{strategy}-group{group_id} â†’ {e}")
        traceback.print_exc()
        log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                            loss=0.0, note=str(e), status="failed")
        insert_failure_record({
            "symbol": symbol, "strategy": strategy, "model": "all",
            "predicted_class": -1, "success": False, "rate": "", "reason": str(e)
        }, feature_vector=[])
        return result

# --------------------------------------------------
# ì „ì²´ í•™ìŠµ ë£¨í‹´
# --------------------------------------------------
def train_models(symbol_list):
    strategies = ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]
    print(f"ğŸš€ [train_models] ì‹¬ë³¼ í•™ìŠµ ì‹œì‘: {symbol_list}")

    for symbol in symbol_list:
        print(f"\nğŸ” [ì‹¬ë³¼] {symbol}")
        for strategy in strategies:
            print(f"â–¶ {symbol}-{strategy} ì „ì²´ ê·¸ë£¹ í•™ìŠµ")
            try:
                class_ranges = get_class_ranges(symbol=symbol, strategy=strategy)
                if not class_ranges:
                    raise ValueError("ë¹ˆ í´ë˜ìŠ¤ ê²½ê³„")
                num_classes = len(class_ranges)
                groups = get_class_groups(num_classes=num_classes)
                max_gid = len(groups) - 1
            except Exception as e:
                print(f"[âŒ í´ë˜ìŠ¤ ê²½ê³„ ê³„ì‚° ì‹¤íŒ¨] {symbol}-{strategy}: {e}")
                _log_fail(symbol, strategy, f"í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
                continue

            for gid in range(max_gid + 1):
                train_one_model(symbol, strategy, group_id=gid)
                time.sleep(0.5)

    # ë©”íƒ€ ë³´ì •
    try:
        import maintenance_fix_meta
        maintenance_fix_meta.fix_all_meta_json()
    except Exception as e:
        print(f"[âš ï¸ meta ë³´ì • ì‹¤íŒ¨] {e}")

    # ì‹¤íŒ¨í•™ìŠµ ë£¨í”„
    try:
        import failure_trainer
        failure_trainer.run_failure_training()
    except Exception as e:
        print(f"[âš ï¸ ì‹¤íŒ¨í•™ìŠµ ë£¨í”„ ì˜ˆì™¸] {e}")

    # ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ
    try:
        train_evo_meta_loop()
    except Exception as e:
        print(f"[âš ï¸ ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ì‹¤íŒ¨] {e}")

    print("âœ… train_models ì™„ë£Œ")

def train_all_models():
    train_models(SYMBOLS)

# --- ì™¸ë¶€ ëª¨ë“ˆ í˜¸í™˜ìš© ì–‡ì€ ë˜í¼ (model_checker ë“±) ---
def train_model(symbol, strategy):
    """ë‹¨ì¼ ì‹¬ë³¼-ì „ëµ í•œ ê°œ í•™ìŠµ(ê·¸ë£¹0)."""
    return train_one_model(symbol, strategy, group_id=0)

# --------------------------------------------------
# ê·¸ë£¹ ë£¨í”„(ì•±ì´ ê¸°ëŒ€í•˜ëŠ” ì—”íŠ¸ë¦¬)
# --------------------------------------------------
def train_symbol_group_loop(sleep_sec: int = 0):
    """
    app.pyê°€ ê¸°ëŒ€í•˜ëŠ” í•¨ìˆ˜.
    SYMBOL_GROUPSë¥¼ ì•ì—ì„œë¶€í„° ì°¨ë¡€ë¡œ í•™ìŠµ. sleep_sec>0ì´ë©´ ê·¸ë£¹ ì‚¬ì´ ê°„ê²© ë‘ .
    """
    try:
        for idx, group in enumerate(SYMBOL_GROUPS):
            print(f"ğŸš€ [train_symbol_group_loop] ê·¸ë£¹ #{idx+1}/{len(SYMBOL_GROUPS)} â†’ {group}")
            train_models(group)
            if sleep_sec > 0:
                time.sleep(sleep_sec)
        print("âœ… train_symbol_group_loop ì™„ë£Œ")
    except Exception as e:
        print(f"[âŒ train_symbol_group_loop ì˜ˆì™¸] {e}")

# --------------------------------------------------
# ì „ëµë³„ ë¬´í•œ ë£¨í”„(ì˜µì…˜)
# --------------------------------------------------
def train_model_loop(strategy):
    global training_in_progress
    if training_in_progress.get(strategy, False):
        print(f"âš ï¸ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: {strategy}")
        return
    training_in_progress[strategy] = True
    print(f"ğŸš€ {strategy} ë¬´í•œ í•™ìŠµ ë£¨í”„ ì‹œì‘")
    try:
        for symbol in SYMBOLS:
            train_one_model(symbol, strategy, group_id=0)
    finally:
        training_in_progress[strategy] = False
        print(f"âœ… {strategy} ë£¨í”„ ì¢…ë£Œ")

if __name__ == "__main__":
    train_all_models()
