# === train.py (ìµœì¢…ë³¸) ===
import os
import json
import time
import traceback
import datetime
import pytz
from collections import Counter

import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import MinMaxScaler

from data.utils import SYMBOLS, get_kline_by_strategy, compute_features
from model.base_model import get_model
from model_weight_loader import get_model_weight
from feature_importance import compute_feature_importance, save_feature_importance
from wrong_data_loader import load_training_prediction_data
from failure_db import load_existing_failure_hashes, insert_failure_record, ensure_failure_db
from logger import log_training_result, load_failure_count, update_model_success
from window_optimizer import find_best_window
from data_augmentation import balance_classes
from config import (
    get_NUM_CLASSES,
    get_FEATURE_INPUT_SIZE,
    get_class_groups,
    get_class_ranges,
    set_NUM_CLASSES,
)

from ranger_adabelief import RangerAdaBelief as Ranger

NUM_CLASSES = get_NUM_CLASSES()
FEATURE_INPUT_SIZE = get_FEATURE_INPUT_SIZE()

training_in_progress = {"ë‹¨ê¸°": False, "ì¤‘ê¸°": False, "ì¥ê¸°": False}

DEVICE = torch.device("cpu")
MODEL_DIR = "/persistent/models"
os.makedirs(MODEL_DIR, exist_ok=True)
now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

STRATEGY_WRONG_REP = {"ë‹¨ê¸°": 4, "ì¤‘ê¸°": 6, "ì¥ê¸°": 8}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def get_feature_hash_from_tensor(x, use_full=False, precision=3):
    """
    ë§ˆì§€ë§‰ timestep(ê¸°ë³¸) ë˜ëŠ” ì „ì²´ featureë¥¼ ë°˜ì˜¬ë¦¼ í›„ sha1 í•´ì‹œê°’ìœ¼ë¡œ ë³€í™˜
    """
    import hashlib

    if x.ndim != 2 or x.shape[0] == 0:
        return "invalid"
    try:
        flat = x.flatten() if use_full else x[-1]
        rounded = [round(float(val), precision) for val in flat]
        return hashlib.sha1(",".join(map(str, rounded)).encode()).hexdigest()
    except Exception as e:
        print(f"[get_feature_hash_from_tensor ì˜¤ë¥˜] {e}")
        return "invalid"


def get_frequent_failures(min_count=5):
    """
    failure_patterns.dbì—ì„œ ë™ì¼ ì‹¤íŒ¨ê°€ min_count ì´ìƒì´ë©´ í•´ì‹œ ì§‘í•© ë°˜í™˜
    """
    import sqlite3

    counter = Counter()
    try:
        with sqlite3.connect("/persistent/logs/failure_patterns.db") as conn:
            rows = conn.execute("SELECT hash FROM failure_patterns").fetchall()
            for row in rows:
                counter[row[0]] += 1
    except Exception:
        pass
    return {h for h, cnt in counter.items() if cnt >= min_count}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•µì‹¬ í•™ìŠµ ë£¨í‹´
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_one_model(symbol, strategy, group_id=None, max_epochs=20):
    """
    ë‹¨ì¼ ì‹¬ë³¼/ì „ëµì— ëŒ€í•´ (group_id ì§€ì • ì‹œ í•´ë‹¹ ê·¸ë£¹ë§Œ) LSTM/CNN_LSTM/Transformer ëª¨ë¸ í•™ìŠµ
    """
    from ssl_pretrain import masked_reconstruction  # íŒŒì¼ëª… ê³ ì •: ssl_pretrain.py

    ensure_failure_db()
    input_size = get_FEATURE_INPUT_SIZE()
    group_ids = [group_id] if group_id is not None else [0]

    for gid in group_ids:
        model_saved = False
        try:
            print(f"âœ… [train_one_model ì‹œì‘] {symbol}-{strategy}-group{gid}")

            # SSL ì‚¬ì „í•™ìŠµ(ì‹¤íŒ¨í•´ë„ ê³„ì†)
            try:
                masked_reconstruction(symbol, strategy, input_size)
            except Exception as e:
                print(f"[âš ï¸ SSL ì‚¬ì „í•™ìŠµ ì‹¤íŒ¨] {e}")

            # ê°€ê²©/í”¼ì²˜
            df = get_kline_by_strategy(symbol, strategy)
            if df is None or df.empty:
                note = "ë°ì´í„° ì—†ìŒ"
                print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{gid} â†’ {note}")
                log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0, loss=0.0, note=note, status="skipped")
                insert_failure_record({"symbol": symbol, "strategy": strategy, "model": "all",
                                       "predicted_class": -1, "success": False, "rate": "", "reason": note}, feature_vector=[])
                return

            feat = compute_features(symbol, df, strategy)
            if feat is None or feat.empty:
                note = "í”¼ì²˜ ì—†ìŒ"
                print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{gid} â†’ {note}")
                log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0, loss=0.0, note=note, status="skipped")
                insert_failure_record({"symbol": symbol, "strategy": strategy, "model": "all",
                                       "predicted_class": -1, "success": False, "rate": "", "reason": note}, feature_vector=[])
                return

            features_only = feat.drop(columns=["timestamp", "strategy"], errors="ignore")
            feat_scaled = MinMaxScaler().fit_transform(features_only)

            # í´ë˜ìŠ¤ ê²½ê³„ & ë¼ë²¨ë§
            try:
                class_ranges = get_class_ranges(symbol=symbol, strategy=strategy, group_id=gid)
            except Exception as e:
                note = f"í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}"
                print(f"[âŒ í´ë˜ìŠ¤ ë²”ìœ„ ê³„ì‚° ì‹¤íŒ¨] {note}")
                log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0, loss=0.0, note=note, status="failed")
                insert_failure_record({"symbol": symbol, "strategy": strategy, "model": "all",
                                       "predicted_class": -1, "success": False, "rate": "", "reason": note}, feature_vector=[])
                return

            num_classes = len(class_ranges)
            set_NUM_CLASSES(num_classes)

            returns = df["close"].pct_change().fillna(0).values
            labels = []
            for r in returns:
                matched = False
                for i, (low, high) in enumerate(class_ranges):
                    if low <= r <= high:
                        labels.append(i)
                        matched = True
                        break
                if not matched:
                    labels.append(0)

            # ìœˆë„ìš° ë° ë°ì´í„°ì…‹
            window = 60
            X, y = [], []
            for i in range(len(feat_scaled) - window):
                X.append(feat_scaled[i:i + window])
                y.append(labels[i + window] if i + window < len(labels) else 0)
            X, y = np.array(X), np.array(y)
            print(f"[ğŸ“Š ì´ˆê¸° ìƒ˜í”Œ ìˆ˜] {len(X)}ê±´ (classes={num_classes})")

            # ë¶€ì¡± ì‹œ ì¦ê°•
            if len(X) < 50:
                print(f"[âš ï¸ ë°ì´í„° ë¶€ì¡± â†’ ì¦ê°•] {symbol}-{strategy}")
                try:
                    X, y = balance_classes(X, y, num_classes=num_classes)
                    print(f"[âœ… ì¦ê°• ì™„ë£Œ] ì´ ìƒ˜í”Œ ìˆ˜: {len(X)}")
                except Exception as e:
                    note = f"ì¦ê°• ì‹¤íŒ¨: {e}"
                    print(f"[âŒ ì¦ê°• ì‹¤íŒ¨] {note}")
                    insert_failure_record({"symbol": symbol, "strategy": strategy, "model": "all",
                                           "predicted_class": -1, "success": False, "rate": "", "reason": note}, feature_vector=[])
                    return

            # ì‹¤íŒ¨ ìƒ˜í”Œ ë³‘í•©
            fail_X, fail_y = load_training_prediction_data(symbol, strategy, input_size, window, group_id=gid)
            if fail_X is not None and len(fail_X) > 0:
                print(f"[ğŸ“Œ ì‹¤íŒ¨ ìƒ˜í”Œ ë³‘í•©] {len(fail_X)}ê±´")
                unique_hashes, merged_X, merged_y = {}, [], []
                for i in range(len(fail_X)):
                    h = get_feature_hash_from_tensor(torch.tensor(fail_X[i:i+1], dtype=torch.float32))
                    if h not in unique_hashes:
                        unique_hashes[h] = True
                        merged_X.append(fail_X[i]); merged_y.append(fail_y[i])
                for i in range(len(X)):
                    h = get_feature_hash_from_tensor(torch.tensor(X[i:i+1], dtype=torch.float32))
                    if h not in unique_hashes:
                        unique_hashes[h] = True
                        merged_X.append(X[i]); merged_y.append(y[i])
                X, y = np.array(merged_X), np.array(merged_y)
                print(f"[ğŸ“Š ë³‘í•© í›„ ìƒ˜í”Œ ìˆ˜] {len(X)}ê±´")

            if len(X) < 10:
                note = f"ìµœì¢… ìƒ˜í”Œ ë¶€ì¡± ({len(X)})"
                print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{gid} â†’ {note}")
                log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0, loss=0.0, note=note, status="skipped")
                insert_failure_record({"symbol": symbol, "strategy": strategy, "model": "all",
                                       "predicted_class": -1, "success": False, "rate": "", "reason": note}, feature_vector=[])
                return

            # ëª¨ë¸ë³„ í•™ìŠµ
            for model_type in ["lstm", "cnn_lstm", "transformer"]:
                print(f"[ğŸ§  í•™ìŠµ ì‹œì‘] {model_type} ëª¨ë¸")
                model = get_model(model_type, input_size=input_size, output_size=num_classes).to(DEVICE)

                model_name = f"{symbol}_{strategy}_{model_type}_group{gid}_cls{num_classes}.pt"
                model_path = os.path.join(MODEL_DIR, model_name)

                optimizer = Ranger(model.parameters(), lr=0.001)
                criterion = torch.nn.CrossEntropyLoss()

                ratio = max(1, int(len(X) * 0.8))
                X_train = torch.tensor(X[:ratio], dtype=torch.float32)
                y_train = torch.tensor(y[:ratio], dtype=torch.long)
                X_val = torch.tensor(X[ratio:], dtype=torch.float32)
                y_val = torch.tensor(y[ratio:], dtype=torch.long)

                train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=64, shuffle=True)
                val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=64)

                total_loss = 0.0
                for epoch in range(max_epochs):
                    model.train()
                    for xb, yb in train_loader:
                        xb, yb = xb.to(DEVICE), yb.to(DEVICE)
                        optimizer.zero_grad()
                        loss = criterion(model(xb), yb)
                        loss.backward()
                        optimizer.step()
                        total_loss += loss.item()
                    if (epoch + 1) % 5 == 0 or epoch == max_epochs - 1:
                        print(f"[ğŸ“ˆ Epoch {epoch+1}/{max_epochs}] Loss: {loss.item():.4f}")

                # í‰ê°€
                model.eval()
                all_preds, all_labels = [], []
                with torch.no_grad():
                    for xb, yb in val_loader:
                        preds = torch.argmax(model(xb.to(DEVICE)), dim=1).cpu().numpy()
                        all_preds.extend(preds); all_labels.extend(yb.numpy())
                acc = accuracy_score(all_labels, all_preds) if all_labels else 0.0
                f1 = f1_score(all_labels, all_preds, average='macro') if all_labels else 0.0
                print(f"[ğŸ¯ {model_type}] acc={acc:.4f}, f1={f1:.4f}")

                # ì €ì¥ + ë©”íƒ€
                os.makedirs(MODEL_DIR, exist_ok=True)
                torch.save(model.state_dict(), model_path)
                with open(model_path.replace(".pt", ".meta.json"), "w", encoding="utf-8") as f:
                    json.dump({
                        "symbol": symbol, "strategy": strategy, "model": model_type,
                        "group_id": gid, "num_classes": num_classes,
                        "input_size": input_size, "timestamp": now_kst().isoformat(),
                        "fail_data_merged": bool(fail_X is not None and len(fail_X) > 0),
                        "model_name": model_name
                    }, f, ensure_ascii=False, indent=2)

                # ë¡œê·¸ ê¸°ë¡ (noteë§Œ ì‚¬ìš©)
                log_training_result(symbol, strategy, model=model_name, accuracy=acc, f1=f1, loss=float(total_loss), note="trained", status="success")

                # ì„±ê³µ DB ì—…ë°ì´íŠ¸(ê¸°ë³¸ ê¸°ì¤€: acc>0.6 and f1>0.55)
                try:
                    update_model_success(symbol, strategy, model_type, bool(acc > 0.6 and f1 > 0.55))
                except Exception as e:
                    print(f"[âš ï¸ update_model_success ì‹¤íŒ¨] {e}")

                print(f"[âœ… {model_type} ëª¨ë¸ í•™ìŠµ ì™„ë£Œ] acc={acc:.4f}, f1={f1:.4f}")
                model_saved = True

        except Exception as e:
            print(f"[âŒ train_one_model ì‹¤íŒ¨] {symbol}-{strategy}-group{gid} â†’ {e}")
            traceback.print_exc()
            insert_failure_record({"symbol": symbol, "strategy": strategy, "model": "all",
                                   "predicted_class": -1, "success": False, "rate": "", "reason": str(e)}, feature_vector=[])

        # í•™ìŠµ ì „ë¶€ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ì €ì¥(ì˜ˆì¸¡ íŒŒì´í”„ ë³´í˜¸)
        if not model_saved:
            print(f"[âš ï¸ {symbol}-{strategy}-group{gid}] í•™ìŠµ ì‹¤íŒ¨ â†’ ë”ë¯¸ ì €ì¥")
            for model_type in ["lstm", "cnn_lstm", "transformer"]:
                model_name = f"{symbol}_{strategy}_{model_type}_group{gid}_cls3.pt"
                model_path = os.path.join(MODEL_DIR, model_name)
                dummy = get_model(model_type, input_size=input_size, output_size=3).to("cpu")
                torch.save(dummy.state_dict(), model_path)
                with open(model_path.replace(".pt", ".meta.json"), "w", encoding="utf-8") as f:
                    json.dump({"symbol": symbol, "strategy": strategy, "model": model_type, "model_name": model_name},
                              f, ensure_ascii=False, indent=2)
            log_training_result(symbol, strategy, model="dummy", accuracy=0.0, f1=0.0, loss=0.0, note="dummy_saved", status="failed")
            insert_failure_record({"symbol": symbol, "strategy": strategy, "model": "all",
                                   "predicted_class": -1, "success": False, "rate": "", "reason": "ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨"}, feature_vector=[])


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì „ì²´/ë£¨í”„ í•™ìŠµ í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def train_all_models():
    """
    SYMBOLS ì „ì²´ì— ëŒ€í•´ ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° í•™ìŠµ
    """
    strategies = ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]

    for strategy in strategies:
        if training_in_progress.get(strategy, False):
            print(f"âš ï¸ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: {strategy}")
            continue

        print(f"ğŸš€ {strategy} í•™ìŠµ ì‹œì‘")
        training_in_progress[strategy] = True

        try:
            for symbol in SYMBOLS:
                try:
                    train_one_model(symbol, strategy)
                except Exception as e:
                    print(f"[ì˜¤ë¥˜] {symbol}-{strategy} í•™ìŠµ ì‹¤íŒ¨: {e}")
        except Exception as e:
            print(f"[ì¹˜ëª… ì˜¤ë¥˜] {strategy} í•™ìŠµ ì¤‘ë‹¨: {e}")
        finally:
            training_in_progress[strategy] = False
            print(f"âœ… {strategy} í•™ìŠµ ì™„ë£Œ")

        time.sleep(3)


def train_models(symbol_list):
    """
    ì£¼ì–´ì§„ ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ ëª¨ë“  ì „ëµ/ê·¸ë£¹ í•™ìŠµ â†’ ë©”íƒ€ ë³´ì •/ì‹¤íŒ¨í•™ìŠµ/ì§„í™”í˜• ë©”íƒ€ë£¨í”„ í˜¸ì¶œ
    """
    import maintenance_fix_meta
    from evo_meta_learner import train_evo_meta_loop
    import safe_cleanup

    strategies = ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]
    print(f"ğŸš€ [train_models] ì‹¬ë³¼ í•™ìŠµ ì‹œì‘: {symbol_list}")

    for symbol in symbol_list:
        print(f"\nğŸ” [ì‹¬ë³¼ ì‹œì‘] {symbol}")
        for strategy in strategies:
            if training_in_progress.get(strategy, False):
                print(f"âš ï¸ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: {strategy}")
                continue

            training_in_progress[strategy] = True
            try:
                train_one_model(symbol, strategy, group_id=None)
            except Exception as e:
                print(f"[âŒ í•™ìŠµ ì‹¤íŒ¨] {symbol}-{strategy} â†’ {e}")
            finally:
                training_in_progress[strategy] = False
                print(f"âœ… {symbol}-{strategy} ì „ì²´ ê·¸ë£¹ í•™ìŠµ ì™„ë£Œ")
                time.sleep(2)

    # ë©”íƒ€ì •ë³´ ë³´ì •
    try:
        maintenance_fix_meta.fix_all_meta_json()
        print(f"âœ… meta ë³´ì • ì™„ë£Œ: {symbol_list}")
    except Exception as e:
        print(f"[âš ï¸ meta ë³´ì • ì‹¤íŒ¨] {e}")

    # ì‹¤íŒ¨í•™ìŠµ ë£¨í”„ (ìˆìœ¼ë©´)
    try:
        import failure_trainer
        failure_trainer.run_failure_training()
        print(f"âœ… ì‹¤íŒ¨í•™ìŠµ ë£¨í”„ ì™„ë£Œ")
    except Exception as e:
        print(f"[âŒ ì‹¤íŒ¨í•™ìŠµ ë£¨í”„ ì˜ˆì™¸] {e}")

    # ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ ì£¼ê¸° í•™ìŠµ (í•œ ë²ˆ ì‹¤í–‰)
    try:
        train_evo_meta_loop()
        print(f"âœ… ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ë£¨í”„ 1íšŒ ì‹¤í–‰")
    except Exception as e:
        print(f"[âŒ ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ì‹¤íŒ¨] {e}")

    # ì •ë¦¬
    try:
        safe_cleanup.auto_delete_old_logs()
    except Exception as e:
        print(f"[âš ï¸ ì •ë¦¬ ì‘ì—… ì‹¤íŒ¨] {e}")


def train_model_loop(strategy):
    """
    íŠ¹ì • strategy í•™ìŠµì„ 1íšŒ ìˆœíšŒ ì‹¤í–‰
    """
    if training_in_progress.get(strategy, False):
        print(f"âš ï¸ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: {strategy}")
        return

    training_in_progress[strategy] = True
    print(f"ğŸš€ {strategy} í•™ìŠµ ë£¨í”„ ì‹œì‘")

    try:
        for symbol in SYMBOLS:
            try:
                train_one_model(symbol, strategy)
            except Exception as e:
                print(f"[ì˜¤ë¥˜] {symbol}-{strategy} í•™ìŠµ ì‹¤íŒ¨: {e}")
    finally:
        training_in_progress[strategy] = False
        print(f"âœ… {strategy} ë£¨í”„ ì¢…ë£Œ")


def train_symbol_group_loop(delay_minutes=5):
    """
    SYMBOL_GROUPS ê¸°ì¤€ ê·¸ë£¹ ìˆœíšŒ í•™ìŠµ + ì˜ˆì¸¡ê¹Œì§€ í¬í•¨í•œ ì¥ê¸° ë£¨í”„
    """
    import time as _time
    import maintenance_fix_meta
    from data.utils import SYMBOL_GROUPS, _kline_cache, _feature_cache
    from predict import predict
    import safe_cleanup
    from evo_meta_learner import train_evo_meta_loop

    def now_kst_local():
        return datetime.datetime.now(pytz.timezone("Asia/Seoul"))

    ensure_failure_db()
    done_path = "/persistent/train_done.json"

    FORCE_TRAINING = True
    loop_count = 0
    group_count = len(SYMBOL_GROUPS)
    print(f"ğŸš€ ì „ì²´ {group_count}ê°œ ê·¸ë£¹ í•™ìŠµ ë£¨í”„ ì‹œì‘ ({now_kst_local().isoformat()})")

    while True:
        loop_count += 1
        print(f"\nğŸ”„ ê·¸ë£¹ ìˆœíšŒ ë£¨í”„ #{loop_count} ì‹œì‘ ({now_kst_local().isoformat()})")
        train_done = {}

        for group_id, group in enumerate(SYMBOL_GROUPS):
            print(f"\nğŸ“‚ [ê·¸ë£¹ {group_id+1}/{group_count}] ì§„ì…")
            if not group:
                print(f"[âš ï¸ ê·¸ë£¹ {group_id+1}] ì‹¬ë³¼ ì—†ìŒ â†’ ê±´ë„ˆëœ€")
                continue

            group_sorted = sorted(group)
            print(f"ğŸ“Š [ê·¸ë£¹ {group_id+1}] í•™ìŠµ ì‹œì‘ | ì‹¬ë³¼ ìˆ˜: {len(group_sorted)}")
            _kline_cache.clear(); _feature_cache.clear()

            for symbol in group_sorted:
                for strategy in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
                    train_done.setdefault(symbol, {}).setdefault(strategy, {})

                    try:
                        class_ranges = get_class_ranges(symbol=symbol, strategy=strategy)
                        if not class_ranges:
                            raise ValueError("ë¹ˆ í´ë˜ìŠ¤ ê²½ê³„ ë°˜í™˜ë¨")
                        num_classes = len(class_ranges)
                        class_groups = get_class_groups(num_classes=num_classes)
                        MAX_GROUP_ID = len(class_groups) - 1
                    except Exception as e:
                        print(f"[âŒ í´ë˜ìŠ¤ ê²½ê³„ ê³„ì‚° ì‹¤íŒ¨] {symbol}-{strategy} â†’ {e}")
                        log_training_result(symbol, strategy, model="range", accuracy=0.0, f1=0.0, loss=0.0, note=f"í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}", status="failed")
                        continue

                    for gid in range(MAX_GROUP_ID + 1):
                        if not FORCE_TRAINING and train_done[symbol][strategy].get(str(gid), False):
                            print(f"[â„¹ï¸ ì¬í•™ìŠµ ìƒëµ] {symbol}-{strategy}-group{gid}")
                            continue

                        try:
                            print(f"[â–¶ í•™ìŠµ ì‹œì‘] {symbol}-{strategy}-group{gid}")
                            train_one_model(symbol, strategy, group_id=gid)
                            train_done[symbol][strategy][str(gid)] = True
                            with open(done_path, "w", encoding="utf-8") as f:
                                json.dump(train_done, f, ensure_ascii=False, indent=2)
                            print(f"[âœ… í•™ìŠµ ì™„ë£Œ] {symbol}-{strategy}-group{gid}")
                            log_training_result(symbol, strategy, model=f"group{gid}", accuracy=0.0, f1=0.0, loss=0.0, note="í•™ìŠµ ì™„ë£Œ", status="success")
                        except Exception as e:
                            print(f"[âŒ í•™ìŠµ ì‹¤íŒ¨] {symbol}-{strategy}-group{gid} â†’ {e}")
                            traceback.print_exc()
                            log_training_result(symbol, strategy, model=f"group{gid}", accuracy=0.0, f1=0.0, loss=0.0, note=str(e), status="failed")

            # ê·¸ë£¹ í•™ìŠµ í›„ ê·¸ë£¹ ì˜ˆì¸¡
            try:
                print(f"ğŸ”® [ê·¸ë£¹ {group_id+1}] ì˜ˆì¸¡ ì‹œì‘")
                for symbol in group_sorted:
                    for strategy in ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]:
                        try:
                            print(f"[ğŸ”® ì˜ˆì¸¡] {symbol}-{strategy}")
                            predict(symbol=symbol, strategy=strategy, source="train_loop")
                        except Exception as e:
                            print(f"[âŒ ì˜ˆì¸¡ ì‹¤íŒ¨] {symbol}-{strategy} â†’ {e}")
                            traceback.print_exc()
            except Exception as e:
                print(f"[âš ï¸ ì˜ˆì¸¡ ìˆ˜í–‰ ì˜¤ë¥˜] ê·¸ë£¹ {group_id+1} â†’ {e}")

        # í›„ì²˜ë¦¬
        try:
            maintenance_fix_meta.fix_all_meta_json()
            safe_cleanup.auto_delete_old_logs()
        except Exception as e:
            print(f"[âš ï¸ í›„ì²˜ë¦¬ ì‹¤íŒ¨] â†’ {e}")

        FORCE_TRAINING = False
        _time.sleep(delay_minutes * 60)

        # ì§„í™”í˜• ë©”íƒ€ ì£¼ê¸° í•™ìŠµ(1íšŒ)
        try:
            train_evo_meta_loop()
        except Exception as e:
            print(f"[âš ï¸ ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ì‹¤íŒ¨] â†’ {e}")


def pretrain_ssl_features(symbol, strategy, pretrain_epochs=5):
    """
    Self-Supervised Learning pretraining (ê°„ë‹¨ ì˜¤í† ì¸ì½”ë”)
    """
    print(f"â–¶ SSL Pretraining ì‹œì‘: {symbol}-{strategy}")

    df = get_kline_by_strategy(symbol, strategy)
    if df is None or df.empty:
        print("â›” ì¤‘ë‹¨: ì‹œì„¸ ë°ì´í„° ì—†ìŒ")
        return

    df_feat = compute_features(symbol, df, strategy)
    if df_feat is None or df_feat.empty or df_feat.isnull().any().any():
        print("â›” ì¤‘ë‹¨: í”¼ì²˜ ìƒì„± ì‹¤íŒ¨ ë˜ëŠ” NaN")
        return

    features_only = df_feat.drop(columns=["timestamp"], errors="ignore")
    feat_scaled = MinMaxScaler().fit_transform(features_only)
    X = np.expand_dims(feat_scaled, axis=1)  # (samples, 1, features)

    input_size = X.shape[2]
    model = get_model("autoencoder", input_size=input_size, output_size=input_size).to(DEVICE).train()

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
    lossfn = nn.MSELoss()

    dataset = TensorDataset(torch.tensor(X, dtype=torch.float32), torch.tensor(X, dtype=torch.float32))
    loader = DataLoader(dataset, batch_size=32, shuffle=True)

    for epoch in range(pretrain_epochs):
        total_loss = 0.0
        for xb, yb in loader:
            xb, yb = xb.to(DEVICE), yb.to(DEVICE)
            out = model(xb)
            loss = lossfn(out, yb)
            optimizer.zero_grad(); loss.backward(); optimizer.step()
            total_loss += loss.item()
        avg_loss = total_loss / max(1, len(loader))
        print(f"[SSL Pretrain {epoch+1}/{pretrain_epochs}] loss={avg_loss:.6f}")

    torch.save(model.state_dict(), f"{MODEL_DIR}/{symbol}_{strategy}_ssl_pretrain.pt")
    print(f"âœ… SSL Pretraining ì™„ë£Œ: {symbol}-{strategy}")
