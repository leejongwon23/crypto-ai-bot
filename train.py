import os, json, time, traceback
from datetime import datetime
import pytz
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import TensorDataset, DataLoader
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import MinMaxScaler

from data.utils import SYMBOLS, get_kline_by_strategy, compute_features
from model.base_model import get_model
from model_weight_loader import get_model_weight
from feature_importance import compute_feature_importance, save_feature_importance
from failure_db import load_existing_failure_hashes, insert_failure_record, ensure_failure_db
from logger import log_training_result
from window_optimizer import find_best_window
from config import get_NUM_CLASSES, get_FEATURE_INPUT_SIZE, get_class_groups, get_class_ranges, set_NUM_CLASSES
from data_augmentation import balance_classes

# âœ… SSL í”„ë¦¬íŠ¸ë ˆì¸ (íŒŒì¼ëª…: ssl_pretrain.py)
from ssl_pretrain import masked_reconstruction

# âœ… ì§„í™”í˜• ë©”íƒ€ ëŸ¬ë„ˆ: ë£¨í”„ í˜¸ì¶œë¡œ í†µì¼
from evo_meta_learner import train_evo_meta_loop

NUM_CLASSES = get_NUM_CLASSES()
FEATURE_INPUT_SIZE = get_FEATURE_INPUT_SIZE()

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
MODEL_DIR = "/persistent/models"
os.makedirs(MODEL_DIR, exist_ok=True)

now_kst = lambda: datetime.now(pytz.timezone("Asia/Seoul"))
training_in_progress = {"ë‹¨ê¸°": False, "ì¤‘ê¸°": False, "ì¥ê¸°": False}

# --------------------------------------------------
# ìœ í‹¸
# --------------------------------------------------
def get_feature_hash_from_tensor(x, use_full=False, precision=3):
    import hashlib
    if x.ndim != 2 or x.shape[0] == 0:
        return "invalid"
    try:
        flat = x.flatten() if use_full else x[-1]
        rounded = [round(float(val), precision) for val in flat]
        return hashlib.sha1(",".join(map(str, rounded)).encode()).hexdigest()
    except Exception:
        return "invalid"

# --------------------------------------------------
# ë‹¨ì¼ (symbol, strategy, group_id) ëª¨ë¸ í•™ìŠµ
# --------------------------------------------------
def train_one_model(symbol, strategy, group_id=None, max_epochs=20):
    """
    - SSL ì‚¬ì „í•™ìŠµ ì‹¤í–‰ (ì‹¤íŒ¨í•´ë„ ê³„ì†)
    - ê°€ê²©/í”¼ì²˜ ë¡œë“œ â†’ ë¼ë²¨ë§ â†’ ìœˆë„ìš° ì‹œí€€ìŠ¤ êµ¬ì„±
    - í•„ìš” ì‹œ í´ë˜ìŠ¤ ë°¸ëŸ°ì‹±
    - [lstm, cnn_lstm, transformer] ê°ê° í•™ìŠµ/í‰ê°€/ì €ì¥
    - ë©”íƒ€íŒŒì¼(.meta.json) ë™ì‹œ ì €ì¥
    """
    try:
        print(f"âœ… [train_one_model ì‹œì‘] {symbol}-{strategy}-group{group_id}")
        ensure_failure_db()

        # 0) SSL í”„ë¦¬íŠ¸ë ˆì¸ (ì‹¤íŒ¨í•´ë„ í†µê³¼)
        try:
            masked_reconstruction(symbol, strategy, FEATURE_INPUT_SIZE)
        except Exception as e:
            print(f"[âš ï¸ SSL ì‚¬ì „í•™ìŠµ ì‹¤íŒ¨] {e}")

        # 1) ë°ì´í„° ë¡œë“œ
        df = get_kline_by_strategy(symbol, strategy)
        if df is None or df.empty:
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ ë°ì´í„° ì—†ìŒ")
            log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                                loss=0.0, note="ë°ì´í„° ì—†ìŒ", status="skipped")
            insert_failure_record({
                "symbol": symbol, "strategy": strategy, "model": "all",
                "predicted_class": -1, "success": False, "rate": "", "reason": "ë°ì´í„° ì—†ìŒ"
            }, feature_vector=[])
            return

        feat = compute_features(symbol, df, strategy)
        if feat is None or feat.empty or feat.isnull().any().any():
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ í”¼ì²˜ ì—†ìŒ/NaN")
            log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                                loss=0.0, note="í”¼ì²˜ ì—†ìŒ", status="skipped")
            insert_failure_record({
                "symbol": symbol, "strategy": strategy, "model": "all",
                "predicted_class": -1, "success": False, "rate": "", "reason": "í”¼ì²˜ ì—†ìŒ"
            }, feature_vector=[])
            return

        features_only = feat.drop(columns=["timestamp", "strategy"], errors="ignore")
        feat_scaled = MinMaxScaler().fit_transform(features_only)

        # 2) í´ë˜ìŠ¤ ê²½ê³„/ë¼ë²¨ë§
        try:
            class_ranges = get_class_ranges(symbol=symbol, strategy=strategy, group_id=group_id)
        except Exception as e:
            print(f"[âŒ í´ë˜ìŠ¤ ë²”ìœ„ ê³„ì‚° ì‹¤íŒ¨] {e}")
            log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                                loss=0.0, note="í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨", status="failed")
            insert_failure_record({
                "symbol": symbol, "strategy": strategy, "model": "all",
                "predicted_class": -1, "success": False, "rate": "", "reason": "í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨"
            }, feature_vector=[])
            return

        num_classes = len(class_ranges)
        set_NUM_CLASSES(num_classes)

        returns = df["close"].pct_change().fillna(0).values
        labels = []
        for r in returns:
            idx = 0
            for i, (lo, hi) in enumerate(class_ranges):
                if lo <= r <= hi:
                    idx = i
                    break
            labels.append(idx)

        # 3) ì‹œí€€ìŠ¤ ìƒì„±
        window = 60
        X, y = [], []
        for i in range(len(feat_scaled) - window):
            X.append(feat_scaled[i:i+window])
            y.append(labels[i + window] if i + window < len(labels) else 0)
        X, y = np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)

        if len(X) < 10:
            print(f"[â© ìŠ¤í‚µ] {symbol}-{strategy}-group{group_id} â†’ ìƒ˜í”Œ ë¶€ì¡±({len(X)})")
            log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                                loss=0.0, note="ìµœì¢… ìƒ˜í”Œ ë¶€ì¡±", status="skipped")
            insert_failure_record({
                "symbol": symbol, "strategy": strategy, "model": "all",
                "predicted_class": -1, "success": False, "rate": "", "reason": "ìµœì¢… ìƒ˜í”Œ ë¶€ì¡±"
            }, feature_vector=[])
            return

        # 4) ë°¸ëŸ°ì‹±(í•„ìš” ì‹œ)
        try:
            if len(X) < 50:
                X, y = balance_classes(X, y, num_classes=num_classes)
                print(f"[âœ… ì¦ê°•/ë°¸ëŸ°ì‹± ì™„ë£Œ] ì´ ìƒ˜í”Œ: {len(X)}")
        except Exception as e:
            print(f"[âš ï¸ ë°¸ëŸ°ì‹± ì‹¤íŒ¨] {e}")

        # 5) í•™ìŠµ/í‰ê°€/ì €ì¥ (ëª¨ë¸ 3ì¢…)
        for model_type in ["lstm", "cnn_lstm", "transformer"]:
            print(f"[ğŸ§  í•™ìŠµ ì‹œì‘] {model_type} | {symbol}-{strategy}-group{group_id}")
            model = get_model(model_type, input_size=FEATURE_INPUT_SIZE, output_size=num_classes).to(DEVICE)
            optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
            criterion = nn.CrossEntropyLoss()

            # train/val split
            val_len = max(1, int(len(X) * 0.2))
            if len(X) - val_len < 1:
                val_len = len(X) - 1
            train_X, val_X = X[:-val_len], X[-val_len:]
            train_y, val_y = y[:-val_len], y[-val_len:]

            train_loader = DataLoader(TensorDataset(
                torch.tensor(train_X), torch.tensor(train_y)), batch_size=64, shuffle=True)
            val_loader = DataLoader(TensorDataset(
                torch.tensor(val_X), torch.tensor(val_y)), batch_size=64)

            total_loss = 0.0
            for epoch in range(max_epochs):
                model.train()
                for xb, yb in train_loader:
                    xb, yb = xb.to(DEVICE), yb.to(DEVICE)
                    logits = model(xb)
                    loss = criterion(logits, yb)
                    if not torch.isfinite(loss):
                        continue
                    optimizer.zero_grad(); loss.backward(); optimizer.step()
                    total_loss += loss.item()
                if (epoch + 1) % 5 == 0 or epoch == max_epochs - 1:
                    print(f"[ğŸ“ˆ {model_type}] Epoch {epoch+1}/{max_epochs} | loss={loss.item():.4f}")

            # í‰ê°€
            model.eval()
            all_preds, all_labels = [], []
            with torch.no_grad():
                for xb, yb in val_loader:
                    preds = torch.argmax(model(xb.to(DEVICE)), dim=1).cpu().numpy()
                    all_preds.extend(preds); all_labels.extend(yb.numpy())
            acc = accuracy_score(all_labels, all_preds)
            f1 = f1_score(all_labels, all_preds, average="macro")
            print(f"[ğŸ¯ {model_type}] acc={acc:.4f}, f1={f1:.4f}")

            # ì €ì¥
            os.makedirs(MODEL_DIR, exist_ok=True)
            model_name = f"{symbol}_{strategy}_{model_type}_group{group_id}_cls{num_classes}.pt"
            model_path = os.path.join(MODEL_DIR, model_name)
            torch.save(model.state_dict(), model_path)

            meta = {
                "symbol": symbol, "strategy": strategy, "model": model_type,
                "group_id": int(group_id) if group_id is not None else 0,
                "num_classes": int(num_classes),
                "input_size": int(FEATURE_INPUT_SIZE),
                "timestamp": now_kst().isoformat(),
                "model_name": model_name
            }
            with open(model_path.replace(".pt", ".meta.json"), "w", encoding="utf-8") as f:
                json.dump(meta, f, ensure_ascii=False, indent=2)

            # âœ… log_training_result í˜¸ì¶œ í˜•ì‹ í†µì¼
            log_training_result(
                symbol=symbol,
                strategy=strategy,
                model=model_name,
                accuracy=float(acc),
                f1=float(f1),
                loss=float(total_loss),
                note="train_one_model",
                source_exchange="BYBIT",
                status="success",
            )

        print(f"[âœ… train_one_model ì™„ë£Œ] {symbol}-{strategy}-group{group_id}")

    except Exception as e:
        print(f"[âŒ train_one_model ì‹¤íŒ¨] {symbol}-{strategy}-group{group_id} â†’ {e}")
        traceback.print_exc()
        log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                            loss=0.0, note=str(e), status="failed")
        insert_failure_record({
            "symbol": symbol, "strategy": strategy, "model": "all",
            "predicted_class": -1, "success": False, "rate": "", "reason": str(e)
        }, feature_vector=[])

# --------------------------------------------------
# ì „ì²´ í•™ìŠµ ë£¨í‹´
# --------------------------------------------------
def train_models(symbol_list):
    """
    - ì‹¬ë³¼ Ã— (ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸°) Ã— ì „ ê·¸ë£¹ í•™ìŠµ
    - ë©”íƒ€ ë³´ì •/ì‹¤íŒ¨í•™ìŠµ/ì§„í™”í˜• ë©”íƒ€ ë£¨í”„ í˜¸ì¶œ
    """
    strategies = ["ë‹¨ê¸°", "ì¤‘ê¸°", "ì¥ê¸°"]
    print(f"ğŸš€ [train_models] ì‹¬ë³¼ í•™ìŠµ ì‹œì‘: {symbol_list}")

    for symbol in symbol_list:
        print(f"\nğŸ” [ì‹¬ë³¼] {symbol}")
        for strategy in strategies:
            print(f"â–¶ {symbol}-{strategy} ì „ì²´ ê·¸ë£¹ í•™ìŠµ")
            # group_id ëª©ë¡ ê³„ì‚°
            try:
                class_ranges = get_class_ranges(symbol=symbol, strategy=strategy)
                if not class_ranges:
                    raise ValueError("ë¹ˆ í´ë˜ìŠ¤ ê²½ê³„")
                num_classes = len(class_ranges)
                groups = get_class_groups(num_classes=num_classes)  # ë¦¬ìŠ¤íŠ¸ë“¤ì˜ ë¦¬ìŠ¤íŠ¸
                max_gid = len(groups) - 1
            except Exception as e:
                print(f"[âŒ í´ë˜ìŠ¤ ê²½ê³„ ê³„ì‚° ì‹¤íŒ¨] {symbol}-{strategy}: {e}")
                log_training_result(symbol, strategy, model="all", accuracy=0.0, f1=0.0,
                                    loss=0.0, note=f"í´ë˜ìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}", status="failed")
                continue

            for gid in range(max_gid + 1):
                train_one_model(symbol, strategy, group_id=gid)
                time.sleep(0.5)

    # ë©”íƒ€ ë³´ì •(ìˆë‹¤ë©´)
    try:
        import maintenance_fix_meta
        maintenance_fix_meta.fix_all_meta_json()
    except Exception as e:
        print(f"[âš ï¸ meta ë³´ì • ì‹¤íŒ¨] {e}")

    # ì‹¤íŒ¨í•™ìŠµ ë£¨í”„
    try:
        import failure_trainer
        failure_trainer.run_failure_training()
    except Exception as e:
        print(f"[âš ï¸ ì‹¤íŒ¨í•™ìŠµ ë£¨í”„ ì˜ˆì™¸] {e}")

    # âœ… ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ë£¨í”„ í˜¸ì¶œ(ë‹¨ë°œ)
    try:
        train_evo_meta_loop()
    except Exception as e:
        print(f"[âš ï¸ ì§„í™”í˜• ë©”íƒ€ëŸ¬ë„ˆ í•™ìŠµ ì‹¤íŒ¨] {e}")

    print("âœ… train_models ì™„ë£Œ")

def train_all_models():
    """SYMBOLS ì „ì²´ ë°˜ë³µ í•™ìŠµ (ê°„ë‹¨ ë²„ì „)"""
    train_models(SYMBOLS)

# --------------------------------------------------
# ê°œë³„ ì „ëµ ë¬´í•œ ë£¨í”„ (ì˜µì…˜)
# --------------------------------------------------
def train_model_loop(strategy):
    global training_in_progress
    if training_in_progress.get(strategy, False):
        print(f"âš ï¸ ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€: {strategy}")
        return
    training_in_progress[strategy] = True
    print(f"ğŸš€ {strategy} ë¬´í•œ í•™ìŠµ ë£¨í”„ ì‹œì‘")

    try:
        for symbol in SYMBOLS:
            train_one_model(symbol, strategy, group_id=0)
    finally:
        training_in_progress[strategy] = False
        print(f"âœ… {strategy} ë£¨í”„ ì¢…ë£Œ")

if __name__ == "__main__":
    # ì˜ˆì‹œ: ì „ ì‹¬ë³¼ í•™ìŠµ
    train_all_models()
