import os
import time
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset, random_split
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from data.utils import SYMBOLS, STRATEGY_CONFIG, get_kline_by_strategy, compute_features
from model.base_model import LSTMPricePredictor
from wrong_data_loader import load_wrong_prediction_data  # âœ… ì¶”ê°€ ëª¨ë“ˆ (ê¸°ëŠ¥ë§Œ ì¶”ê°€)

WINDOW = 30

def create_dataset(features, window=30):
    X, y = [], []
    for i in range(len(features) - window - 1):
        x_seq = features[i:i+window]
        current_close = features[i+window-1]['close']
        future_close = features[i+window]['close']
        label = 1 if future_close > current_close * 1.01 else 0  # âœ… ê¸°ì¡´ êµ¬ì¡° ê·¸ëŒ€ë¡œ
        X.append([list(row.values()) for row in x_seq])
        y.append(label)
    return np.array(X), np.array(y)

def train_model(symbol, strategy, input_size=11, batch_size=32, epochs=10, lr=1e-3):
    print(f"ðŸ“š í•™ìŠµ ì‹œìž‘: {symbol} / {strategy}")

    df = get_kline_by_strategy(symbol, strategy)
    if df is None or len(df) < WINDOW + 20:
        print(f"âŒ {symbol} / {strategy} ë°ì´í„° ë¶€ì¡±")
        return

    df_feat = compute_features(df)
    if len(df_feat) < WINDOW + 1:
        print(f"âŒ {symbol} / {strategy} í”¼ì²˜ ë¶€ì¡±")
        return

    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df_feat.values)
    feature_dicts = [dict(zip(df_feat.columns, row)) for row in scaled]

    X, y = create_dataset(feature_dicts, window=WINDOW)
    if len(X) == 0:
        print(f"âš ï¸ ë¼ë²¨ ë¶€ì¡±: {symbol} / {strategy}")
        return

    X_tensor = torch.tensor(X, dtype=torch.float32)
    y_tensor = torch.tensor(y, dtype=torch.float32)
    dataset = TensorDataset(X_tensor, y_tensor)
    val_len = int(len(dataset) * 0.2)
    train_len = len(dataset) - val_len
    train_set, val_set = random_split(dataset, [train_len, val_len])

    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=batch_size)

    model = LSTMPricePredictor(input_size=input_size)
    model_path = f"models/{symbol}_{strategy}_lstm.pt"
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
        print(f"ðŸ“¦ ì´ì „ ëª¨ë¸ ë¡œë“œ: {model_path}")

    criterion = nn.BCELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    model.train()

    # âœ… ì˜¤ë‹µ ë°ì´í„° ìš°ì„  í•™ìŠµ (ìƒˆ ê¸°ëŠ¥ ì¶”ê°€, ê¸°ì¡´ í•™ìŠµ êµ¬ì¡° ê·¸ëŒ€ë¡œ ìœ ì§€)
    wrong_data = load_wrong_prediction_data(symbol, strategy, input_size, window=WINDOW)
    if wrong_data:
        print(f"âš ï¸ ì˜¤ë‹µ ë°ì´í„° ìš°ì„  í•™ìŠµ ì¤‘: {symbol} / {strategy}")
        wrong_loader = DataLoader(wrong_data, batch_size=batch_size, shuffle=True)
        for xb, yb in wrong_loader:
            signal_pred, _ = model(xb)
            loss = criterion(signal_pred, yb)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

    # âœ… ê¸°ì¡´ ì¼ë°˜ í•™ìŠµ (ìˆ˜ì • ì—†ì´ ê·¸ëŒ€ë¡œ ìœ ì§€)
    for epoch in range(epochs):
        total_loss = 0
        for xb, yb in train_loader:
            signal_pred, _ = model(xb)
            loss = criterion(signal_pred, yb)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"[{symbol}-{strategy}] Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f}")

    os.makedirs("models", exist_ok=True)
    torch.save(model.state_dict(), model_path)
    print(f"âœ… ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: {model_path}")

def main():
    while True:
        for strategy in STRATEGY_CONFIG:
            for symbol in SYMBOLS:
                try:
                    train_model(symbol, strategy)
                except Exception as e:
                    print(f"[ERROR] {symbol}-{strategy} í•™ìŠµ ì˜¤ë¥˜: {e}")
        print("â³ 1ì‹œê°„ ëŒ€ê¸° í›„ ìž¬í•™ìŠµ ë°˜ë³µ...")
        time.sleep(3600)

if __name__ == "__main__":
    main()
