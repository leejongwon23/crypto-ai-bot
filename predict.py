# predict.py (FINAL)

import os, sys, json, datetime, pytz
import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from sklearn.preprocessing import MinMaxScaler

from data.utils import get_kline_by_strategy, compute_features

# --- window_optimizer Ìò∏Ìôò ÏûÑÌè¨Ìä∏ ---
try:
    from window_optimizer import find_best_windows  # ÏÑ†Ìò∏
except Exception:
    try:
        from window_optimizer import find_best_window
    except Exception:
        find_best_window = None

    def find_best_windows(symbol, strategy):
        try:
            if callable(find_best_window):
                best = int(find_best_window(symbol, strategy, window_list=[10, 20, 30, 40, 60], group_id=None))
            else:
                best = 60
        except Exception:
            best = 60
        return [best, best, best]

# logger ÏùòÏ°¥ ÏµúÏÜåÌôî: get_available_models Ï†úÍ±∞(Î°úÏª¨Íµ¨ÌòÑ), ÎÇòÎ®∏ÏßÄÎäî Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
from logger import log_prediction, update_model_success
from failure_db import insert_failure_record, load_existing_failure_hashes, ensure_failure_db
from predict_trigger import get_recent_class_frequencies, adjust_probs_with_diversity
from model.base_model import get_model
from model_weight_loader import load_model_cached
from config import (
    get_NUM_CLASSES, get_FEATURE_INPUT_SIZE, get_class_groups,
    get_class_return_range, class_to_expected_return
)

DEVICE = torch.device("cpu")
MODEL_DIR = "/persistent/models"
PREDICTION_LOG_PATH = "/persistent/prediction_log.csv"

NUM_CLASSES = get_NUM_CLASSES()
FEATURE_INPUT_SIZE = get_FEATURE_INPUT_SIZE()
now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

# -----------------------------
# Î°úÏª¨ Ìó¨Ìçº: get_feature_hash
# -----------------------------
def _get_feature_hash(feature_row) -> str:
    try:
        import hashlib
        if feature_row is None:
            return "none"
        if isinstance(feature_row, torch.Tensor):
            arr = feature_row.detach().cpu().flatten().numpy().astype(float)
        elif isinstance(feature_row, np.ndarray):
            arr = feature_row.flatten().astype(float)
        elif isinstance(feature_row, (list, tuple)):
            arr = np.array(feature_row, dtype=float).flatten()
        else:
            arr = np.array([float(feature_row)], dtype=float)
        rounded = [round(float(x), 2) for x in arr]
        joined = ",".join(map(str, rounded))
        return hashlib.sha1(joined.encode()).hexdigest()
    except Exception:
        return "hash_error"

# -----------------------------
# Î°úÏª¨ Ìó¨Ìçº: Î™®Îç∏ ÌÉêÏÉâ (logger.get_available_models ÎåÄÏ≤¥)
# -----------------------------
def get_available_models(symbol: str, strategy: str):
    """
    /persistent/modelsÏóêÏÑú Îã§Ïùå Í∑úÏπôÏùÑ ÎßåÏ°±ÌïòÎäî ptÎßå Î∞òÌôò:
      - ÌååÏùºÎ™Ö ÏãúÏûëÏù¥ '{symbol}_'
      - ÌååÏùºÎ™ÖÏóê '_{strategy}_' Ìè¨Ìï®
      - ÎèôÏùº Í≤ΩÎ°úÏóê .meta.json Ï°¥Ïû¨
    Î∞òÌôò Ìè¨Îß∑: [{"pt_file": "AAVEUSDT_Ïû•Í∏∞_lstm_group1_cls3.pt"}, ...]
    """
    try:
        if not os.path.isdir(MODEL_DIR):
            return []
        items = []
        prefix = f"{symbol}_"
        needle = f"_{strategy}_"
        for fn in os.listdir(MODEL_DIR):
            if not fn.endswith(".pt"):
                continue
            if not fn.startswith(prefix):
                continue
            if needle not in fn:
                continue
            meta = os.path.join(MODEL_DIR, fn.replace(".pt", ".meta.json"))
            if not os.path.exists(meta):
                continue
            items.append({"pt_file": fn})
        # Ï†ïÎ†¨(ÏïàÏ†ïÏÑ±)
        items.sort(key=lambda x: x["pt_file"])
        return items
    except Exception as e:
        print(f"[get_available_models Ïò§Î•ò] {e}")
        return []

# -----------------------------
# ÏïôÏÉÅÎ∏î Ïä§ÌÉúÌÇπ (ÏòµÏÖò)
# -----------------------------
def ensemble_stacking(model_outputs, meta_model=None):
    X_stack = np.array(model_outputs).reshape(1, -1)
    if meta_model is not None:
        pred = meta_model.predict(X_stack)
        return int(pred[0])
    else:
        avg_probs = np.mean(model_outputs, axis=0)
        return int(np.argmax(avg_probs))

def failed_result(symbol, strategy, model_type="unknown", reason="", source="ÏùºÎ∞ò", X_input=None):
    from datetime import datetime as _dt
    t = _dt.now(pytz.timezone("Asia/Seoul")).strftime("%Y-%m-%d %H:%M:%S")
    result = {
        "symbol": symbol, "strategy": strategy, "success": False, "reason": reason,
        "model": str(model_type or "unknown"), "rate": 0.0, "class": -1,
        "timestamp": t, "source": source, "predicted_class": -1, "label": -1
    }
    try:
        log_prediction(
            symbol=symbol, strategy=strategy, direction="ÏòàÏ∏°Ïã§Ìå®",
            entry_price=0, target_price=0, model=str(model_type or "unknown"),
            success=False, reason=reason, rate=0.0, timestamp=t,
            return_value=0.0, volatility=True, source=source,
            predicted_class=-1, label=-1
        )
    except Exception as e:
        print(f"[failed_result log_prediction Ïò§Î•ò] {e}")
    try:
        if X_input is not None:
            feature_hash = _get_feature_hash(X_input)
            insert_failure_record(result, feature_hash, feature_vector=np.array(X_input).flatten().tolist(), label=-1)
    except Exception as e:
        print(f"[failed_result insert_failure_record Ïò§Î•ò] {e}")
    return result

# -----------------------------
# Î©îÏù∏ ÏòàÏ∏°
# -----------------------------
def predict(symbol, strategy, source="ÏùºÎ∞ò", model_type=None):
    """
    - Ï†ÄÏû•Îêú Î™®Îç∏ ÏòàÏ∏° Ï∑®Ìï© ‚Üí (Î©îÌÉÄ ÎòêÎäî ÏßÑÌôîÌòï Î©îÌÉÄ) ÏµúÏ¢Ö ÌÅ¥ÎûòÏä§ ÏÑ†ÌÉù
    - ÏÑ±Í≥µ ÌåêÏ†ïÏùÄ get_class_return_range Í∏∞Ï§Ä
    - Î°úÍ∑∏ Í∞ïÌôî: ÏúàÎèÑÏö∞/ÌôïÎ•†/ÏÑ†ÌÉù ÏÇ¨Ïú†/ÌÅ¥ÎûòÏä§ Í≤ΩÍ≥Ñ Í∏∞Î°ù
    """
    try:
        from evo_meta_learner import predict_evo_meta
    except Exception:
        predict_evo_meta = None
    try:
        from meta_learning import get_meta_prediction
    except Exception:
        def get_meta_prediction(probs_list, feature_tensor, meta_info=None):
            avg = np.mean(np.array(probs_list), axis=0)
            return int(np.argmax(avg))

    ensure_failure_db()
    os.makedirs("/persistent/logs", exist_ok=True)

    if not symbol or not strategy:
        insert_failure_record({"symbol": symbol or "None", "strategy": strategy or "None"},
                              "invalid_symbol_strategy", label=-1)
        return None

    log_strategy = strategy
    try:
        # ---------- Îç∞Ïù¥ÌÑ∞/ÏúàÎèÑÏö∞ ----------
        window_list = find_best_windows(symbol, strategy)
        print(f"[ü™ü ÏúàÎèÑÏö∞ ÏÑ†ÌÉù] {symbol}-{strategy} -> {window_list}")
        if not window_list:
            insert_failure_record({"symbol": symbol, "strategy": log_strategy}, "window_list_none", label=-1)
            return None

        df = get_kline_by_strategy(symbol, strategy)
        if df is None or len(df) < max(window_list) + 1:
            insert_failure_record({"symbol": symbol, "strategy": log_strategy}, "df_short", label=-1)
            return None

        feat = compute_features(symbol, df, strategy)
        if feat is None or feat.dropna().shape[0] < max(window_list) + 1:
            insert_failure_record({"symbol": symbol, "strategy": log_strategy}, "feature_short", label=-1)
            return None

        features_only = feat.drop(columns=["timestamp", "strategy"], errors="ignore")
        feat_scaled = MinMaxScaler().fit_transform(features_only)
        if feat_scaled.shape[1] < FEATURE_INPUT_SIZE:
            feat_scaled = np.pad(feat_scaled, ((0, 0), (0, FEATURE_INPUT_SIZE - feat_scaled.shape[1])), mode="constant")
        else:
            feat_scaled = feat_scaled[:, :FEATURE_INPUT_SIZE]

        # ---------- Î™®Îç∏ Ïä§Ï∫î ----------
        models = get_available_models(symbol, strategy)
        if not models:
            insert_failure_record({"symbol": symbol, "strategy": log_strategy}, "no_models", label=-1)
            return None
        print(f"[üß† Î™®Îç∏Í∞êÏßÄ] {symbol}-{strategy} -> {len(models)}Í∞ú")

        # ÏµúÍ∑º ÌÅ¥ÎûòÏä§ ÎπàÎèÑ(ÌôïÎ•† Ï°∞Ï†ïÏö©, ÏóÜÏúºÎ©¥ Î¨¥Ïãú)
        try:
            recent_freq = get_recent_class_frequencies(strategy)
        except Exception:
            recent_freq = None

        feature_tensor = torch.tensor(feat_scaled[-1], dtype=torch.float32)

        # ---------- Í∞úÎ≥Ñ Î™®Îç∏ ÏòàÏ∏° ----------
        model_outputs_list, all_model_predictions = get_model_predictions(
            symbol, strategy, models, df, feat_scaled, window_list, recent_freq
        )
        if not model_outputs_list:
            insert_failure_record({"symbol": symbol, "strategy": log_strategy}, "no_valid_model", label=-1)
            return None

        probs_stack = np.array([m["probs"] for m in model_outputs_list])
        avg_probs = probs_stack.mean(axis=0)

        # ÏµúÍ∑º ÎπàÎèÑ Í∏∞Î∞ò Ï°∞Ï†ï(ÏòµÏÖò)
        adj_probs = avg_probs.copy()
        try:
            if recent_freq is not None:
                cand = adjust_probs_with_diversity(avg_probs, recent_freq)
                if isinstance(cand, (list, np.ndarray)) and len(cand) == len(avg_probs):
                    adj_probs = np.array(cand, dtype=float)
        except Exception as e:
            print(f"[‚ö†Ô∏è ÌôïÎ•†Ï°∞Ï†ï Ïã§Ìå®] {e}")

        # ---------- ÌÅ¥ÎûòÏä§ Í≤ΩÍ≥Ñ Î°úÍ∑∏ ----------
        try:
            num_classes = len(avg_probs)
            class_ranges = [get_class_return_range(c, symbol, strategy) for c in range(num_classes)]
            # loggerÏóê ÏÉà Ìï®ÏàòÍ∞Ä ÏóÜÏùÑ ÏàòÎèÑ ÏûàÏñ¥ try/except
            import logger as _logger
            _logger.log_class_ranges(
                symbol=symbol, strategy=strategy, group_id=None,
                class_ranges=class_ranges, note="predict"
            )
            print(f"[üìè ÌÅ¥ÎûòÏä§Í≤ΩÍ≥Ñ Î°úÍ∑∏] {symbol}-{strategy} -> {class_ranges}")
        except Exception as e:
            print(f"[‚ö†Ô∏è log_class_ranges Ïã§Ìå®/ÎØ∏Íµ¨ÌòÑ] {e}")

        # ---------- Î©îÌÉÄ Í≤∞Ï†ï ----------
        try:
            from meta_learning import get_meta_prediction
        except Exception:
            def get_meta_prediction(probs_list, feature_tensor, meta_info=None):
                avg = np.mean(np.array(probs_list), axis=0)
                return int(np.argmax(avg))

        meta_success_rate = {c: 0.5 for c in range(len(avg_probs))}  # ÏûêÎ¶¨ÌëúÏãúÏûê
        final_pred_class = get_meta_prediction(
            [m["probs"] for m in model_outputs_list],
            feature_tensor,
            meta_info={"success_rate": meta_success_rate, "adjusted_probs": adj_probs.tolist()}
        )

        # ÏßÑÌôîÌòï Î©îÌÉÄ(ÏûàÏúºÎ©¥ Ïö∞ÏÑ†)
        use_evo = False
        evo_model_path = os.path.join(MODEL_DIR, "evo_meta_learner.pt")
        if os.path.exists(evo_model_path) and callable(predict_evo_meta):
            try:
                evo_pred = predict_evo_meta(feature_tensor.unsqueeze(0), input_size=FEATURE_INPUT_SIZE)
                if evo_pred is not None and int(evo_pred) != int(final_pred_class):
                    print(f"[üîÅ ÏßÑÌôîÌòï Î©îÌÉÄÎü¨ÎÑà Ï†ÑÌôò] {final_pred_class} ‚Üí {int(evo_pred)}")
                    final_pred_class = int(evo_pred)
                    use_evo = True
            except Exception as e:
                print(f"[‚ö†Ô∏è ÏßÑÌôîÌòï Î©îÌÉÄÎü¨ÎÑà ÏòàÏô∏] {e}")

        # ---------- Î°úÍπÖ(ÌôïÎ•† ÏöîÏïΩ) ----------
        def _topk_desc(probs, k=5):
            idx = np.argsort(probs)[::-1][:k]
            return [f"{int(i)}:{probs[i]:.3f}" for i in idx]

        print(f"[üî¢ ÌôïÎ•†(raw)] {symbol}-{strategy} -> {np.round(avg_probs, 3).tolist()}")
        if not np.allclose(adj_probs, avg_probs):
            print(f"[üéõÔ∏è ÌôïÎ•†(adj)] {symbol}-{strategy} -> {np.round(adj_probs, 3).tolist()}")
        print(f"[META] {'ÏßÑÌôîÌòï' if use_evo else 'Í∏∞Î≥∏'} Î©îÌÉÄ ÏÑ†ÌÉù: ÌÅ¥ÎûòÏä§ {final_pred_class} | TOP5={_topk_desc(adj_probs)}")

        # ---------- ÏÑ±Í≥µ ÌåêÏ†ï & Í∏∞Î°ù ----------
        cls_min, cls_max = get_class_return_range(final_pred_class, symbol, strategy)
        current_price = float(df.iloc[-1]["close"])
        expected_ret = class_to_expected_return(final_pred_class, symbol, strategy)
        entry_price = float(all_model_predictions[0]["entry_price"])  # ÎèôÏùº ÏãúÏ†ê Í∞ÄÍ≤© ÏÇ¨Ïö©
        actual_return_meta = (current_price / (entry_price + 1e-12)) - 1
        meta_success_flag = actual_return_meta >= cls_min

        if not meta_success_flag:
            insert_failure_record(
                {"symbol": symbol, "strategy": log_strategy},
                "meta_predicted_fail", label=final_pred_class, feature_vector=feature_tensor.numpy()
            )

        log_prediction(
            symbol=symbol,
            strategy=log_strategy,
            direction="ÏòàÏ∏°",
            entry_price=entry_price,
            target_price=entry_price * (1 + expected_ret),
            model="meta",
            model_name="evo_meta_learner",
            predicted_class=final_pred_class,
            label=final_pred_class,
            note=("ÏßÑÌôîÌòï Î©îÌÉÄ ÏÑ†ÌÉù" if use_evo else "Í∏∞Î≥∏ Î©îÌÉÄ ÏÑ†ÌÉù")
                 + f" | win={window_list} | top5={_topk_desc(adj_probs)}",
            top_k=_topk_desc(adj_probs),  # CSVÏóê ÌôïÎ•† ÏöîÏïΩ Ï†ÄÏû•
            success=meta_success_flag,
            reason=f"ÏàòÏùµÎ•†ÎèÑÎã¨:{meta_success_flag}; cls_min={cls_min:.4f}, now_ret={actual_return_meta:.4f}",
            rate=expected_ret,
            return_value=actual_return_meta,
            source="ÏßÑÌôîÌòï" if use_evo else "Í∏∞Î≥∏",
            group_id=all_model_predictions[0].get("group_id"),
            feature_vector=feature_tensor.numpy()
        )

        return {
            "symbol": symbol,
            "strategy": log_strategy,
            "model": "meta",
            "class": final_pred_class,
            "expected_return": expected_ret,
            "timestamp": now_kst().isoformat(),
            "reason": "ÏßÑÌôîÌòï Î©îÌÉÄ ÏµúÏ¢Ö ÏÑ†ÌÉù" if use_evo else "Í∏∞Î≥∏ Î©îÌÉÄ ÏµúÏ¢Ö ÏÑ†ÌÉù",
            "source": source
        }

    except Exception as e:
        print(f"[‚ùå predict ÏòàÏô∏] {e}")
        insert_failure_record({"symbol": symbol or "None", "strategy": strategy or "None"}, "exception", label=-1)
        return None

# -----------------------------
# ÌèâÍ∞Ä(Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ)
# -----------------------------
def evaluate_predictions(get_price_fn):
    import csv, os
    import pandas as pd
    from collections import defaultdict
    from failure_db import check_failure_exists

    ensure_failure_db()

    PREDICTION_LOG = PREDICTION_LOG_PATH
    now_local = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))
    date_str = now_local().strftime("%Y-%m-%d")
    LOG_DIR = "/persistent/logs"
    EVAL_RESULT = os.path.join(LOG_DIR, f"evaluation_{date_str}.csv")
    WRONG = os.path.join(LOG_DIR, f"wrong_{date_str}.csv")

    eval_horizon_map = {"Îã®Í∏∞": 4, "Ï§ëÍ∏∞": 24, "Ïû•Í∏∞": 168}
    updated, evaluated = [], []

    try:
        rows = list(csv.DictReader(open(PREDICTION_LOG, "r", encoding="utf-8-sig")))
        if not rows:
            return
    except Exception as e:
        print(f"[Ïò§Î•ò] prediction_log.csv ÏùΩÍ∏∞ Ïã§Ìå® ‚Üí {e}")
        return

    grouped_preds = defaultdict(list)
    for r in rows:
        key = (r.get("symbol"), r.get("strategy"), r.get("timestamp"))
        grouped_preds[key].append(r)

    for key, preds in grouped_preds.items():
        for r in preds:
            try:
                if r.get("status") not in [None, "", "pending", "v_pending"]:
                    updated.append(r); continue

                symbol = r.get("symbol", "UNKNOWN")
                strategy = r.get("strategy", "ÏïåÏàòÏóÜÏùå")
                model = r.get("model", "unknown")
                group_id = int(r.get("group_id", 0)) if str(r.get("group_id")).isdigit() else 0

                pred_class = int(float(r.get("predicted_class", -1))) if pd.notnull(r.get("predicted_class")) else -1
                label = int(float(r.get("label", -1))) if pd.notnull(r.get("label")) else -1
                r["label"] = label

                entry_price = float(r.get("entry_price", 0))
                if entry_price <= 0 or label == -1:
                    reason = "entry_price Ïò§Î•ò ÎòêÎäî label=-1"
                    r.update({"status": "fail", "reason": reason, "return": 0.0})
                    log_prediction(
                        symbol=symbol, strategy=strategy, direction="ÏòàÏ∏°Ïã§Ìå®",
                        entry_price=entry_price, target_price=entry_price,
                        timestamp=now_local().isoformat(), model=model, predicted_class=pred_class,
                        success=False, reason=reason, rate=0.0, return_value=0.0,
                        volatility=False, source="ÌèâÍ∞Ä", label=label, group_id=group_id
                    )
                    if not check_failure_exists(r):
                        from failure_db import insert_failure_record
                        insert_failure_record(r, f"{symbol}-{strategy}-{now_local().isoformat()}",
                                              feature_vector=None, label=label)
                    updated.append(r); continue

                timestamp = pd.to_datetime(r.get("timestamp"), errors="coerce")
                if timestamp is None or pd.isna(timestamp):
                    r.update({"status": "fail", "reason": "timestamp ÌååÏã± Ïã§Ìå®", "return": 0.0})
                    updated.append(r); continue
                if timestamp.tzinfo is None:
                    timestamp = timestamp.tz_localize("Asia/Seoul")
                else:
                    timestamp = timestamp.tz_convert("Asia/Seoul")

                eval_hours = eval_horizon_map.get(strategy, 6)
                deadline = timestamp + pd.Timedelta(hours=eval_hours)

                df = get_price_fn(symbol, strategy)
                if df is None or "timestamp" not in df.columns:
                    r.update({"status": "fail", "reason": "Í∞ÄÍ≤© Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå", "return": 0.0})
                    updated.append(r); continue

                df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
                df["timestamp"] = df["timestamp"].dt.tz_localize("UTC").dt.tz_convert("Asia/Seoul")
                future_df = df[df["timestamp"] >= timestamp]
                if future_df.empty:
                    r.update({"status": "fail", "reason": "ÎØ∏Îûò Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå", "return": 0.0})
                    updated.append(r); continue

                actual_max = future_df["high"].max()
                gain = (actual_max - entry_price) / (entry_price + 1e-12)

                if pred_class >= 0:
                    cls_min, cls_max = get_class_return_range(pred_class, symbol, strategy)
                else:
                    cls_min, cls_max = (0.0, 0.0)

                reached_target = gain >= cls_min

                if now_local() < deadline:
                    if reached_target:
                        status = "success"
                    else:
                        r.update({"status": "pending", "reason": "‚è≥ ÌèâÍ∞Ä ÎåÄÍ∏∞ Ï§ë", "return": round(gain, 5)})
                        updated.append(r); continue
                else:
                    status = "success" if reached_target else "fail"

                vol = str(r.get("volatility", "")).lower() in ["1", "true"]
                if vol:
                    status = "v_success" if status == "success" else "v_fail"

                r.update({
                    "status": status,
                    "reason": f"[pred_class={pred_class}] gain={gain:.3f} (cls_min={cls_min}, cls_max={cls_max})",
                    "return": round(gain, 5),
                    "group_id": group_id
                })

                log_prediction(
                    symbol=symbol, strategy=strategy, direction=f"ÌèâÍ∞Ä:{status}",
                    entry_price=entry_price, target_price=entry_price * (1 + gain),
                    timestamp=now_local().isoformat(), model=model, predicted_class=pred_class,
                    success=(status in ["success", "v_success"]), reason=r["reason"],
                    rate=gain, return_value=gain, volatility=vol, source="ÌèâÍ∞Ä",
                    label=label, group_id=group_id
                )

                if status in ["fail", "v_fail"] and not check_failure_exists(r):
                    from failure_db import insert_failure_record
                    insert_failure_record(r, f"{symbol}-{strategy}-{now_local().isoformat()}",
                                          feature_vector=None, label=label)

                if model == "meta":
                    update_model_success(symbol, strategy, model, status in ["success", "v_success"])

                evaluated.append({str(k): (v if v is not None else "") for k, v in r.items()})
            except Exception as e:
                r.update({"status": "fail", "reason": f"ÏòàÏô∏: {e}", "return": 0.0})
                updated.append(r)

    def safe_write_csv(path, rows):
        if not rows:
            return
        fieldnames = sorted({str(k) for row in rows for k in row.keys() if k is not None})
        with open(path, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(rows)

    updated += evaluated
    safe_write_csv(PREDICTION_LOG, updated)
    safe_write_csv(EVAL_RESULT, evaluated)
    failed = [r for r in evaluated if r["status"] in ["fail", "v_fail"]]
    safe_write_csv(WRONG, failed)

    print(f"[‚úÖ ÌèâÍ∞Ä ÏôÑÎ£å] Ï¥ù {len(evaluated)}Í±¥ ÌèâÍ∞Ä, Ïã§Ìå® {len(failed)}Í±¥")

# -----------------------------
# Í∞úÎ≥Ñ Î™®Îç∏ ÏòàÏ∏°(Í∑∏ÎåÄÎ°ú + Î°úÍ∑∏ Î≥¥Í∞ï)
# -----------------------------
def get_model_predictions(symbol, strategy, models, df, feat_scaled, window_list, recent_freq):
    import json
    model_outputs_list, all_model_predictions = [], []

    # Ï≤´ Î™®Îç∏Ïùò ÌÅ¥ÎûòÏä§ Ïàò Í∏∞Ï§ÄÏúºÎ°ú Î∂àÏùºÏπò Î™®Îç∏ÏùÄ Ïä§ÌÇµ
    expected_num_classes = None

    for model_info in models:
        try:
            pt_file = model_info.get("pt_file")
            if not pt_file:
                continue
            model_path = os.path.join(MODEL_DIR, pt_file)
            meta_path = model_path.replace(".pt", ".meta.json")
            if not os.path.exists(meta_path):
                print(f"[‚ö†Ô∏è Î©îÌÉÄÌååÏùº ÏóÜÏùå] {meta_path}")
                continue

            with open(meta_path, "r", encoding="utf-8") as f:
                meta = json.load(f)
            model_type = meta.get("model", "lstm")
            group_id = meta.get("group_id", 0)
            input_size = meta.get("input_size", FEATURE_INPUT_SIZE)
            num_classes = meta.get("num_classes", NUM_CLASSES)

            if expected_num_classes is None:
                expected_num_classes = int(num_classes)
            elif int(num_classes) != expected_num_classes:
                print(f"[‚ö†Ô∏è ÌÅ¥ÎûòÏä§Ïàò Î∂àÏùºÏπò Ïä§ÌÇµ] {pt_file} num_classes={num_classes} (expected={expected_num_classes})")
                continue

            window = window_list[min(int(group_id), max(0, len(window_list) - 1))]
            input_seq = feat_scaled[-window:]
            if input_seq.shape[0] < window:
                print(f"[‚ö†Ô∏è Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°±] {symbol}-{strategy}-group{group_id}")
                continue

            input_tensor = torch.tensor(input_seq, dtype=torch.float32).unsqueeze(0)

            model = get_model(model_type, input_size=input_size, output_size=num_classes)
            model = load_model_cached(model_path, model, ttl_sec=600)
            if model is None:
                print(f"[‚ö†Ô∏è Î™®Îç∏ Î°úÎî© Ïã§Ìå®] {model_path}")
                continue
            model.eval()

            with torch.no_grad():
                out = model(input_tensor.to(DEVICE))
                softmax_probs = F.softmax(out, dim=1)
                predicted_class = torch.argmax(softmax_probs, dim=1).item()
                probs = softmax_probs.squeeze().cpu().numpy()

            print(f"[üî© Î™®Îç∏ÏòàÏ∏°] {os.path.basename(model_path)} g{group_id} -> pred={predicted_class}, top5={np.argsort(probs)[::-1][:5].tolist()}")

            model_outputs_list.append({
                "probs": probs, "predicted_class": predicted_class, "group_id": group_id,
                "model_type": model_type, "model_path": model_path,
                "symbol": symbol, "strategy": strategy
            })

            entry_price = df["close"].iloc[-1]
            all_model_predictions.append({
                "class": predicted_class, "probs": probs, "entry_price": float(entry_price),
                "num_classes": num_classes, "group_id": group_id,
                "model_name": model_type, "model_symbol": symbol,
                "symbol": symbol, "strategy": strategy
            })

        except Exception as e:
            print(f"[‚ùå Î™®Îç∏ ÏòàÏ∏° Ïã§Ìå®] {model_info} ‚Üí {e}")
            continue

    return model_outputs_list, all_model_predictions

# -----------------------------
# Îã®ÎèÖ Ïã§Ìñâ ÌÖåÏä§Ìä∏
# -----------------------------
if __name__ == "__main__":
    res = predict("BTCUSDT", "Îã®Í∏∞")
    print(res)
    try:
        df = pd.read_csv(PREDICTION_LOG_PATH, encoding="utf-8-sig")
        print("[‚úÖ prediction_log.csv ÏÉÅÏúÑ 20Ï§Ñ Ï∂úÎ†•]")
        print(df.head(20))
    except Exception as e:
        print(f"[Ïò§Î•ò] prediction_log.csv Î°úÎìú Ïã§Ìå® ‚Üí {e}")
