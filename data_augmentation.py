# data_augmentation.py â€” ì¦ê°•/í´ë˜ìŠ¤ê· í˜• + (ì˜µì…˜) íŒ¨í„´ìœ ì‚¬ë„ ë³´ë¥˜ê¹Œì§€ "í•œ íŒŒì¼"ë¡œ í†µí•©
from __future__ import annotations
import numpy as np
from collections import Counter
from typing import Tuple, Optional, Dict, List

# (ì˜µì…˜) torch ìƒ˜í”ŒëŸ¬ ì§€ì›  # âœ… ì¶”ê°€
try:
    import torch
    from torch.utils.data import WeightedRandomSampler
except Exception:
    torch = None
    WeightedRandomSampler = None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (ì˜µì…˜) ë°ì´í„° ì ‘ê·¼: predict ë‹¨ê³„ ìœ ì‚¬ë„ ë³´ë¥˜ìš©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    from data.utils import get_kline_by_strategy
except Exception:
    try:
        from utils import get_kline_by_strategy  # ë£¨íŠ¸ í´ë°±
    except Exception:
        get_kline_by_strategy = None  # ì—†ìœ¼ë©´ ë³´ë¥˜ ê¸°ëŠ¥ì€ ìë™ ë¹„í™œì„±

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì¦ê°• ìœ í‹¸
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def add_gaussian_noise(X: np.ndarray, mean: float = 0.0, std: float = 0.01,
                       rng: Optional[np.random.Generator] = None) -> np.ndarray:
    rng = rng or np.random
    noise = rng.normal(mean, std, X.shape).astype(np.float32)
    return (X.astype(np.float32) + noise)

def apply_scaling(X: np.ndarray, scale_range: Tuple[float, float] = (0.95, 1.05),
                  rng: Optional[np.random.Generator] = None) -> np.ndarray:
    rng = rng or np.random
    scale = float(rng.uniform(*scale_range))
    return (X.astype(np.float32) * scale)

def apply_shift(X: np.ndarray, shift_range: Tuple[float, float] = (-0.02, 0.02),
                rng: Optional[np.random.Generator] = None) -> np.ndarray:
    rng = rng or np.random
    shift = float(rng.uniform(*shift_range))
    return (X.astype(np.float32) + shift)

def apply_dropout_mask(X: np.ndarray, dropout_prob: float = 0.05,
                       rng: Optional[np.random.Generator] = None) -> np.ndarray:
    rng = rng or np.random
    mask = rng.binomial(1, 1.0 - float(dropout_prob), X.shape).astype(np.float32)
    return (X.astype(np.float32) * mask)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë°°ì¹˜ ì¦ê°•
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def augment_batch(X_batch: np.ndarray,
                  add_noise_prob: float = 0.9,
                  scale_prob: float = 0.6,
                  shift_prob: float = 0.5,
                  dropout_prob: float = 0.3,
                  rng: Optional[np.random.Generator] = None) -> np.ndarray:
    """
    X_batch: (batch, window, feat) ë˜ëŠ” (window, feat)
    ë°˜í™˜: float32 ë°°ì—´
    """
    if X_batch is None:
        return np.array([], dtype=np.float32)

    rng_local = rng if isinstance(rng, np.random.Generator) else np.random.default_rng()
    arr = np.array(X_batch, dtype=np.float32)
    if arr.ndim == 2:
        arr = arr[np.newaxis, ...]

    outs: List[np.ndarray] = []
    for x in arr:
        xa = x.copy()
        try:
            if rng_local.random() < add_noise_prob:
                xa = add_gaussian_noise(xa, std=0.01, rng=rng_local)
            if rng_local.random() < scale_prob:
                xa = apply_scaling(xa, (0.95, 1.05), rng_local)
            if rng_local.random() < shift_prob:
                xa = apply_shift(xa, (-0.02, 0.02), rng_local)
            if rng_local.random() < dropout_prob:
                xa = apply_dropout_mask(xa, 0.05, rng_local)
        except Exception:
            xa = x.copy()
        outs.append(xa.astype(np.float32))

    return np.stack(outs, axis=0)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì†Œìˆ˜ í´ë˜ìŠ¤ ë³µì œ + ë¯¸ì„¸ ë…¸ì´ì¦ˆ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _dup_with_noise(X: np.ndarray, times: int, noise_level: float = 0.005) -> np.ndarray:
    if times <= 1:
        return X.astype(np.float32)
    X_rep = np.repeat(X.astype(np.float32), times, axis=0)
    if noise_level > 0:
        std = np.std(X, axis=0)
        std = np.where(np.isfinite(std), std, 0.0)
        std = np.clip(std, 1e-6, None)
        noise = np.random.normal(0.0, noise_level, size=X_rep.shape) * std
        X_rep = (X_rep + noise.astype(np.float32)).astype(np.float32)
    return X_rep

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì • (ì•ˆì • ìº¡ í¬í•¨)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def balance_classes(X: np.ndarray,
                    y: np.ndarray,
                    min_count: int = 5,
                    num_classes: Optional[int] = None,
                    target_ratio: float = 0.8,
                    rng: Optional[np.random.Generator] = None) -> Tuple[np.ndarray, np.ndarray]:
    """
    - ì†Œìˆ˜ í´ë˜ìŠ¤ë§Œ ì ë‹¹íˆ ì˜¤ë²„ìƒ˜í”Œ
    - ê³¼ë„ ì¦í­ ë°©ì§€: ìƒìœ„ 75í¼ì„¼íƒ€ì¼ ìº¡ + ë°°ìˆ˜ ìƒí•œ(2~6ë°°)
    - ì›ë³¸ ë¶„í¬ë¥¼ í¬ê²Œ í›¼ì†í•˜ì§€ ì•Šë„ë¡ ê²½ë¯¸ ë³€í˜• ìœ„ì£¼
    - âš ï¸ 'ë¼ë²¨ ë³‘í•©/ì¶•ì†Œ'ëŠ” í•˜ì§€ ì•ŠìŒ (YOPO ì² í•™ ì¤€ìˆ˜)
    """
    if X is None or y is None or len(X) == 0 or len(y) == 0:
        raise ValueError("balance_classes ì¤‘ë‹¨: X ë˜ëŠ” y ë¹„ì–´ìˆìŒ")

    rng_local = rng if isinstance(rng, np.random.Generator) else np.random.default_rng()
    X = np.asarray(X, dtype=np.float32)
    y = np.asarray(y).astype(np.int64)

    # ê¸°ëŒ€ í˜•íƒœ: (N, window, feat)
    if X.ndim != 3 or y.ndim != 1 or len(X) != len(y):
        return X, y

    if num_classes is None:
        num_classes = int(np.max(y)) + 1 if len(y) > 0 else 0
    if num_classes <= 1:
        return X, y

    cc = Counter(y.tolist())
    print(f"[ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬] {dict(cc)}")

    X_parts = [X]
    y_parts = [y]

    nz = np.array([c for c in cc.values() if c > 0], dtype=int)
    if nz.size == 0:
        return X, y
    cap = max(int(np.percentile(nz, 75)), int(np.mean(nz)), 32)

    idx_by_cls = {c: np.where(y == c)[0] for c in range(num_classes)}
    for cls in range(num_classes):
        idx = idx_by_cls.get(cls, np.array([], dtype=int))
        c = int(len(idx))
        if c <= 0 or c >= cap:
            continue
        need = cap - c
        times = int(np.ceil((c + need) / max(c, 1)))
        times = max(2, min(times, 6))

        X_cls = X[idx]
        X_aug = _dup_with_noise(X_cls, times=times, noise_level=0.005)
        take = min(max(0, len(X_aug) - c), need) if len(X_aug) > c else min(len(X_aug), need)
        if take > 0:
            base = X_aug[:take]
            try:
                base = augment_batch(base, rng=rng_local)
            except Exception:
                pass
            X_parts.append(base.astype(np.float32))
            y_parts.append(np.full((take,), cls, dtype=np.int64))

    X_out = np.concatenate(X_parts, axis=0)
    y_out = np.concatenate(y_parts, axis=0)

    perm = rng_local.permutation(len(y_out))
    X_out = X_out[perm].astype(np.float32)
    y_out = y_out[perm].astype(np.int64)

    print(f"[ğŸ“Š ìµœì¢… í´ë˜ìŠ¤ ë¶„í¬] {dict(Counter(y_out.tolist()))}")
    print(f"[âœ… balance_classes ì™„ë£Œ] ì´ ìƒ˜í”Œìˆ˜: {len(y_out)} (ìº¡={cap})")
    return X_out, y_out

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# âœ… í•™ìŠµìš© í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ & ìƒ˜í”ŒëŸ¬ (ë¼ë²¨ ë³‘í•© ì—†ì´ ë³´ì •)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def compute_class_weights(y: np.ndarray,
                          num_classes: Optional[int] = None,
                          method: str = "effective",
                          beta: float = 0.999) -> np.ndarray:
    """
    method:
      - "inverse":  weight_c = 1 / count_c
      - "effective": weight_c = (1 - beta) / (1 - beta**count_c)  (Cui et al., 2019)
    ë°˜í™˜: shape=(num_classes,) float32
    """
    y = np.asarray(y).astype(np.int64)
    if y.size == 0:
        return np.zeros((0,), dtype=np.float32)
    if num_classes is None:
        num_classes = int(np.max(y)) + 1
    counts = np.bincount(y, minlength=num_classes).astype(np.float64)
    counts[counts <= 0] = 1.0

    if method == "inverse":
        w = 1.0 / counts
    else:  # effective
        beta = float(beta)
        w = (1.0 - beta) / (1.0 - np.power(beta, counts))
    w = w / (w.mean() + 1e-12)
    return w.astype(np.float32)

def make_sample_weights(y: np.ndarray, class_weights: np.ndarray) -> np.ndarray:
    """
    ê° ìƒ˜í”Œë³„ weight = class_weights[y_i]
    """
    y = np.asarray(y).astype(np.int64)
    w = np.asarray(class_weights, dtype=np.float32)
    if y.size == 0 or w.size == 0:
        return np.zeros((0,), dtype=np.float32)
    w = w / (w.mean() + 1e-12)
    return w[y]

def make_weighted_sampler(y: np.ndarray,
                          class_weights: Optional[np.ndarray] = None,
                          method: str = "effective",
                          beta: float = 0.999,
                          replacement: bool = True):
    """
    PyTorch WeightedRandomSampler ìƒì„± (ê°€ëŠ¥í•  ë•Œë§Œ).
    - torch ë¯¸ì„¤ì¹˜/ë¶ˆê°€ ì‹œ None ë°˜í™˜
    """
    if torch is None or WeightedRandomSampler is None:
        return None
    y = np.asarray(y).astype(np.int64)
    if y.size == 0:
        return None
    if class_weights is None:
        class_weights = compute_class_weights(y, method=method, beta=beta)
    sample_w = make_sample_weights(y, class_weights)
    tens = torch.as_tensor(sample_w, dtype=torch.float32)
    return WeightedRandomSampler(weights=tens, num_samples=len(tens), replacement=replacement)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# (ì˜µì…˜) ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ë³´ë¥˜ Guard â€” predictì—ì„œ í•„ìš” ì‹œ ì‚¬ìš©
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _to_returns(close: np.ndarray) -> np.ndarray:
    close = np.asarray(close, dtype=np.float64)
    if close.size < 3:
        return np.zeros((0,), dtype=np.float64)
    r = np.diff(close) / (close[:-1] + 1e-12)
    r = np.tanh(r * 5.0)
    r = r - r.mean()
    std = r.std() + 1e-12
    return (r / std)

def _cosine(a: np.ndarray, b: np.ndarray) -> float:
    a = a.astype(np.float64, copy=False)
    b = b.astype(np.float64, copy=False)
    na = np.linalg.norm(a) + 1e-12
    nb = np.linalg.norm(b) + 1e-12
    return float(np.dot(a, b) / (na * nb))

def _rolling_template(x: np.ndarray, w: int, stride: int = 8) -> np.ndarray:
    vs = []
    if x.size < w:
        return np.zeros((0, w), dtype=np.float64)
    for i in range(0, x.size - w + 1, stride):
        vs.append(x[i:i+w])
    if not vs:
        return np.zeros((0, w), dtype=np.float64)
    return np.stack(vs, axis=0)

def should_abstain_by_similarity(symbol: str, strategy: str, window: int = 60, thr: float = 0.10) -> bool:
    """
    ìµœê·¼ window ê¸¸ì´ ë°˜í™˜ìœ¨ íŒ¨í„´ê³¼ ê³¼ê±° í…œí”Œë¦¿ì˜ í‰ê·  ì½”ì‚¬ì¸ ìœ ì‚¬ë„ê°€ thr ë¯¸ë§Œì´ë©´ ë³´ë¥˜(True).
    get_kline_by_strategyê°€ ì—†ê±°ë‚˜ ë°ì´í„° ë¶€ì¡±ì´ë©´ False(ë³´ë¥˜ ì•„ë‹˜).
    """
    if get_kline_by_strategy is None:
        return False
    try:
        df = get_kline_by_strategy(symbol, strategy)
        if df is None or "close" not in df.columns or len(df) < (window * 4):
            return False
        close = df["close"].to_numpy(dtype=np.float64)
        r = _to_returns(close)
        if r.size < (window * 4):
            return False

        cur = r[-window:]
        hist = r[:-(window*3)]
        tmpl = _rolling_template(hist, w=window, stride=max(4, window // 8))
        if tmpl.shape[0] == 0:
            return False

        sims = np.array([_cosine(cur, t) for t in tmpl], dtype=np.float64)
        sim_mean = float(np.nanmean(sims)) if sims.size else 0.0
        return (sim_mean < float(thr))
    except Exception:
        return False
