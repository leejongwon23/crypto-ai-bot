import torch
import numpy as np
import os
import json
import pandas as pd

PERSIST_DIR = "/persistent"
IMPORTANCE_DIR = os.path.join(PERSIST_DIR, "importances")
os.makedirs(IMPORTANCE_DIR, exist_ok=True)

# --- ì¤‘ìš”ë„ ë¶„ì„ (ëª¨ë¸ ì¶œë ¥ì´ íŠœí”Œì¸ì§€ ì•ˆì „ ì²´í¬ í¬í•¨)
def compute_feature_importance(model, X_val, y_val, feature_names):
    model.eval()

    try:
        pred, *_ = model(X_val)
    except Exception as e:
        print(f"[ERROR] ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨ (ê¸°ë³¸): {e}")
        return dict(zip(feature_names, [0.0] * len(feature_names)))

    baseline_loss = torch.nn.BCELoss()(pred, y_val).item()
    importances = []

    for i in range(X_val.shape[2]):
        X_permuted = X_val.clone()
        X_permuted[:, :, i] = X_permuted[:, torch.randperm(X_val.shape[1]), i]
        try:
            perm_pred, *_ = model(X_permuted)
            loss = torch.nn.BCELoss()(perm_pred, y_val).item()
            importances.append(loss - baseline_loss)
        except Exception as e:
            print(f"[ERROR] ì¤‘ìš”ë„ ê³„ì‚° ì‹¤íŒ¨ (feature {i}): {e}")
            importances.append(0.0)

    return dict(zip(feature_names, importances))

# --- CNN_LSTM & Transformerìš© permutation ì¤‘ìš”ë„ (ì˜ˆì™¸ ì²˜ë¦¬ í¬í•¨)
def compute_permutation_importance(model, X_val, y_val, feature_names):
    model.eval()

    try:
        pred, *_ = model(X_val)
    except Exception as e:
        print(f"[ERROR] ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨ (perm): {e}")
        return dict(zip(feature_names, [0.0] * len(feature_names)))

    baseline_loss = torch.nn.BCELoss()(pred, y_val).item()
    importances = []

    for i in range(X_val.shape[2]):
        X_permuted = X_val.clone()
        perm_idx = torch.randperm(X_val.shape[0])
        X_permuted[:, :, i] = X_permuted[perm_idx, :, i]
        try:
            perm_pred, *_ = model(X_permuted)
            loss = torch.nn.BCELoss()(perm_pred, y_val).item()
            importances.append(loss - baseline_loss)
        except Exception as e:
            print(f"[ERROR] ì¤‘ìš”ë„ ê³„ì‚° ì‹¤íŒ¨ (perm feature {i}): {e}")
            importances.append(0.0)

    return dict(zip(feature_names, importances))

def save_feature_importance(importances, symbol, strategy, model_type):
    fname = f"{symbol}_{strategy}_{model_type}_importance.json"
    path = os.path.join(IMPORTANCE_DIR, fname)
    with open(path, "w") as f:
        json.dump(importances, f, indent=2)
    print(f"âœ… ì¤‘ìš”ë„ ì €ì¥ë¨: {path}")

# âœ… ì¤‘ìš”ë„ ê¸°ë°˜ feature ì œê±° í•¨ìˆ˜
def drop_low_importance_features(df: pd.DataFrame, importances: dict, threshold: float = 0.05) -> pd.DataFrame:
    """
    ì¤‘ìš”ë„ê°€ ë‚®ì€ featureë“¤ì„ ì œê±°í•œ ìƒˆë¡œìš´ DataFrame ë°˜í™˜
    """
    drop_cols = [col for col, imp in importances.items() if imp < threshold]
    remaining_cols = [col for col in df.columns if col not in drop_cols]
    if not remaining_cols:
        print("[ê²½ê³ ] ëª¨ë“  featureê°€ ì œê±°ë˜ì—ˆìŒ. ìµœì†Œ 1ê°œ ì´ìƒ ìœ ì§€ í•„ìš”.")
        return df
    print(f"ğŸ§¹ ì œê±°ëœ feature ìˆ˜: {len(drop_cols)} â†’ {drop_cols}")
    return df[remaining_cols]
