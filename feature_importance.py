# === feature_importance.py (ë””ìŠ¤í¬ ë¶€ì¡± ë‚´ì„±, train.py í˜¸í™˜, ì•ˆì „ ì €ìž¥) ===
import os
import json
import time
import errno
import torch
import numpy as np
import pandas as pd

# ì—¬ê¸°ë§Œ ë°”ê¿¨ì–´ ðŸ‘‡
PERSIST_DIR = "/opt/render/project/src/persistent"

DEFAULT_IMPORTANCE_DIR = os.path.join(PERSIST_DIR, "importances")
FALLBACK_IMPORTANCE_DIR = os.environ.get("TMPDIR", "/tmp") + "/importances"
DISABLE_IMPORTANCE_SAVE = os.environ.get("DISABLE_IMPORTANCE_SAVE", "0") == "1"

_cached_dir = None
_cached_disabled = False


def _ensure_dir(path: str) -> str | None:
    """ë””ë ‰í† ë¦¬ ìƒì„±. ENOSPCë©´ None ë°˜í™˜. ê·¸ ì™¸ ì˜¤ë¥˜ëŠ” ì¡°ìš©ížˆ í¬ê¸°."""
    try:
        os.makedirs(path, exist_ok=True)
        return path
    except OSError as e:
        if e.errno == errno.ENOSPC:
            return None
        return None


def _get_importance_dir() -> str | None:
    """ìš°ì„ ìˆœìœ„: /opt/render/project/src/persistent â†’ /tmp â†’ ì—†ìœ¼ë©´ ë¹„í™œì„±í™”"""
    global _cached_dir, _cached_disabled
    if _cached_disabled or DISABLE_IMPORTANCE_SAVE:
        return None
    if _cached_dir:
        return _cached_dir

    # 1) persistent ë°‘ì—
    d1 = _ensure_dir(DEFAULT_IMPORTANCE_DIR)
    if d1:
        _cached_dir = d1
        return d1

    # 2) /tmp
    d2 = _ensure_dir(FALLBACK_IMPORTANCE_DIR)
    if d2:
        _cached_dir = d2
        print(f"[feature_importance] ì €ìž¥ ê²½ë¡œë¥¼ ìž„ì‹œë¡œ ì „í™˜: {d2}")
        return d2

    # 3) ì‹¤íŒ¨ â†’ ë¹„í™œì„±í™”
    _cached_disabled = True
    print("[feature_importance] ê²½ê³ : ì €ìž¥ ë¹„í™œì„±í™”(ë””ìŠ¤í¬ ì—¬ìœ  ì—†ìŒ)")
    return None


def _ensure_feature_names(feature_names, n_features):
    if isinstance(feature_names, (list, tuple)) and len(feature_names) == n_features:
        return list(feature_names)
    return [f"f_{i}" for i in range(n_features)]


@torch.no_grad()
def compute_feature_importance(
    model,
    X_val,
    y_val=None,
    feature_names=None,
    method: str = "baseline",
    *,
    device=None,
    max_seconds: float = 30.0,
    print_every: int = 20,
):
    """
    permutation ê¸°ë°˜ ì¤‘ìš”ë„. ì‹œê°„ ì˜ˆì‚° ì´ˆê³¼ ì‹œ ì¡°ê¸° ì¢…ë£Œ.
    """
    # 1) ìž…ë ¥ ì •ë¦¬
    if isinstance(X_val, pd.DataFrame):
        feature_names = list(X_val.columns)
        X_np = X_val.values.astype(np.float32)
        X_val = torch.from_numpy(X_np[:, None, :])  # (N, 1, F)
    elif isinstance(X_val, np.ndarray):
        X_np = X_val.astype(np.float32)
        if X_np.ndim == 2:
            X_np = X_np[:, None, :]
        X_val = torch.from_numpy(X_np)

    # 2) device
    if device is not None:
        X_val = X_val.to(device)
        model = model.to(device)

    # 3) y
    if y_val is None:
        y_val = torch.zeros(X_val.shape[0], dtype=torch.long, device=X_val.device)
    else:
        if isinstance(y_val, np.ndarray):
            y_val = torch.from_numpy(y_val.astype(np.int64)).to(X_val.device)
        elif isinstance(y_val, torch.Tensor):
            y_val = y_val.to(X_val.device)
        else:
            y_val = torch.zeros(X_val.shape[0], dtype=torch.long, device=X_val.device)

    n_feat = int(X_val.shape[2])
    names = _ensure_feature_names(feature_names, n_feat)

    model.eval()
    start = time.time()

    # ê¸°ì¤€ loss
    try:
        logits = model(X_val)
        y_val = y_val.view(-1).long()
        baseline_loss = torch.nn.CrossEntropyLoss()(logits, y_val).item()
    except Exception as e:
        print(f"[feature_importance] ëª¨ë¸ ì˜ˆì¸¡ ì‹¤íŒ¨({method}): {e}")
        return dict(zip(names, [0.0] * n_feat))

    importances = np.zeros(n_feat, dtype=float)

    for i in range(n_feat):
        # ì‹œê°„ ì˜ˆì‚° ì²´í¬
        if (time.time() - start) > float(max_seconds):
            print(f"[feature_importance] ì‹œê°„ì˜ˆì‚° ì´ˆê³¼ â†’ {i}/{n_feat}ì—ì„œ ì¤‘ë‹¨")
            break
        try:
            X_perm = X_val.clone()
            perm_idx = torch.randperm(X_val.shape[0], device=X_val.device)
            X_perm[:, :, i] = X_perm[perm_idx, :, i]

            logits_perm = model(X_perm)
            loss = torch.nn.CrossEntropyLoss()(logits_perm, y_val).item()
            importances[i] = float(loss - baseline_loss)

            if print_every and (i % max(1, int(print_every)) == 0):
                print(f"[imp] {i+1}/{n_feat} Î”={importances[i]:.6f}")
        except Exception as e:
            print(f"[feature_importance] ì¤‘ìš”ë„ ê³„ì‚° ì‹¤íŒ¨({method}, idx={i}): {e}")
            importances[i] = 0.0

    return dict(zip(names, importances.tolist()))


def compute_permutation_importance(model, X_val, y_val, feature_names, **kwargs):
    return compute_feature_importance(
        model,
        X_val,
        y_val,
        feature_names,
        method="permutation",
        **kwargs,
    )


def _safe_write_json(path: str, obj) -> bool:
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
        return True
    except OSError as e:
        if getattr(e, "errno", None) == errno.ENOSPC:
            print(f"[feature_importance] ENOSPC: JSON ì €ìž¥ ì‹¤íŒ¨ â†’ {path}")
            return False
        print(f"[feature_importance] JSON ì €ìž¥ ì˜¤ë¥˜: {e}")
        return False


def _safe_write_csv(path: str, df: pd.DataFrame) -> bool:
    try:
        df.to_csv(path, index=False, encoding="utf-8-sig")
        return True
    except OSError as e:
        if getattr(e, "errno", None) == errno.ENOSPC:
            print(f"[feature_importance] ENOSPC: CSV ì €ìž¥ ì‹¤íŒ¨ â†’ {path}")
            return False
        print(f"[feature_importance] CSV ì €ìž¥ ì˜¤ë¥˜: {e}")
        return False


def save_feature_importance(
    importances,
    symbol,
    strategy,
    model_type=None,
    method: str = "baseline",
    **kwargs,  # í˜¸ì¶œë¶€ì—ì„œ window ê°™ì€ ê±° ë„£ì–´ë„ ë¬´ì‹œ
):
    """
    train ìª½ì—ì„œ model_type ì•ˆ ì¤˜ë„ ê¹¨ì§€ì§€ ì•Šê²Œ í•œ ë²„ì „.
    """
    if DISABLE_IMPORTANCE_SAVE:
        print("[feature_importance] ì €ìž¥ ë¹„í™œì„±í™”(í™˜ê²½ë³€ìˆ˜)")
        return False

    if model_type is None:
        model_type = "default"

    out_dir = _get_importance_dir()
    if not out_dir:
        return False

    suffix = f"_importance_{method}"
    fname_base = f"{symbol}_{strategy}_{model_type}{suffix}"
    path_json = os.path.join(out_dir, fname_base + ".json")
    path_csv = os.path.join(out_dir, fname_base + ".csv")

    imp = {str(k): float(v) for k, v in (importances or {}).items()}
    ok_json = _safe_write_json(path_json, imp)

    df = pd.DataFrame(imp.items(), columns=["feature", "importance"]).sort_values(
        by="importance", ascending=False
    )
    ok_csv = _safe_write_csv(path_csv, df)

    if ok_json and ok_csv:
        print(f"[feature_importance] ì €ìž¥ ì™„ë£Œ: {path_json}, {path_csv}")
        return True

    # í•œ ë²ˆ ë” /tmp
    if out_dir != FALLBACK_IMPORTANCE_DIR:
        fb_dir = _ensure_dir(FALLBACK_IMPORTANCE_DIR)
        if fb_dir:
            pj = os.path.join(fb_dir, fname_base + ".json")
            pc = os.path.join(fb_dir, fname_base + ".csv")
            ok_json2 = ok_json or _safe_write_json(pj, imp)
            ok_csv2 = ok_csv or _safe_write_csv(pc, df)
            if ok_json2 and ok_csv2:
                print(f"[feature_importance] í´ë°± ì €ìž¥ ì™„ë£Œ: {pj}, {pc}")
                return True

    print("[feature_importance] ê²½ê³ : ì¤‘ìš”ë„ ì €ìž¥ ì‹¤íŒ¨(ë””ìŠ¤í¬ ì—¬ìœ  ì—†ìŒ)")
    return False


def drop_low_importance_features(
    df: pd.DataFrame,
    importances: dict,
    threshold: float = 0.05,
    input_size: int = None,
    min_features: int = 5,
) -> pd.DataFrame:
    importances = importances or {}
    drop_cols = [
        col for col, imp in importances.items() if (imp is not None and float(imp) < threshold)
    ]
    remaining_cols = [
        c for c in df.columns if c not in drop_cols and c not in ["timestamp", "strategy"]
    ]

    # ìµœì†Œ í”¼ì²˜ ìˆ˜ ë³´ìž¥
    if len(remaining_cols) < min_features:
        for i in range(len(remaining_cols), min_features):
            pad_col = f"pad_{i}"
            if pad_col not in df.columns:
                df[pad_col] = 0.0
            remaining_cols.append(pad_col)

    if not remaining_cols:
        print("[feature_importance] ê²½ê³ : ëª¨ë“  feature ì œê±°ë¨ â†’ pad_0 ì¶”ê°€")
        df["pad_0"] = 0.0
        remaining_cols = ["pad_0"]

    print(f"[feature_importance] ì œê±°ëœ feature ìˆ˜: {len(drop_cols)} â†’ {drop_cols}")
    cols_out = remaining_cols + [c for c in ["timestamp", "strategy"] if c in df.columns]
    return df[cols_out]


def get_top_features(importances: dict, top_n: int = 10) -> pd.DataFrame:
    if not importances:
        return pd.DataFrame(columns=["feature", "importance"])
    df = pd.DataFrame(importances.items(), columns=["feature", "importance"])
    return df.sort_values(by="importance", ascending=False).head(top_n)
