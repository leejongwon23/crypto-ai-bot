import os, csv, datetime, pandas as pd, pytz, hashlib
from data.utils import get_kline_by_strategy
import pandas as pd

DIR, LOG = "/persistent", "/persistent/logs"
PREDICTION_LOG = f"{DIR}/prediction_log.csv"
WRONG = f"{DIR}/wrong_predictions.csv"
EVAL_RESULT = f"{DIR}/evaluation_result.csv"
TRAIN_LOG = f"{LOG}/train_log.csv"
AUDIT_LOG = f"{LOG}/evaluation_audit.csv"
os.makedirs(LOG, exist_ok=True)

now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))
model_success_tracker = {}

def update_model_success(s, t, m, success):
    k = (s, t or "ì•Œìˆ˜ì—†ìŒ", m)
    model_success_tracker.setdefault(k, {"success":0,"fail":0})
    model_success_tracker[k]["success" if success else "fail"] += 1

def get_model_success_rate(s, t, m, min_total=10):
    r = model_success_tracker.get((s, t or "ì•Œìˆ˜ì—†ìŒ", m), {"success":0,"fail":0})
    total = r["success"] + r["fail"]
    return 0.5 if total < min_total else r["success"] / total

def load_failure_count():
    path = "/persistent/logs/failure_count.csv"
    if not os.path.exists(path): return {}
    try:
        with open(path, "r", encoding="utf-8-sig") as f:
            return {f"{r['symbol']}-{r['strategy']}": int(r["failures"]) for r in csv.DictReader(f)}
    except: return {}

def get_actual_success_rate(strategy):
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig")
        df = df[df["strategy"] == strategy]
        df = df[df["status"].isin(["success", "fail"])]
        return round(len(df[df["status"] == "success"]) / len(df), 4) if len(df) > 0 else 0.0
    except: return 0.0

def get_strategy_eval_count(strategy):
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig")
        return len(df[(df["strategy"] == strategy) & df["status"].isin(["success", "fail"])])
    except: return 0

def log_audit_prediction(s, t, status, reason):
    row = {
        "timestamp": now_kst().isoformat(),
        "symbol": str(s or "UNKNOWN"),
        "strategy": str(t or "ì•Œìˆ˜ì—†ìŒ"),
        "status": str(status),
        "reason": str(reason)
    }
    try:
        with open(AUDIT_LOG, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.DictWriter(f, fieldnames=row.keys())
            if f.tell() == 0: w.writeheader()
            w.writerow(row)
    except: pass

def log_prediction(symbol, strategy, direction=None, entry_price=0, target_price=0,
                   timestamp=None, model=None, success=True, reason="", rate=0.0,
                   return_value=None, volatility=False, source="ì¼ë°˜", predicted_class=None, label=None):
    import csv, os, datetime, pytz

    now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))
    now = timestamp or now_kst().isoformat()
    full_path = "/persistent/prediction_log.csv"
    date_str = now.split("T")[0]
    dated_path = f"/persistent/logs/prediction_{date_str}.csv"

    # âœ… predicted_class ë³´ì •
    try:
        pred_class_val = int(float(predicted_class))
        if pred_class_val < 0 or pred_class_val >= 100:
            pred_class_val = -1
    except:
        pred_class_val = -1

    # âœ… labelë„ predicted_classë¡œ ê¸°ë³¸ ëŒ€ì…
    if label is None or str(label).strip() == "":
        label = pred_class_val

    # âœ… ì˜ˆì¸¡ ì„±ê³µ ì—¬ë¶€ + ë³€ë™ì„± ê¸°ì¤€
    status = "v_success" if success and volatility else \
             "v_fail" if not success and volatility else \
             "success" if success else "fail"

    row = {
        "timestamp": now,
        "symbol": str(symbol or "UNKNOWN"),
        "strategy": str(strategy or "ì•Œìˆ˜ì—†ìŒ"),
        "direction": direction or "N/A",
        "entry_price": float(entry_price or 0.0),
        "target_price": float(target_price or 0.0),
        "model": str(model or "unknown"),
        "rate": float(rate or 0.0),
        "status": status,
        "reason": reason or "",
        "return": float(return_value if return_value is not None else rate or 0.0),
        "volatility": bool(volatility),
        "source": str(source or "ì¼ë°˜"),
        "predicted_class": str(int(pred_class_val)),
        "label": str(label)
    }

    # âœ… None key ì œê±°
    row = {k: v for k, v in row.items() if k is not None}

    try:
        with open(dated_path, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.DictWriter(f, fieldnames=row.keys())
            if f.tell() == 0:
                w.writeheader()
            w.writerow(row)
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ë‚ ì§œë³„ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨ â†’ {e}")

    try:
        with open(full_path, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.DictWriter(f, fieldnames=row.keys())
            if f.tell() == 0:
                w.writeheader()
            w.writerow(row)
    except Exception as e:
        print(f"[ì˜¤ë¥˜] í†µí•© ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨ â†’ {e}")



def get_dynamic_eval_wait(strategy):
    return {"ë‹¨ê¸°":4, "ì¤‘ê¸°":24, "ì¥ê¸°":168}.get(strategy, 6)

def get_feature_hash(feature_row):
    rounded = [round(float(x), 2) for x in feature_row]
    joined = ",".join(map(str, rounded))
    return hashlib.sha1(joined.encode()).hexdigest()

strategy_stats = {}

# ğŸ“ logger.py íŒŒì¼ í•˜ë‹¨ì— ì¶”ê°€í•˜ì„¸ìš”

import pandas as pd
from collections import defaultdict

def analyze_class_success():
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig")
        df = df[df["status"].isin(["success", "fail"])]
        df = df[df["predicted_class"] >= 0]

        result = defaultdict(lambda: {"success": 0, "fail": 0})

        for _, row in df.iterrows():
            strategy = row["strategy"]
            cls = int(row["predicted_class"])
            key = (strategy, cls)
            result[key]["success" if row["status"] == "success" else "fail"] += 1

        summary = []
        for (strategy, cls), counts in result.items():
            total = counts["success"] + counts["fail"]
            rate = counts["success"] / total if total > 0 else 0
            summary.append({
                "strategy": strategy,
                "class": cls,
                "total": total,
                "success": counts["success"],
                "fail": counts["fail"],
                "success_rate": round(rate, 4)
            })

        summary_df = pd.DataFrame(summary)
        summary_df = summary_df.sort_values(by=["strategy", "class"])
        return summary_df

    except Exception as e:
        print(f"[ì˜¤ë¥˜] í´ë˜ìŠ¤ ì„±ê³µë¥  ë¶„ì„ ì‹¤íŒ¨ â†’ {e}")
        return pd.DataFrame([])

def get_recent_predicted_classes(strategy: str, recent_days: int = 3):
    try:
        df = pd.read_csv("/persistent/prediction_log.csv")
        df = df[df["strategy"] == strategy]
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        cutoff = pd.Timestamp.now() - pd.Timedelta(days=recent_days)
        df = df[df["timestamp"] >= cutoff]
        return set(df["predicted_class"].dropna().astype(int).tolist())
    except:
        return set()

def get_fine_tune_targets(min_samples=30, max_success_rate=0.4):
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        df = df[df["status"].isin(["success", "fail"])]

        if "predicted_class" not in df.columns:
            print("[ê²½ê³ ] predicted_class ì»¬ëŸ¼ ì—†ìŒ â†’ -1ë¡œ ìƒì„± í›„ ì²˜ë¦¬")
            df["predicted_class"] = -1

        if "label" not in df.columns:
            df["label"] = df["predicted_class"]

        if "strategy" not in df.columns:
            df["strategy"] = "ì•Œìˆ˜ì—†ìŒ"

        df = df[df["predicted_class"].notna()]
        df["predicted_class"] = pd.to_numeric(df["predicted_class"], errors="coerce").fillna(-1).astype(int)
        df["label"] = pd.to_numeric(df["label"], errors="coerce").fillna(-1).astype(int)

        result = defaultdict(lambda: {"success": 0, "fail": 0})
        for _, row in df.iterrows():
            strategy = row["strategy"]
            cls = int(row["predicted_class"])
            key = (strategy, cls)
            result[key]["success" if row["status"] == "success" else "fail"] += 1

        fine_tune_targets = []
        for (strategy, cls), counts in result.items():
            total = counts["success"] + counts["fail"]
            rate = counts["success"] / total if total > 0 else 0
            if total < min_samples or rate < max_success_rate:
                fine_tune_targets.append({
                    "strategy": strategy,
                    "class": cls,
                    "samples": total,
                    "success_rate": round(rate, 4)
                })

        # âœ… Fallback: fine-tune ëŒ€ìƒì´ ì—†ìœ¼ë©´ ìµœê·¼ ì„±ê³µ/ì‹¤íŒ¨ ìƒê´€ì—†ì´ ìƒ˜í”Œë§í•´ì„œ ë°˜í™˜
        if not fine_tune_targets:
            print("[INFO] fine-tune ëŒ€ìƒì´ ì—†ì–´ fallback ì‹¤í–‰")
            fallback = df[["strategy", "predicted_class"]].drop_duplicates().head(min_samples)
            fallback = fallback.rename(columns={"predicted_class": "class"})
            fallback["samples"] = min_samples
            fallback["success_rate"] = 0.5
            return fallback.sort_values(by=["strategy", "class"])

        return pd.DataFrame(fine_tune_targets).sort_values(by=["strategy", "class"])

    except Exception as e:
        print(f"[ì˜¤ë¥˜] fine-tune ëŒ€ìƒ ë¶„ì„ ì‹¤íŒ¨ â†’ {e}")
        return pd.DataFrame([])



def get_feature_hash_from_tensor(tensor):
    """
    í…ì„œ ë°ì´í„°ë¥¼ ë°›ì•„ í•´ì‹œê°’ ìƒì„± (í•™ìŠµ í”¼ì²˜ ì¤‘ë³µ ë°©ì§€ìš©)
    """
    try:
        flat = tensor.detach().cpu().numpy().flatten()
        rounded = [round(float(x), 2) for x in flat]
        joined = ",".join(map(str, rounded))
        return hashlib.sha1(joined.encode()).hexdigest()
    except Exception as e:
        print(f"[ì˜¤ë¥˜] get_feature_hash_from_tensor ì‹¤íŒ¨ â†’ {e}")
        return "unknown"
        
def export_recent_model_stats(recent_days=3):
    """
    ìµœê·¼ Nì¼ê°„ ëª¨ë¸ë³„ ì„±ê³µë¥  ì§‘ê³„ â†’ CSV ì €ì¥
    """
    try:
        path = "/persistent/prediction_log.csv"
        df = pd.read_csv(path, encoding="utf-8-sig")
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")

        # ìµœê·¼ ê¸°ê°„ í•„í„°ë§
        cutoff = pd.Timestamp.now() - pd.Timedelta(days=recent_days)
        df = df[df["timestamp"] >= cutoff]
        df = df[df["status"].isin(["success", "fail"])]

        if df.empty:
            print("â— ìµœê·¼ ì˜ˆì¸¡ ë°ì´í„° ì—†ìŒ")
            return

        from collections import defaultdict
        stats = defaultdict(lambda: {"success": 0, "fail": 0})

        for _, row in df.iterrows():
            key = (row["symbol"], row["strategy"], row["model"])
            stats[key]["success" if row["status"] == "success" else "fail"] += 1

        summary = []
        for (symbol, strategy, model), count in stats.items():
            total = count["success"] + count["fail"]
            rate = count["success"] / total if total > 0 else 0
            summary.append({
                "symbol": symbol,
                "strategy": strategy,
                "model": model,
                "total": total,
                "success": count["success"],
                "fail": count["fail"],
                "recent_success_rate": round(rate, 4)
            })

        summary_df = pd.DataFrame(summary)
        save_path = "/persistent/logs/recent_model_stats.csv"
        summary_df.to_csv(save_path, index=False, encoding="utf-8-sig")
        print(f"ğŸ“ˆ ìµœê·¼ ëª¨ë¸ ì„±ëŠ¥ ì €ì¥ ì™„ë£Œ â†’ {save_path}")

    except Exception as e:
        print(f"[ì˜¤ë¥˜] ìµœê·¼ ëª¨ë¸ ì„±ëŠ¥ ì§‘ê³„ ì‹¤íŒ¨ â†’ {e}")

def log_training_result(symbol, strategy, model_name, acc, f1, loss):
    """
    ëª¨ë¸ í•™ìŠµ ê²°ê³¼ë¥¼ ë¡œê·¸ë¡œ ì €ì¥
    - ì´ì–´ í•™ìŠµ ì—¬ë¶€ê°€ ìˆëŠ” ê²½ìš° ë¡œê·¸ë¡œ ëª…í™•íˆ ë‚¨ê¹€
    """
    try:
        import os
        timestamp = now_kst().strftime("%Y-%m-%d %H:%M:%S")
        model_path = f"/persistent/models/{symbol}_{strategy}_{model_name}.pt"
        mode = "ì´ì–´í•™ìŠµ" if os.path.exists(model_path) else "ì‹ ê·œí•™ìŠµ"

        row = {
            "timestamp": timestamp,
            "symbol": symbol,
            "strategy": strategy,
            "model": model_name,
            "mode": mode,
            "accuracy": float(acc),
            "f1_score": float(f1),
            "loss": float(loss)
        }

        headers = list(row.keys())
        pd.DataFrame([row]).to_csv(TRAIN_LOG, mode="a", index=False,
                                   header=not os.path.exists(TRAIN_LOG),
                                   encoding="utf-8-sig")
    except Exception as e:
        print(f"[í•™ìŠµ ë¡œê·¸ ì €ì¥ ì˜¤ë¥˜] {e}")


def get_class_success_rate(strategy, recent_days=3):
    """
    ìµœê·¼ prediction_log.csv ê¸°ë°˜ìœ¼ë¡œ
    í´ë˜ìŠ¤ë³„ ì„±ê³µë¥ ì„ ê³„ì‚°í•´ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜
    """
    from collections import defaultdict
    import pandas as pd
    import os

    path = "/persistent/prediction_log.csv"
    if not os.path.exists(path):
        return {}

    try:
        df = pd.read_csv(path, encoding="utf-8-sig")
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        cutoff = pd.Timestamp.now() - pd.Timedelta(days=recent_days)

        df = df[(df["strategy"] == strategy) &
                (df["timestamp"] >= cutoff) &
                (df["predicted_class"] >= 0) &
                (df["status"].isin(["success", "fail"]))]

        stats = defaultdict(lambda: {"success": 0, "fail": 0})
        for _, row in df.iterrows():
            cls = int(row["predicted_class"])
            if row["status"] == "success":
                stats[cls]["success"] += 1
            else:
                stats[cls]["fail"] += 1

        result = {}
        for cls, val in stats.items():
            total = val["success"] + val["fail"]
            if total > 0:
                result[cls] = round(val["success"] / total, 4)

        return result

    except Exception as e:
        print(f"[âš ï¸ í´ë˜ìŠ¤ ì„±ê³µë¥  ê³„ì‚° ì˜¤ë¥˜] {e}")
        return {}

import os

MODEL_DIR = "/persistent/models"


def get_available_models():
    import os, json, glob
    MODEL_DIR = "/persistent/models"

    models = []
    pt_files = glob.glob(os.path.join(MODEL_DIR, "*.pt"))
    for pt_path in pt_files:
        meta_path = pt_path.replace(".pt", ".meta.json")
        if not os.path.exists(meta_path):
            continue
        with open(meta_path, "r", encoding="utf-8") as f:
            meta = json.load(f)
        if all(k in meta for k in ["symbol", "strategy", "model", "input_size"]):
            models.append({
                "symbol": meta["symbol"],
                "strategy": meta["strategy"],
                "model": meta["model"],
                "pt_file": os.path.basename(pt_path)
            })
    return models
