import os, csv, datetime, pandas as pd, pytz, hashlib
import sqlite3
from collections import defaultdict

# -------------------------
# ê¸°ë³¸ ê²½ë¡œ/ë””ë ‰í† ë¦¬
# -------------------------
DIR = "/persistent"
LOG_DIR = os.path.join(DIR, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# âœ… prediction_logëŠ” "ë£¨íŠ¸" ê²½ë¡œë¡œ í†µì¼
PREDICTION_LOG = f"{DIR}/prediction_log.csv"
WRONG = f"{DIR}/wrong_predictions.csv"  # (í˜¸í™˜ ëª©ì ìœ¼ë¡œ ìœ ì§€ë§Œ)
EVAL_RESULT = f"{LOG_DIR}/evaluation_result.csv"

# âœ… í•™ìŠµ ë¡œê·¸ íŒŒì¼ëª… í†µì¼
TRAIN_LOG = f"{LOG_DIR}/train_log.csv"
AUDIT_LOG = f"{LOG_DIR}/evaluation_audit.csv"

# âœ… ê³µìš© í—¤ë” (ensure_prediction_log_existsì—ì„œ ì‚¬ìš©)
PREDICTION_HEADERS = [
    "timestamp", "symbol", "strategy", "direction",
    "entry_price", "target_price",
    "model", "predicted_class", "top_k", "note",
    "success", "reason", "rate", "return_value",
    "label", "group_id", "model_symbol", "model_name",
    "source", "volatility", "source_exchange"
]

now_kst = lambda: datetime.datetime.now(pytz.timezone("Asia/Seoul"))

# -------------------------
# ìƒˆë¡œ ì¶”ê°€: ì•ˆì „í•œ ë¡œê·¸ íŒŒì¼ ë³´ì¥
# -------------------------
def ensure_prediction_log_exists():
    """
    /persistent/prediction_log.csv ê°€ ì—†ìœ¼ë©´ í—¤ë”ê¹Œì§€ ìƒì„±.
    ë””ë ‰í† ë¦¬ë„ ë³´ì¥.
    """
    try:
        os.makedirs(os.path.dirname(PREDICTION_LOG), exist_ok=True)
        if not os.path.exists(PREDICTION_LOG):
            with open(PREDICTION_LOG, "w", newline="", encoding="utf-8-sig") as f:
                csv.writer(f).writerow(PREDICTION_HEADERS)
            print("[âœ… ensure_prediction_log_exists] prediction_log.csv ìƒì„± ì™„ë£Œ")
        else:
            # í—¤ë” ëˆ„ë½ëœ ê¸°ì¡´ íŒŒì¼ ë³´ì •
            try:
                with open(PREDICTION_LOG, "r", encoding="utf-8-sig") as f:
                    first_line = f.readline()
                if "," not in first_line or any(h not in first_line for h in ["timestamp","symbol","strategy"]):
                    # ë°±ì—… í›„ í—¤ë” ì‚½ì…
                    bak = PREDICTION_LOG + ".bak"
                    os.replace(PREDICTION_LOG, bak)
                    with open(PREDICTION_LOG, "w", newline="", encoding="utf-8-sig") as f:
                        csv.writer(f).writerow(PREDICTION_HEADERS)
                    with open(bak, "r", encoding="utf-8-sig") as src, open(PREDICTION_LOG, "a", newline="", encoding="utf-8-sig") as dst:
                        dst.write(src.read())
                    print("[âœ… ensure_prediction_log_exists] ê¸°ì¡´ íŒŒì¼ í—¤ë” ë³´ì • ì™„ë£Œ")
            except Exception as e:
                print(f"[âš ï¸ ensure_prediction_log_exists] í—¤ë” í™•ì¸ ì‹¤íŒ¨: {e}")
    except Exception as e:
        print(f"[âš ï¸ ensure_prediction_log_exists] ì˜ˆì™¸: {e}")

# -------------------------
# ìƒˆë¡œ ì¶”ê°€: feature hash ìœ í‹¸(ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ ì‚¬ìš©)
# -------------------------
def get_feature_hash(feature_row) -> str:
    """
    numpy ë°°ì—´/torch í…ì„œ/ë¦¬ìŠ¤íŠ¸/ìŠ¤ì¹¼ë¼ ì§€ì›.
    ì†Œìˆ˜ì  2ìë¦¬ ë°˜ì˜¬ë¦¼ í›„ SHA1.
    """
    try:
        import numpy as _np
        if feature_row is None:
            return "none"
        if "torch" in str(type(feature_row)):
            try:
                feature_row = feature_row.detach().cpu().numpy()
            except Exception:
                feature_row = feature_row
        if isinstance(feature_row, _np.ndarray):
            arr = feature_row.flatten().astype(float)
        elif isinstance(feature_row, (list, tuple)):
            arr = _np.array(feature_row, dtype=float).flatten()
        else:
            arr = _np.array([float(feature_row)], dtype=float)
        rounded = [round(float(x), 2) for x in arr]
        joined = ",".join(map(str, rounded))
        return hashlib.sha1(joined.encode()).hexdigest()
    except Exception:
        return "hash_error"

# -------------------------
# SQLite: ëª¨ë¸ ì„±ê³µ/ì‹¤íŒ¨ ì§‘ê³„
# -------------------------
_db_conn = None
def get_db_connection():
    """lazy sqlite connection (logs/failure_patterns.db)"""
    global _db_conn
    if _db_conn is None:
        try:
            _db_conn = sqlite3.connect(os.path.join(LOG_DIR, "failure_patterns.db"), check_same_thread=False)
            print("[âœ… logger.py DB connection ìƒì„± ì™„ë£Œ]")
        except Exception as e:
            print(f"[ì˜¤ë¥˜] logger.py DB connection ìƒì„± ì‹¤íŒ¨ â†’ {e}")
            _db_conn = None
    return _db_conn

def ensure_success_db():
    """model_success í…Œì´ë¸” ë³´ì¥"""
    try:
        conn = get_db_connection()
        conn.execute("""
            CREATE TABLE IF NOT EXISTS model_success (
                symbol TEXT,
                strategy TEXT,
                model TEXT,
                success INTEGER,
                fail INTEGER,
                PRIMARY KEY(symbol, strategy, model)
            )
        """)
        conn.commit()
        print("[âœ… ensure_success_db] model_success í…Œì´ë¸” í™•ì¸ ì™„ë£Œ")
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ensure_success_db ì‹¤íŒ¨ â†’ {e}")

def update_model_success(s, t, m, success):
    """ëª¨ë¸ë³„ ì„±ê³µ/ì‹¤íŒ¨ ëˆ„ì """
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO model_success (symbol, strategy, model, success, fail)
            VALUES (?, ?, ?, ?, ?)
            ON CONFLICT(symbol, strategy, model) DO UPDATE SET
                success = success + excluded.success,
                fail = fail + excluded.fail
        """, (s, t or "ì•Œìˆ˜ì—†ìŒ", m, int(success), int(not success)))
        conn.commit()
        print(f"[âœ… update_model_success] {s}-{t}-{m} ê¸°ë¡ ({'ì„±ê³µ' if success else 'ì‹¤íŒ¨'})")
    except Exception as e:
        print(f"[ì˜¤ë¥˜] update_model_success ì‹¤íŒ¨ â†’ {e}")

def get_model_success_rate(s, t, m):
    """ì„±ê³µë¥  ì—†ìœ¼ë©´ 0.0 (ì°¸ê³ ìš©)"""
    try:
        conn = get_db_connection()
        cur = conn.cursor()
        cur.execute("""
            SELECT success, fail FROM model_success
            WHERE symbol=? AND strategy=? AND model=?
        """, (s, t or "ì•Œìˆ˜ì—†ìŒ", m))
        row = cur.fetchone()
        if row is None:
            return 0.0
        success_cnt, fail_cnt = row
        total = success_cnt + fail_cnt
        return (success_cnt / total) if total > 0 else 0.0
    except Exception as e:
        print(f"[ì˜¤ë¥˜] get_model_success_rate ì‹¤íŒ¨ â†’ {e}")
        return 0.0

# ì„œë²„ ì‹œì‘ ì‹œ í…Œì´ë¸”/ë¡œê·¸ íŒŒì¼ ë³´ì¥
ensure_success_db()
ensure_prediction_log_exists()

# -------------------------
# íŒŒì¼ ë¡œë“œ/ìœ í‹¸
# -------------------------
def load_failure_count():
    path = os.path.join(LOG_DIR, "failure_count.csv")
    if not os.path.exists(path):
        return {}
    try:
        with open(path, "r", encoding="utf-8-sig") as f:
            return {f"{r['symbol']}-{r['strategy']}": int(r["failures"]) for r in csv.DictReader(f)}
    except:
        return {}

def _normalize_status(df: pd.DataFrame) -> pd.DataFrame:
    """
    ë¡œê·¸ í˜¸í™˜:
    - ìƒˆ í¬ë§·: 'success' (True/False)
    - êµ¬ í¬ë§·: 'status' ('success'/'fail')
    ë‘˜ ë‹¤ ì§€ì›í•˜ë„ë¡ df['status']ë¥¼ ìƒì„±í•´ ë°˜í™˜.
    """
    if "status" in df.columns:
        df["status"] = (
            df["status"].astype(str).str.lower().map(lambda x: "success" if x == "success" else "fail")
        )
        return df

    if "success" in df.columns:
        s = df["success"]
        s_norm = s.map(lambda x: str(x).strip().lower() in ["true", "1", "yes", "y"])
        df["status"] = s_norm.map(lambda b: "success" if b else "fail")
        return df

    # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ë¹ˆ status ì¶”ê°€(ì§‘ê³„ ê²°ê³¼ëŠ” 0ê±´ ì²˜ë¦¬)
    df["status"] = ""
    return df

def get_actual_success_rate(strategy, min_samples: int = 1):
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        df = df[df["strategy"] == strategy]
        df = _normalize_status(df)
        df = df[df["status"].isin(["success", "fail"])]
        n = len(df)
        if n < max(1, min_samples):
            return 0.0
        return round(len(df[df["status"] == "success"]) / n, 4)
    except Exception as e:
        print(f"[ì˜¤ë¥˜] get_actual_success_rate ì‹¤íŒ¨ â†’ {e}")
        return 0.0

def get_strategy_eval_count(strategy):
    try:
        df = pd.read_csv(PREDICTION_LOG, encoding="utf-8-sig", on_bad_lines="skip")
        df = _normalize_status(df)
        return len(df[(df["strategy"] == strategy) & (df["status"].isin(["success", "fail"]))])
    except Exception as e:
        print(f"[ì˜¤ë¥˜] get_strategy_eval_count ì‹¤íŒ¨ â†’ {e}")
        return 0

def log_audit_prediction(s, t, status, reason):
    row = {
        "timestamp": now_kst().isoformat(),
        "symbol": str(s or "UNKNOWN"),
        "strategy": str(t or "ì•Œìˆ˜ì—†ìŒ"),
        "status": str(status),
        "reason": str(reason)
    }
    try:
        with open(AUDIT_LOG, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.DictWriter(f, fieldnames=row.keys())
            if f.tell() == 0:
                w.writeheader()
            w.writerow(row)
    except:
        pass

# -------------------------
# ì˜ˆì¸¡ ë¡œê·¸ ê¸°ë¡
# -------------------------
def log_prediction(
    symbol, strategy, direction=None, entry_price=0, target_price=0,
    timestamp=None, model=None, predicted_class=None, top_k=None,
    note="", success=False, reason="", rate=None, return_value=None,
    label=None, group_id=None, model_symbol=None, model_name=None,
    source="ì¼ë°˜", volatility=False, feature_vector=None,
    source_exchange="BYBIT"
):
    """
    ì˜ˆì¸¡ ë¡œê·¸ ê¸°ë¡ í•¨ìˆ˜ (í‘œì¤€ ê²½ë¡œ/í—¤ë” ì‚¬ìš©)
    source_exchange: BYBIT / BINANCE / MIXED
    """
    from datetime import datetime as _dt
    from failure_db import insert_failure_record  # ì™¸ë¶€ ëª¨ë“ˆ ì˜ì¡´

    LOG_FILE = PREDICTION_LOG  # âœ… ë£¨íŠ¸ ê²½ë¡œë¡œ í†µì¼
    os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)

    now = _dt.now(pytz.timezone("Asia/Seoul")).isoformat() if timestamp is None else timestamp
    top_k_str = ",".join(map(str, top_k)) if top_k else ""

    predicted_class = predicted_class if predicted_class is not None else -1
    label = label if label is not None else -1
    reason = reason or "ì‚¬ìœ ì—†ìŒ"
    rate = 0.0 if rate is None else float(rate)
    return_value = 0.0 if return_value is None else float(return_value)
    entry_price = entry_price or 0.0
    target_price = target_price or 0.0

    allowed_sources = ["ì¼ë°˜", "meta", "evo_meta", "baseline_meta", "ì§„í™”í˜•", "í‰ê°€", "ë‹¨ì¼", "ë³€ë™ì„±", "train_loop"]
    if source not in allowed_sources:
        source = "ì¼ë°˜"

    row = [
        now, symbol, strategy, direction, entry_price, target_price,
        (model or ""), predicted_class, top_k_str, note,
        str(success), reason, rate, return_value, label,
        group_id, model_symbol, model_name, source, volatility, source_exchange
    ]

    try:
        write_header = not os.path.exists(LOG_FILE) or os.path.getsize(LOG_FILE) == 0
        with open(LOG_FILE, "a", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            if write_header:
                writer.writerow(PREDICTION_HEADERS)
            writer.writerow(row)

        print(f"[âœ… ì˜ˆì¸¡ ë¡œê·¸ ê¸°ë¡ë¨] {symbol}-{strategy} class={predicted_class} | success={success} | src={source_exchange} | reason={reason}")

        # ì‹¤íŒ¨ ì¼€ì´ìŠ¤ëŠ” ì‹¤íŒ¨ DBì—ë„ ê¸°ë¡(ì¤‘ë³µ ì²´í¬ëŠ” failure_dbì—ì„œ)
        if not success:
            feature_hash = f"{symbol}-{strategy}-{model or ''}-{predicted_class}-{label}-{rate}"
            safe_vector = []
            try:
                import numpy as _np
                if feature_vector is not None:
                    if isinstance(feature_vector, _np.ndarray):
                        safe_vector = feature_vector.flatten().tolist()
                    elif isinstance(feature_vector, list):
                        safe_vector = feature_vector
            except:
                safe_vector = []

            insert_failure_record(
                {
                    "symbol": symbol, "strategy": strategy, "direction": direction,
                    "model": model or "", "predicted_class": predicted_class,
                    "rate": rate, "reason": reason, "label": label, "source": source,
                    "entry_price": entry_price, "target_price": target_price,
                    "return_value": return_value
                },
                feature_hash=feature_hash, label=label, feature_vector=safe_vector
            )

    except Exception as e:
        print(f"[âš ï¸ ì˜ˆì¸¡ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨] {e}")

# -------------------------
# log_training_result ì¶”ê°€
# -------------------------
def log_training_result(
    symbol,
    strategy,
    model="",
    accuracy=0.0,
    f1=0.0,
    loss=0.0,
    note="",
    source_exchange="BYBIT",
    status="success",
):
    """
    í•™ìŠµ ê²°ê³¼ ë¡œê·¸ë¥¼ CSVë¡œ ê¸°ë¡í•˜ê³ , ì„±ê³µ/ì‹¤íŒ¨ ëˆ„ì (DB)ë„ ê°±ì‹ í•©ë‹ˆë‹¤.
    CSV í—¤ë”: timestamp,symbol,strategy,model,accuracy,f1,loss,note,source_exchange,status
    """
    LOG_FILE = TRAIN_LOG
    os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)
    now = datetime.datetime.now(pytz.timezone("Asia/Seoul")).isoformat()
    row = [
        now, str(symbol), str(strategy), str(model or ""),
        float(accuracy) if accuracy is not None else 0.0,
        float(f1) if f1 is not None else 0.0,
        float(loss) if loss is not None else 0.0,
        str(note or ""), str(source_exchange or "BYBIT"),
        str(status or "success")
    ]
    try:
        write_header = not os.path.exists(LOG_FILE)
        with open(LOG_FILE, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.writer(f)
            if write_header:
                w.writerow(["timestamp","symbol","strategy","model","accuracy","f1","loss","note","source_exchange","status"])
            w.writerow(row)
        print(f"[âœ… í•™ìŠµ ë¡œê·¸ ê¸°ë¡] {symbol}-{strategy} {model} status={status}")
    except Exception as e:
        print(f"[âš ï¸ í•™ìŠµ ë¡œê·¸ ê¸°ë¡ ì‹¤íŒ¨] {e}")
    try:
        ensure_success_db()
        update_model_success(symbol, strategy, model or "", str(status).lower() == "success")
    except Exception as e:
        print(f"[âš ï¸ model_success ì§‘ê³„ ì‹¤íŒ¨] {e}")

# === [ì¶”ê°€] ìˆ˜ìµë¥  í´ë˜ìŠ¤ ê²½ê³„ ë¡œê·¸ ===
def log_class_ranges(symbol, strategy, class_ranges, group_id=None, source="train"):
    """
    /persistent/logs/class_ranges.csv ì— ê¸°ë¡
    ì»¬ëŸ¼: timestamp,symbol,strategy,group_id,idx,low,high,source
    """
    import csv, datetime, pytz, os
    path = os.path.join(LOG_DIR, "class_ranges.csv")
    os.makedirs(os.path.dirname(path), exist_ok=True)
    now = datetime.datetime.now(pytz.timezone("Asia/Seoul")).isoformat()

    write_header = not os.path.exists(path)
    try:
        with open(path, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.writer(f)
            if write_header:
                w.writerow(["timestamp","symbol","strategy","group_id","idx","low","high","source"])
            for i, rng in enumerate(class_ranges):
                lo, hi = (float(rng[0]), float(rng[1])) if isinstance(rng, (list, tuple)) and len(rng) == 2 else (None, None)
                w.writerow([now, symbol, strategy, int(group_id) if group_id is not None else 0, i, lo, hi, source])
        print(f"[ğŸ“ í´ë˜ìŠ¤ê²½ê³„ ë¡œê·¸] {symbol}-{strategy}-g{group_id} â†’ {len(class_ranges)}ê°œ ê¸°ë¡")
    except Exception as e:
        print(f"[âš ï¸ í´ë˜ìŠ¤ê²½ê³„ ë¡œê·¸ ì‹¤íŒ¨] {e}")


# === [ì¶”ê°€] ë¼ë²¨(í‘œë³¸) ë¶„í¬ ë¡œê·¸ ===
def log_label_distribution(symbol, strategy, labels, group_id=None, note=""):
    """
    /persistent/logs/label_distribution.csv ì— ê¸°ë¡
    ì»¬ëŸ¼: timestamp,symbol,strategy,group_id,total,counts_json,n_unique,entropy,note
    """
    import csv, json, math, datetime, pytz, os
    from collections import Counter

    path = os.path.join(LOG_DIR, "label_distribution.csv")
    os.makedirs(os.path.dirname(path), exist_ok=True)
    now = datetime.datetime.now(pytz.timezone("Asia/Seoul")).isoformat()

    # ì•ˆì „ ë³€í™˜
    try:
        labels_list = list(map(int, list(labels)))
    except Exception:
        labels_list = []

    cnt = Counter(labels_list)
    total = sum(cnt.values())
    if total > 0:
        probs = [c/total for c in cnt.values()]
        entropy = -sum(p*math.log(p + 1e-12) for p in probs)
    else:
        entropy = 0.0

    row = [
        now, str(symbol), str(strategy),
        int(group_id) if group_id is not None else 0,
        int(total),
        json.dumps({int(k): int(v) for k, v in sorted(cnt.items())}, ensure_ascii=False),
        int(len(cnt)),
        float(round(entropy, 6)),
        str(note or "")
    ]

    write_header = not os.path.exists(path)
    try:
        with open(path, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.writer(f)
            if write_header:
                w.writerow(["timestamp","symbol","strategy","group_id","total","counts_json","n_unique","entropy","note"])
            w.writerow(row)
        print(f"[ğŸ“Š ë¼ë²¨ë¶„í¬ ë¡œê·¸] {symbol}-{strategy}-g{group_id} â†’ total={total}, classes={len(cnt)}, H={round(entropy,4)}")
    except Exception as e:
        print(f"[âš ï¸ ë¼ë²¨ë¶„í¬ ë¡œê·¸ ì‹¤íŒ¨] {e}")
