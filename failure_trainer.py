# === failure_trainer.py (v2025-10-26 ì•ˆì •ì™„ì„±: TZ-safe cooldown, robust backup/restore, shadow weighting, safer metrics, self-contained loader) ===
import os, csv, json, glob, shutil, time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import pandas as pd
import pytz

# ì™¸ë¶€ ì˜ì¡´
from train import train_one_model
from config import get_class_ranges, get_class_groups
import logger  # ì•ˆì „ ë¡œê·¸ìš©

# â”€â”€ ê³µí†µ ê²½ë¡œ/íƒ€ì„ì¡´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
KST = pytz.timezone("Asia/Seoul")
PERSIST_DIR = "/persistent"
LOG_DIR  = os.path.join(PERSIST_DIR, "logs")
LOCK_DIR = os.path.join(PERSIST_DIR, "locks")
os.makedirs(LOG_DIR, exist_ok=True)
os.makedirs(LOCK_DIR, exist_ok=True)

STATE_JSON  = os.path.join(LOG_DIR, "failure_learn_state.json")        # ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê° ì €ì¥
SUMMARY_CSV = os.path.join(LOG_DIR, "failure_retrain_summary.csv")     # ì¬í•™ìŠµ ìš”ì•½ ë¡œê·¸
BACKUP_DIR  = os.path.join(PERSIST_DIR, "tmp", "failure_retrain_backups")
os.makedirs(BACKUP_DIR, exist_ok=True)
LOCK_PATH   = os.getenv("SAFE_LOCK_PATH", os.path.join(LOCK_DIR, "train_or_predict.lock"))

# ì‹¤íŒ¨ ë¡œê·¸ ì†ŒìŠ¤(ë¡œë”ê°€ ì½ëŠ” í‘œì¤€ + íˆìŠ¤í† ë¦¬)
WRONG_CSV_ROOT = os.path.join(PERSIST_DIR, "wrong_predictions.csv")

# â”€â”€ í™˜ê²½ íŒŒë¼ë¯¸í„° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
COOLDOWN_MIN         = int(os.getenv("FAIL_RETRAIN_COOLDOWN_MIN", "20"))
MINI_EPOCHS          = max(1, min(3, int(os.getenv("FAIL_MINI_EPOCHS", "2"))))   # 1~3
ROLLBACK_ENABLE      = os.getenv("ROLLBACK_ON_DEGRADE", "1") == "1"
ROLLBACK_TOLERANCE   = float(os.getenv("ROLLBACK_TOLERANCE", "0.01"))            # ì„±ëŠ¥ì•…í™” í—ˆìš©ì˜¤ì°¨
MAX_TARGETS          = int(os.getenv("FAIL_MAX_TARGETS", "8"))
LOOKBACK_DAYS        = int(os.getenv("FAIL_LOOKBACK_DAYS", "7"))
CSV_CHUNKSIZE        = int(os.getenv("FAIL_LEARN_CHUNKSIZE", "50000"))

# ì„€ë„ìš° ì‹¤íŒ¨ ê°€ì¤‘ì¹˜(ìµœê·¼/ì„€ë„ìš° ìš°ì„ ìˆœìœ„ ê°•í™”)
W_RECENT_DAY         = float(os.getenv("FAIL_WEIGHT_RECENT", "1.5"))
W_VERY_RECENT_DAY    = float(os.getenv("FAIL_WEIGHT_VERY_RECENT", "2.0"))
W_SHADOW_FAIL        = float(os.getenv("FAIL_WEIGHT_SHADOW", "1.3"))   # ì„€ë„ìš° ì‹¤íŒ¨ ë³´ì • ê°€ì¤‘
W_NORMAL_FAIL        = float(os.getenv("FAIL_WEIGHT_NORMAL", "1.0"))

# â”€â”€ ëª¨ë¸/ì•„í‹°íŒ©íŠ¸ ìœ„ì¹˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_DIR   = "/persistent/models"
KNOWN_EXTS  = (".ptz", ".pt", ".safetensors")
MODEL_TYPES = ("lstm", "cnn_lstm", "transformer")

# â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _now_kst() -> datetime:
    return datetime.now(KST)

def _now_str() -> str:
    return _now_kst().strftime("%Y-%m-%d %H:%M:%S")

def _load_state():
    try:
        if os.path.exists(STATE_JSON):
            with open(STATE_JSON, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {"last_run_ts": None}

def _save_state(state: dict):
    try:
        os.makedirs(os.path.dirname(STATE_JSON), exist_ok=True)
        with open(STATE_JSON, "w", encoding="utf-8") as f:
            json.dump(state, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def _append_summary_row(row: dict):
    write_header = not os.path.exists(SUMMARY_CSV)
    try:
        # ê³ ì • í—¤ë” + ì¶”ê°€ í•„ë“œ ë³´ì¡´
        base_fields = ["timestamp","symbol","strategy","score","group_id",
                       "before_f1","after_f1","delta","result","backup_dir"]
        for k in row.keys():
            if k not in base_fields:
                base_fields.append(k)
        with open(SUMMARY_CSV, "a", newline="", encoding="utf-8-sig") as f:
            w = csv.DictWriter(f, fieldnames=base_fields)
            if write_header: w.writeheader()
            w.writerow({k: row.get(k,"") for k in base_fields})
    except Exception:
        pass

# â”€â”€ ì‹¤íŒ¨ ë¡œê·¸ ë¡œë”(ìê¸‰ìì¡±: wrong_predictions.csv + logs/wrong_*.csv) â”€â”€
def _iter_recent_rows_from_csv(path: str, cutoff_kst: datetime, chunksize: int = CSV_CHUNKSIZE):
    # ì‹¤íŒ¨í–‰ ì„ ë³„ì— í•„ìš”í•œ ìµœì†Œ ì»¬ëŸ¼
    cols = ["timestamp", "symbol", "strategy", "status", "success", "note"]
    try:
        for chunk in pd.read_csv(
            path,
            usecols=lambda c: c in cols,
            encoding="utf-8-sig",
            chunksize=int(chunksize),
            on_bad_lines="skip",
        ):
            if chunk.empty:
                continue
            # timestamp â†’ KST aware ì‹œë¦¬ì¦ˆë¡œ ë³€í™˜
            ts = pd.to_datetime(chunk["timestamp"], errors="coerce", utc=True)
            if ts.notna().any():
                ts = ts.dt.tz_convert("Asia/Seoul")
            else:
                ts = pd.to_datetime(chunk["timestamp"], errors="coerce")
                try:
                    ts = ts.dt.tz_localize("Asia/Seoul")
                except Exception:
                    pass
            mask = ts >= cutoff_kst
            if not mask.any():
                continue
            sub = chunk.loc[mask].copy()
            sub["__ts"] = ts[mask]
            yield sub
    except Exception:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í†µìœ¼ë¡œë¼ë„ ì½ê¸°
        try:
            df = pd.read_csv(path, encoding="utf-8-sig", on_bad_lines="skip")
            if df.empty:
                return
            df["__ts"] = pd.to_datetime(df.get("timestamp"), errors="coerce")
            yield df
        except Exception:
            return

def _load_recent_failures(days: int = LOOKBACK_DAYS) -> pd.DataFrame:
    cutoff = _now_kst() - timedelta(days=int(days))
    parts: List[pd.DataFrame] = []

    if os.path.exists(WRONG_CSV_ROOT):
        for sub in _iter_recent_rows_from_csv(WRONG_CSV_ROOT, cutoff):
            parts.append(sub)

    for path in glob.glob(os.path.join(LOG_DIR, "wrong_*.csv")):
        for sub in _iter_recent_rows_from_csv(path, cutoff):
            parts.append(sub)

    if not parts:
        return pd.DataFrame(columns=["timestamp","symbol","strategy","status","success","note","__ts"])

    cols_union = ["timestamp","symbol","strategy","status","success","note","__ts"]
    df = pd.concat([p[[c for c in cols_union if c in p.columns]] for p in parts], ignore_index=True)
    keep_cols = [c for c in ["__ts","symbol","strategy","status","success","note"] if c in df.columns]
    try:
        df = df.drop_duplicates(subset=keep_cols)
    except Exception:
        df = df.drop_duplicates()
    return df

def _coerce_bool_like(v: Any) -> Optional[bool]:
    s = str(v).strip().lower()
    if s in ("true","1","yes","y"):
        return True
    if s in ("false","0","no","n"):
        return False
    return None

# â”€â”€ ëª¨ë¸/ë©”íƒ€ íƒìƒ‰ & ë°±ì—…/ë³µêµ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _stem_without_ext(p: str) -> str:
    base = p
    for e in KNOWN_EXTS:
        if base.endswith(e):
            return base[:-len(e)]
    return os.path.splitext(base)[0]

def _rel_under_model_dir(path: str) -> str:
    absp = os.path.abspath(path)
    absroot = os.path.abspath(MODEL_DIR)
    if absp.startswith(absroot):
        return os.path.relpath(absp, absroot)
    return os.path.basename(path)

def _find_group_artifacts(symbol: str, strategy: str, group_id: int):
    """
    í•´ë‹¹ ì‹¬ë³¼/ì „ëµ/ê·¸ë£¹ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ì™€ .meta.json ê²½ë¡œ ìˆ˜ì§‘.
    """
    items = []
    patt = os.path.join(MODEL_DIR, f"{symbol}_{strategy}_*_group{int(group_id)}_cls*")
    cands = []
    for e in KNOWN_EXTS:
        cands.extend(glob.glob(patt + e))
    # ë””ë ‰í† ë¦¬ë³„ ë³„ì¹­ ê²½ë¡œë„ íƒìƒ‰
    for mtype in MODEL_TYPES:
        for e in KNOWN_EXTS:
            p = os.path.join(MODEL_DIR, symbol, strategy, f"{mtype}{e}")
            if os.path.exists(p):
                cands.append(p)

    seen = set()
    for wpath in cands:
        stem = _stem_without_ext(os.path.basename(wpath))
        if stem in seen:
            continue
        seen.add(stem)

        meta1 = os.path.join(MODEL_DIR, f"{stem}.meta.json")
        meta2 = None
        try:
            parts = stem.split("_")
            if len(parts) >= 3:
                mtype = parts[2]
                meta2 = os.path.join(MODEL_DIR, symbol, strategy, f"{mtype}.meta.json")
        except Exception:
            pass

        meta_path = meta1 if os.path.exists(meta1) else (meta2 if (meta2 and os.path.exists(meta2)) else None)
        items.append({"weight": wpath, "meta": meta_path})
    return items

def _read_meta_f1(meta_path: str):
    """ì—¬ëŸ¬ í‚¤ í›„ë³´ì—ì„œ val_f1 íƒìƒ‰."""
    try:
        if not meta_path or not os.path.exists(meta_path):
            return None
        with open(meta_path, "r", encoding="utf-8") as f:
            m = json.load(f)
        for k in [
            ("metrics","val_f1"),
            ("metrics","best_val_f1"),
            ("val","f1"),
            ("f1",),
        ]:
            cur = m
            try:
                for kk in k:
                    cur = cur[kk]
                if cur is not None:
                    return float(cur)
            except Exception:
                continue
        return None
    except Exception:
        return None

def _backup_group(symbol: str, strategy: str, group_id: int):
    """
    ëª¨ë¸/ë©”íƒ€ë¥¼ MODEL_DIR ê¸°ì¤€ ìƒëŒ€ê²½ë¡œë¡œ ë°±ì—…(manifest í¬í•¨) â†’ ì›ìœ„ì¹˜ ë³µêµ¬ ê°€ëŠ¥
    """
    try:
        ts = _now_kst().strftime("%Y%m%d_%H%M%S")
        dst = os.path.join(BACKUP_DIR, f"{symbol}_{strategy}_g{group_id}_{ts}")
        os.makedirs(dst, exist_ok=True)
        copied = 0
        manifest = []
        for it in _find_group_artifacts(symbol, strategy, group_id):
            for p in [it.get("weight"), it.get("meta")]:
                if p and os.path.exists(p):
                    rel = _rel_under_model_dir(p)
                    out = os.path.join(dst, rel)
                    os.makedirs(os.path.dirname(out), exist_ok=True)
                    shutil.copy2(p, out)
                    manifest.append({"rel": rel})
                    copied += 1
        with open(os.path.join(dst, "manifest.json"), "w", encoding="utf-8") as f:
            json.dump({"items": manifest}, f, ensure_ascii=False, indent=2)
        return dst if copied > 0 else None
    except Exception as e:
        print(f"[ë°±ì—… ì‹¤íŒ¨] {symbol}-{strategy}-g{group_id} â†’ {e}")
        return None

def _restore_from_backup(backup_dir: str) -> bool:
    """
    manifest.jsonì„ ì‚¬ìš©í•˜ì—¬ MODEL_DIR ê¸°ì¤€ ì›ìœ„ì¹˜ ë³µêµ¬.
    manifest ì—†ìœ¼ë©´ í´ë” ì „ì²´ í‰ë©´ ë³µêµ¬(í•˜ìœ„ í˜¸í™˜).
    """
    try:
        if not backup_dir or not os.path.isdir(backup_dir):
            return False
        manifest_path = os.path.join(backup_dir, "manifest.json")
        rels: List[str] = []
        if os.path.exists(manifest_path):
            with open(manifest_path, "r", encoding="utf-8") as f:
                doc = json.load(f)
                rels = [it.get("rel") for it in doc.get("items", []) if it and it.get("rel")]
        else:
            for root, _, files in os.walk(backup_dir):
                for fn in files:
                    if fn == "manifest.json":
                        continue
                    rels.append(os.path.relpath(os.path.join(root, fn), backup_dir))

        ok = True
        for rel in rels:
            src = os.path.join(backup_dir, rel)
            dst = os.path.join(MODEL_DIR, rel)
            os.makedirs(os.path.dirname(dst), exist_ok=True)
            try:
                shutil.copy2(src, dst)
            except Exception as e:
                ok = False
                print(f"[ë³µêµ¬ ì‹¤íŒ¨] {src} â†’ {dst} : {e}")
        return ok
    except Exception as e:
        print(f"[ë³µêµ¬ ì‹¤íŒ¨] {backup_dir} â†’ {e}")
        return False

def _best_f1_for_group(symbol: str, strategy: str, group_id: int):
    f1s = []
    for it in _find_group_artifacts(symbol, strategy, group_id):
        f1 = _read_meta_f1(it.get("meta"))
        if f1 is not None:
            f1s.append(float(f1))
    return max(f1s) if f1s else None

# â”€â”€ íƒ€ê¹ƒ ìŠ¤ì½”ì–´ë§(ì„€ë„ìš° ì‹¤íŒ¨ ê°€ì¤‘ í¬í•¨) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _score_targets(df: pd.DataFrame, lookback_days=LOOKBACK_DAYS, max_targets=MAX_TARGETS):
    """
    ì‹¤íŒ¨ í–‰ë“¤ì„ (symbol, strategy)ë¡œ ë¬¶ê³  ì ìˆ˜í™”í•´ ìƒìœ„ Nê°œë§Œ ë°˜í™˜.
    - ê¸°ë³¸ ê°€ì¤‘ì¹˜: 1.0
    - ìµœê·¼(lookback) ë²”ìœ„ë©´ W_RECENT_DAY, 1ì¼ ì´ë‚´ë©´ W_VERY_RECENT_DAY
    - ì„€ë„ìš° ì‹¤íŒ¨(status/noteì— 'shadow' ë˜ëŠ” 'v_fail' í¬í•¨, í˜¹ì€ is_shadow í”Œë˜ê·¸)ë©´ W_SHADOW_FAIL ê³±
    ë°˜í™˜: [(symbol, strategy, score), ...]
    """
    if df is None or df.empty:
        return []

    ts_col = "__ts" if "__ts" in df.columns else "timestamp"
    now = _now_kst()
    since = now - timedelta(days=int(lookback_days))

    dff = df.copy()

    # ì‹¤íŒ¨í–‰ ì„ ë³„: status ìš°ì„ , ì—†ìœ¼ë©´ success=Falseë¥˜
    if "status" in dff.columns:
        status_l = dff["status"].astype(str).str.lower()
        dff = dff[status_l.isin(["fail", "v_fail", "shadow_fail"])]
    elif "success" in dff.columns:
        succ = dff["success"].apply(_coerce_bool_like)
        dff = dff[succ == False]  # noqa: E712

    if dff.empty:
        return []

    # ê¸°ë³¸ ê°€ì¤‘
    dff["w"] = W_NORMAL_FAIL

    # ì„€ë„ìš° ê°€ì¤‘
    try:
        status = dff.get("status")
        note = dff.get("note")
        flags = (status.astype(str).str.lower() if status is not None else "") \
                + " " + (note.astype(str).str.lower() if note is not None else "")
        shadow_mask = flags.str.contains("shadow", na=False) | (status.astype(str).str.lower().isin(["v_fail","shadow_fail"]) if status is not None else False)
        dff.loc[shadow_mask, "w"] = dff.loc[shadow_mask, "w"] * W_SHADOW_FAIL
    except Exception:
        pass

    # ì‹œì  ê°€ì¤‘
    try:
        if ts_col not in dff.columns:
            dff[ts_col] = pd.to_datetime(dff["timestamp"], errors="coerce", utc=True).dt.tz_convert("Asia/Seoul")
        recent_mask = dff[ts_col].notna() & (dff[ts_col] >= since)
        dff.loc[recent_mask, "w"] = dff.loc[recent_mask, "w"] * W_RECENT_DAY
        very_recent = dff[ts_col].notna() & (dff[ts_col] >= now - timedelta(days=1))
        dff.loc[very_recent, "w"] = dff.loc[very_recent, "w"] * W_VERY_RECENT_DAY
    except Exception:
        pass

    cols = [c for c in ["symbol","strategy","w"] if c in dff.columns]
    if len(cols) < 3:
        return []
    g = dff.groupby(["symbol","strategy"], dropna=False)["w"].sum().reset_index(name="score")
    g = g.sort_values("score", ascending=False)

    out = []
    for _, r in g.head(int(max_targets)).iterrows():
        s = str(r["symbol"]); t = str(r["strategy"])
        if s and t:
            out.append((s, t, float(r["score"])))
    return out

# â”€â”€ ëŸ°íƒ€ì„ ë½(ë™ì‹œ ì‹¤í–‰ ì¶©ëŒ ë°©ì§€) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _touch_lock():
    try:
        with open(LOCK_PATH, "w", encoding="utf-8") as f:
            f.write(_now_str())
    except Exception:
        pass

def _release_lock():
    try:
        if os.path.exists(LOCK_PATH):
            os.remove(LOCK_PATH)
    except Exception:
        pass

# â”€â”€ ë©”ì¸ ë£¨í‹´ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_failure_training():
    """
    âœ… ì‹¤íŒ¨ìƒ˜í”Œ ê¸°ë°˜ 'ì´ì–´í•™ìŠµ'(ë¯¸ë‹ˆì—í­) + ì„±ëŠ¥ì•…í™” ì‹œ ë¡¤ë°±.
    - ì„€ë„ìš° ì‹¤íŒ¨ë¥¼ ì ìˆ˜ì— í¬í•¨(ê°€ì¤‘)í•´ ìš°ì„ ìˆœìœ„ ë°˜ì˜.
    - ê³¼ë„ ì‹¤í–‰ ë°©ì§€: ë§ˆì§€ë§‰ ì‹¤í–‰ í›„ COOLDOWN_MIN ë¶„ ì´ë‚´ë©´ ìŠ¤í‚µ.
    - ëŸ°íƒ€ì„ ë½ìœ¼ë¡œ train/predict ì¶©ëŒ ë°©ì§€.
    - ìš”ì•½ì€ /persistent/logs/failure_retrain_summary.csv ì— ì ì¬.
    """
    # ì¿¨ë‹¤ìš´ ì²´í¬ (TZ-aware ì•ˆì „ ë¹„êµ)
    state = _load_state()
    last_ts = state.get("last_run_ts")
    if last_ts:
        try:
            last_dt = datetime.fromisoformat(last_ts)
            if last_dt.tzinfo is None:
                last_dt = KST.localize(last_dt)
            if _now_kst() - last_dt < timedelta(minutes=COOLDOWN_MIN):
                print(f"â³ ì‹¤íŒ¨í•™ìŠµ ì¿¨ë‹¤ìš´ ì¤‘({COOLDOWN_MIN}ë¶„). ì´ë²ˆ í„´ì€ ìŠ¤í‚µ.")
                return
        except Exception:
            pass

    # ì‹¤íŒ¨ ë°ì´í„° ë¡œë“œ(ìì²´ ë¡œë”)
    df_fail = _load_recent_failures(days=LOOKBACK_DAYS)
    if df_fail.empty:
        print("âœ… ì‹¤íŒ¨ ìƒ˜í”Œ ì—†ìŒ â†’ ì‹¤íŒ¨í•™ìŠµ ìƒëµ")
        _save_state({"last_run_ts": _now_kst().isoformat()})
        return

    targets = _score_targets(df_fail, lookback_days=LOOKBACK_DAYS, max_targets=MAX_TARGETS)
    if not targets:
        print("âœ… íƒ€ê¹ƒ ì—†ìŒ(ìŠ¤ì½”ì–´ 0) â†’ ì‹¤íŒ¨í•™ìŠµ ìƒëµ")
        _save_state({"last_run_ts": _now_kst().isoformat()})
        return

    print(f"ğŸš¨ ì‹¤íŒ¨í•™ìŠµ ëŒ€ìƒ {len(targets)}ê°œ:", targets)

    # ì „ì—­ ë½
    if os.path.exists(LOCK_PATH):
        print("ğŸ”’ ì „ì—­ ë½ ê°ì§€ â†’ ì•ˆì „ìƒ ì´ë²ˆ í„´ ìŠ¤í‚µ")
        _save_state({"last_run_ts": _now_kst().isoformat()})
        return

    _touch_lock()
    try:
        for symbol, strategy, score in targets:
            print(f"\nğŸš¨ ì‹¤íŒ¨ í•™ìŠµ ì‹œì‘: {symbol}-{strategy} (score={score:.2f})")
            try:
                class_ranges = get_class_ranges(symbol=symbol, strategy=strategy)
                if not class_ranges or len(class_ranges) < 2:
                    logger.log_training_result(symbol, strategy, model="failure_retrain",
                                               note="ê²½ê³„<2 â†’ ìŠ¤í‚µ", status="skipped")
                    print(f"â­ï¸ ê²½ê³„<2 â†’ ìŠ¤í‚µ: {symbol}-{strategy}")
                    _append_summary_row({
                        "timestamp": _now_str(), "symbol": symbol, "strategy": strategy,
                        "score": float(score), "group_id": -1,
                        "before_f1": "", "after_f1": "", "delta": "", "result": "skip_bounds", "backup_dir": ""
                    })
                    continue

                groups = get_class_groups(num_classes=len(class_ranges))
                max_gid = len(groups) - 1

                for gid in range(max_gid + 1):
                    # â”€â”€ ë°±ì—… & ê¸°ì¤€ ì„±ëŠ¥
                    backup_dir = _backup_group(symbol, strategy, gid)
                    before_f1  = _best_f1_for_group(symbol, strategy, gid)
                    print(f"[INFO] g{gid} ì´ì „ ìµœê³  F1 = {before_f1}")

                    # â”€â”€ ë¯¸ë‹ˆì—í­ ì¬í•™ìŠµ
                    try:
                        train_one_model(symbol, strategy, group_id=gid, max_epochs=MINI_EPOCHS)
                    except Exception as ge:
                        logger.log_training_result(symbol, strategy, model=f"failure_retrain_g{gid}",
                                                   note=f"ì˜ˆì™¸:{ge}", status="failed")
                        print(f"[âŒ ê·¸ë£¹ ì¬í•™ìŠµ ì‹¤íŒ¨] {symbol}-{strategy}-g{gid} â†’ {ge}")
                        _append_summary_row({
                            "timestamp": _now_str(), "symbol": symbol, "strategy": strategy,
                            "score": float(score), "group_id": gid, "before_f1": before_f1,
                            "after_f1": "", "delta": "", "result": "train_error", "backup_dir": backup_dir or ""
                        })
                        continue

                    # íŒŒì¼ ì“°ê¸°/ë§í¬ ì§€ì—° ëŒ€ë¹„ ì ê¹ ëŒ€ê¸°
                    time.sleep(0.5)

                    # â”€â”€ ì„±ëŠ¥ ë¹„êµ/ë¡œê·¸/ë¡¤ë°±
                    after_f1 = _best_f1_for_group(symbol, strategy, gid)
                    delta = None if (before_f1 is None or after_f1 is None) else float(after_f1 - before_f1)
                    result = "kept"

                    if ROLLBACK_ENABLE and before_f1 is not None and after_f1 is not None:
                        if delta < -ROLLBACK_TOLERANCE:
                            ok = _restore_from_backup(backup_dir)
                            result = "rollback" if ok else "rollback_failed"
                            note = f"ë¯¸ë‹ˆì—í­ í›„ ì•…í™”(delta={delta:.4f} < -tol={ROLLBACK_TOLERANCE}) â†’ ë¡¤ë°±"
                            logger.log_training_result(symbol, strategy, model=f"failure_retrain_g{gid}",
                                                       note=note, status=("rolled_back" if ok else "failed"))
                            print(f"[ROLLBACK] g{gid}: {note} (ok={ok})")
                        else:
                            status = "improved" if (delta is not None and delta > 0) else "kept"
                            logger.log_training_result(symbol, strategy, model=f"failure_retrain_g{gid}",
                                                       note=f"ë¯¸ë‹ˆì—í­ ì™„ë£Œ delta={delta}", status=status)
                    else:
                        logger.log_training_result(symbol, strategy, model=f"failure_retrain_g{gid}",
                                                   note="ë¯¸ë‹ˆì—í­ ì™„ë£Œ(ë¹„êµ ë¶ˆê°€/ë¡¤ë°± ë¹„í™œì„±)", status="done")

                    _append_summary_row({
                        "timestamp": _now_str(),
                        "symbol": symbol,
                        "strategy": strategy,
                        "score": float(score),
                        "group_id": gid,
                        "before_f1": ("" if before_f1 is None else float(before_f1)),
                        "after_f1": ("" if after_f1 is None else float(after_f1)),
                        "delta": ("" if delta is None else float(delta)),
                        "result": result,
                        "backup_dir": backup_dir or ""
                    })

            except Exception as e:
                logger.log_training_result(symbol, strategy, model="failure_retrain",
                                           note=f"ì˜ˆì™¸:{e}", status="failed")
                print(f"[âŒ ì‹¤íŒ¨ í•™ìŠµ ì˜ˆì™¸] {symbol}-{strategy} â†’ {e}")
    finally:
        _release_lock()

    # ë§ˆì§€ë§‰ ì‹¤í–‰ ì‹œê° ì—…ë°ì´íŠ¸(ì¿¨ë‹¤ìš´ ê¸°ì¤€)
    _save_state({"last_run_ts": _now_kst().isoformat()})

# íŒŒì¼ ë§¨ ì•„ë˜ì—
def retrain_failures(limit: int | None = None,
                     lookback_days: int | None = None,
                     max_targets: int | None = None):
    # í˜¸í™˜ìš© ë˜í¼(íŒŒë¼ë¯¸í„°ëŠ” í˜„ì¬ ë‚´ë¶€ì—ì„œ ì§ì ‘ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
    return run_failure_training()

if __name__ == "__main__":
    run_failure_training()
