# ================================================
# labels.py â€” YOPO RAW ê¸°ë°˜ ìˆ˜ìµë¥  ë¼ë²¨ë§
#            (H ê³ ì • + ë™ì  ì—£ì§€ íŠœë‹ + í¬ì†Œ í´ë˜ìŠ¤ ë³‘í•© ì˜µì…˜ ë²„ì „)
# ================================================
from __future__ import annotations

import json
import logging
import os
import hashlib
from pathlib import Path
from typing import Dict, List, Tuple
import numpy as np
import pandas as pd

from config import (
    BOUNDARY_BAND,
    _strategy_horizon_hours,
    _future_extreme_signed_returns,
    get_BIN_META,
    get_CLASS_BIN,
    get_SPARSE_CLASS,  # ğŸ”¥ ì•„ì´ë””ì–´ A ì„¤ì •
    TRAIN_ZERO_BAND_ABS,  # ğŸ”¥ í•™ìŠµìš© 0% ê·¼ì²˜ ì ˆëŒ€ ìˆ˜ìµë¥  ë°´ë“œ
)


logger = logging.getLogger(__name__)

# --------------------------------------------
# ê³µí†µ ì„¤ì • (ê¸°ì¡´ ìœ ì§€)
# --------------------------------------------
_BIN_META = dict(get_BIN_META() or {})

def _as_ratio(x: float) -> float:
    try:
        xv = float(x)
    except Exception:
        return 0.0
    return xv / 100.0 if xv >= 1.0 else xv

def _as_percent(x: float) -> float:
    try:
        xv = float(x)
    except Exception:
        return 0.0
    return xv * 100.0 if 0.0 < xv < 1.0 else xv

_TARGET_BINS = int(os.getenv("TARGET_BINS", str(_BIN_META.get("TARGET_BINS", 8))))
_MIN_LABEL_CLASSES = int(os.getenv("MIN_LABEL_CLASSES", "4"))

# âœ… í•œ í´ë˜ìŠ¤ë‹¹ ìµœì†Œ íŒ¨í„´ ìˆ˜(ìƒ˜í”Œ ìˆ˜) ê¸°ì¤€
#   - ë°ì´í„°ê°€ ì¶©ë¶„í•˜ë©´ ê° í´ë˜ìŠ¤ì— ìµœì†Œ ì´ ì •ë„ëŠ” ë“¤ì–´ê°€ë„ë¡ ì—£ì§€ë¥¼ ìë¦„
_MIN_SAMPLES_PER_CLASS = int(os.getenv("MIN_SAMPLES_PER_CLASS", "50"))

# ğŸ”¥ SPARSE_CLASS(ì•„ì´ë””ì–´ A) ì„¤ì •: í¬ì†Œ í´ë˜ìŠ¤ ë³‘í•©ìš©
_SPARSE_CLASS_CONF = dict(get_SPARSE_CLASS() or {})
_SC_MIN_SAMPLES = int(_SPARSE_CLASS_CONF.get("MIN_SAMPLES_PER_CLASS", 12))
_SC_MIN_CLASSES = int(_SPARSE_CLASS_CONF.get("MIN_CLASSES_AFTER_MERGE", 8))
_SC_MAX_PASSES = int(_SPARSE_CLASS_CONF.get("MAX_MERGE_PASSES", 2))

# ğŸ”¥ í¬ì†Œ bin ë³‘í•© ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ OFF)
#   - 0 (ê¸°ë³¸): bin ë³‘í•© í•˜ì§€ ì•ŠìŒ â†’ í´ë˜ìŠ¤ ê°œìˆ˜ ê·¸ëŒ€ë¡œ ìœ ì§€
#   - 1       : ì•„ì´ë””ì–´ A ë³‘í•© ì¼¬  â†’ ì‹¤í—˜ìš©
MERGE_SPARSE_LABEL_BINS = os.getenv("MERGE_SPARSE_LABEL_BINS", "0").strip().lower() in (
    "1",
    "true",
    "yes",
    "on",
)

# ğŸ”¥ ê·¹ë‹¨ ê¼¬ë¦¬(trim) ë¹„ìœ¨ (ë¶„í¬ ì—£ì§€ ê³„ì‚°ìš©)
# - ì˜ˆ: 0.005 â†’ í•˜ìœ„ 0.5%, ìƒìœ„ 0.5% ì •ë„ë§Œ "êµ¬ê°„ ê³„ì‚°"ì—ì„œ ì ê¹ ì œì™¸
_TAIL_TRIM_FRAC = float(os.getenv("LABEL_TAIL_TRIM_FRAC", "0.005"))

# ğŸ”¥ ì „ëµë³„ H ê³ ì • (í•µì‹¬ ìˆ˜ì •)
# - ë‹¨ê¸°: 4h ìº”ë“¤ 1ê°œ
# - ì¤‘ê¸°: 1d ìº”ë“¤ 1ê°œ
# - ì¥ê¸°: ì£¼ë´‰(1w) ìº”ë“¤ 1ê°œ
_FIXED_H = {
    "ë‹¨ê¸°": 1,   # 4ì‹œê°„ë´‰ â†’ t+1ìº”ë“¤
    "ì¤‘ê¸°": 1,   # 1ì¼ë´‰ â†’ t+1ìº”ë“¤
    "ì¥ê¸°": 1,   # ì£¼ë´‰(1w) â†’ t+1ìº”ë“¤
}

_DEFAULT_STRATEGY_HOURS = {
    "ë‹¨ê¸°": 4,
    "ì¤‘ê¸°": 24,
    "ì¥ê¸°": 24 * 7,
}

def _ensure_dir_with_fallback(primary: str, fallback: str) -> Path:
    p_primary = Path(primary).resolve()
    try:
        p_primary.mkdir(parents=True, exist_ok=True)
        return p_primary
    except Exception:
        p_fallback = Path(fallback).resolve()
        p_fallback.mkdir(parents=True, exist_ok=True)
        return p_fallback

_PERSIST_BASE = os.getenv("PERSIST_DIR", "/persistent")

_EDGES_DIR = _ensure_dir_with_fallback(
    os.getenv("LABEL_EDGES_DIR", f"{_PERSIST_BASE}/label_edges"),
    "/tmp/label_edges",
)
_LABELS_DIR = _ensure_dir_with_fallback(
    os.getenv("LABEL_TABLE_DIR", f"{_PERSIST_BASE}/labels"),
    "/tmp/labels",
)

_RAW_MIN_GAIN_FOR_TRAIN = float(os.getenv("MIN_GAIN_FOR_TRAIN", "0.003"))
_MIN_GAIN_FOR_TRAIN = _as_ratio(_RAW_MIN_GAIN_FOR_TRAIN)

# ============================================================
# ì‹œê°„/ì „ëµ í—¬í¼
# ============================================================
def _to_series_ts_kst(ts_like) -> pd.Series:
    ts = pd.to_datetime(ts_like, errors="coerce")
    if getattr(ts.dt, "tz", None) is None:
        ts = ts.dt.tz_localize("Asia/Seoul")
    else:
        ts = ts.dt.tz_convert("Asia/Seoul")
    return ts

def _normalize_strategy_name(strategy: str) -> str:
    s = str(strategy).strip()
    if "ë‹¨ê¸°" in s: return "ë‹¨ê¸°"
    if "ì¤‘ê¸°" in s: return "ì¤‘ê¸°"
    if "ì¥ê¸°" in s: return "ì¥ê¸°"
    return s

# ğŸ”¥ (í•µì‹¬ìˆ˜ì •) ì „ëµë³„ Hë¥¼ ë¬´ì¡°ê±´ ê³ ì •ê°’ìœ¼ë¡œ ë°˜í™˜
def _get_fixed_horizon_candles(strategy: str) -> int:
    pure = _normalize_strategy_name(strategy)
    return int(_FIXED_H.get(pure, 1))

# ============================================================
# ë¯¸ë˜ ìˆ˜ìµë¥ (Hê°œ ìº”ë“¤ ë™ì•ˆ high/low)
# ============================================================
def _future_extreme_signed_returns_by_candles(df: pd.DataFrame, H: int):
    """
    ê° ì‹œì  iì—ì„œ,
    - ì§„ì… ê¸°ì¤€: close[i]
    - ë¯¸ë˜ êµ¬ê°„: i ì´í›„ Hê°œ ìº”ë“¤ (i+1 ~ i+H)
      â†’ í˜„ì¬ ìº”ë“¤(high/low)ì€ 'ë¯¸ë˜'ì—ì„œ ì œì™¸ (ê·¼ë³¸ ë²„ê·¸ ìˆ˜ì • í¬ì¸íŠ¸)
    """
    n = len(df)
    if n == 0:
        return np.zeros(0, dtype=np.float32), np.zeros(0, dtype=np.float32)

    close = pd.to_numeric(df["close"], errors="coerce").to_numpy(dtype=np.float32)
    high  = pd.to_numeric(df.get("high", df["close"]), errors="coerce").to_numpy(dtype=np.float32)
    low   = pd.to_numeric(df.get("low",  df["close"]), errors="coerce").to_numpy(dtype=np.float32)

    up = np.zeros(n, dtype=np.float32)
    dn = np.zeros(n, dtype=np.float32)
    H = max(1, int(H))

    for i in range(n):
        # ğŸ”¥ i ì´í›„ Hê°œ ìº”ë“¤ë§Œ ì‚¬ìš© (i+1 ~ i+H)
        start = i + 1
        end = min(n, i + 1 + H)  # íŒŒì´ì¬ ìŠ¬ë¼ì´ìŠ¤ endëŠ” exclusive

        # ë¯¸ë˜ ìº”ë“¤ì´ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ 0ìœ¼ë¡œ ì²˜ë¦¬
        if start >= end:
            up[i] = 0.0
            dn[i] = 0.0
            continue

        base = close[i] if close[i] > 0 else 1e-6

        future_high = float(np.max(high[start:end]))
        future_low  = float(np.min(low[start:end]))

        up[i] = (future_high - base) / (base + 1e-12)
        dn[i] = (future_low  - base) / (base + 1e-12)

    return up, dn

# ============================================================
# RAW gain ì„ íƒ
# ============================================================
def _pick_per_candle_gain(up: np.ndarray, dn: np.ndarray) -> np.ndarray:
    return np.where(np.abs(up) >= np.abs(dn), up, dn).astype(np.float32)

# ============================================================
# RAW bin ìƒì„± (ğŸ”¥ ë™ì  ì—£ì§€ íŠœë‹ + ê¼¬ë¦¬ ì •ë¦¬ ë²„ì „)
# ============================================================
def _raw_bins(dist: np.ndarray, target_bins: int) -> np.ndarray:
    """
    ë™ì  ë¶„í¬ ê¸°ë°˜ ì—£ì§€ ê³„ì‚°:
    - í´ë˜ìŠ¤ ê°œìˆ˜(target_bins)ëŠ” ìµœëŒ€í•œ ìœ ì§€
    - í•œ í´ë˜ìŠ¤ë‹¹ ìµœì†Œ ìƒ˜í”Œ ìˆ˜(_MIN_SAMPLES_PER_CLASS)ë¥¼ ê³ ë ¤í•´ bin ìˆ˜ ìë™ ì¡°ì •
    - ë¶„ìœ„ìˆ˜(quantile) ê¸°ë°˜ì´ë¼ ê·¹ë‹¨ êµ¬ê°„ì´ 3%~28% ê°™ì€ ë¯¸ì¹œ í­ìœ¼ë¡œ ì»¤ì§€ì§€ ì•ŠìŒ
    - ì¶”ê°€: ìƒ/í•˜ìœ„ ê·¹ë‹¨ ê¼¬ë¦¬ë¥¼ ì†ŒëŸ‰(trim)í•´ì„œ, ë¹„ì •ìƒ ê°’ì´ ì „ì²´ êµ¬ê°„ì„ ì°¢ì–´ë¨¹ì§€ ì•Šê²Œ í•¨
    """
    # ìœ íš¨ ê°’ë§Œ ì‚¬ìš©
    if dist is None:
        return np.linspace(-0.01, 0.01, target_bins + 1).astype(float)

    dist = np.asarray(dist, dtype=float)
    dist = dist[np.isfinite(dist)]
    if dist.size == 0:
        return np.linspace(-0.01, 0.01, target_bins + 1).astype(float)

    n = dist.size

    # ğŸ”¥ ê·¹ë‹¨ ê¼¬ë¦¬ ì†ŒëŸ‰ ì œê±° (êµ¬ê°„ ê³„ì‚°ìš©)
    # - LABEL_TAIL_TRIM_FRAC ë¹„ìœ¨(ì˜ˆ: 0.005 â†’ ìƒ/í•˜ìœ„ 0.5%)ë§Œ ì ê¹ ì œì™¸
    # - ë‚¨ëŠ” ìƒ˜í”Œì´ ë„ˆë¬´ ì ìœ¼ë©´(ì ˆë°˜ ì´í•˜ ë“±) ê·¸ëƒ¥ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    if _TAIL_TRIM_FRAC > 0.0 and n >= 100:
        try:
            q_low, q_high = np.quantile(
                dist,
                [_TAIL_TRIM_FRAC, 1.0 - _TAIL_TRIM_FRAC]
            )
            mask = (dist >= q_low) & (dist <= q_high)
            trimmed = dist[mask]
            # ìµœì†Œ ìœ ì§€ ì¡°ê±´: ì „ì²´ì˜ 70% ì´ìƒ, ê·¸ë¦¬ê³  ìµœì†Œ ìƒ˜í”Œ ìˆ˜ í™•ë³´
            if trimmed.size >= max(_MIN_LABEL_CLASSES * 2, int(0.7 * n)):
                dist = trimmed
                n = dist.size
        except Exception:
            # quantile ê³„ì‚° ì‹¤íŒ¨ ì‹œ trimming ìƒëµ
            pass

    lo = float(np.min(dist))
    hi = float(np.max(dist))
    if not np.isfinite(lo):
        lo = -0.01
    if not np.isfinite(hi):
        hi = 0.01
    if hi <= lo:
        hi = lo + 1e-6

    # ë°ì´í„° ì–‘ì´ ì ìœ¼ë©´ ì–´ì°¨í”¼ ì„¸ë¶„í™”ê°€ ì•ˆ ë˜ë¯€ë¡œ ê· ë“± ë¶„í• ë¡œ ë¹ ë¥´ê²Œ ë¦¬í„´
    if n < _MIN_SAMPLES_PER_CLASS * 2:
        return np.linspace(
            lo,
            hi,
            max(_MIN_LABEL_CLASSES, min(target_bins, 4)) + 1,
        ).astype(float)

    # ë°ì´í„°ê°€ í—ˆìš©í•˜ëŠ” ìµœëŒ€ bin ìˆ˜ (ê° binì— ìµœì†Œ ìƒ˜í”Œ ìˆ˜ë¥¼ ê°–ë„ë¡)
    max_bins_by_samples = max(1, n // max(1, _MIN_SAMPLES_PER_CLASS))

    # ì‹¤ì œ ì‚¬ìš©í•  bin ìˆ˜
    # - ë„ˆë¬´ ë§ì§€ë„ ì•Šê³ 
    # - ìµœì†Œ í´ë˜ìŠ¤ ìˆ˜ëŠ” ì§€í‚¤ë©´ì„œ
    bins = int(min(target_bins, max_bins_by_samples))
    bins = int(max(_MIN_LABEL_CLASSES, bins))

    if bins <= 1:
        # ì–´ì©” ìˆ˜ ì—†ì´ 1ê°œ bin ìˆ˜ì¤€ì´ë©´ ìµœì†Œ 2ê°œë¡œ ìª¼ê°œ ì¤€ë‹¤
        return np.linspace(lo, hi, 2 + 1).astype(float)

    # ë¶„ìœ„ìˆ˜(quantile) ê¸°ë°˜ ì—£ì§€ ê³„ì‚°
    # ì˜ˆ: bins=14 â†’ q = [0, 1/14, 2/14, ..., 1]
    qs = np.linspace(0.0, 1.0, bins + 1)
    try:
        edges = np.quantile(dist, qs)
    except Exception:
        # quantile ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ê· ë“± ë¶„í• ë¡œ fallback
        return np.linspace(lo, hi, bins + 1).astype(float)

    edges = np.asarray(edges, dtype=float)

    # ë‹¨ì¡° ì¦ê°€(ê²¹ì¹˜ì§€ ì•Šë„ë¡) ë³´ì¥
    for i in range(1, edges.size):
        if edges[i] <= edges[i - 1]:
            edges[i] = edges[i - 1] + 1e-9

    # ì•ˆì „ì¥ì¹˜: ì „ì²´ ë²”ìœ„ëŠ” ì›ë˜ lo~hi ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šê²Œ í´ë¨í”„
    edges[0] = min(edges[0], lo)
    edges[-1] = max(edges[-1], hi)

    return edges

def _vector_bin(gains: np.ndarray, edges: np.ndarray) -> np.ndarray:
    e = edges.copy()
    e[-1] += 1e-12
    bins = np.searchsorted(e, gains, side="right") - 1
    return np.clip(bins, 0, edges.size - 2).astype(np.int64)

# ============================================================
# í¬ì†Œ í´ë˜ìŠ¤ ë³‘í•© (ì•„ì´ë””ì–´ A) â€” ì˜µì…˜
# ============================================================
def _merge_sparse_bins(edges: np.ndarray, values: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
    """
    ì•„ì´ë””ì–´ A:
    - í•œ "í´ë˜ìŠ¤"ì— ë“¤ì–´ì˜¨ ìƒ˜í”Œ ìˆ˜ê°€ ë„ˆë¬´ ì ìœ¼ë©´,
      ë°”ë¡œ ì´ì›ƒ binê³¼ í•©ì³ì„œ ê·¹ë‹¨ ê¼¬ë¦¬ë¥¼ ì¤„ì¸ë‹¤.
    - ê¸°ë³¸ì€ MERGE_SPARSE_LABEL_BINS=0 ìœ¼ë¡œ êº¼ì ¸ ìˆê³ ,
      1ë¡œ ì¼  ê²½ìš°ì—ë§Œ ì‹¤ì œ ë³‘í•©ì— ì‚¬ìš©í•œë‹¤.
    ë°˜í™˜: (ìƒˆ edges, ìƒˆ bin_counts)
    """
    try:
        edges = np.asarray(edges, dtype=float)
        if edges.size < 3:
            return edges, np.zeros(max(0, edges.size - 1), dtype=int)

        values = np.asarray(values, dtype=float)
        values = values[np.isfinite(values)]
        if values.size == 0:
            return edges, np.zeros(max(0, edges.size - 1), dtype=int)

        # ì´ˆê¸° bin ì¹´ìš´íŠ¸ ê³„ì‚° (ë¼ë²¨ ê¸°ì¤€ ë¶„í¬)
        e2 = edges.copy()
        e2[-1] += 1e-12
        counts, _ = np.histogram(values, bins=e2)
        counts = counts.astype(int)

        total = int(counts.sum())
        if total <= 0:
            return edges, counts

        min_samples = max(1, _SC_MIN_SAMPLES)
        min_classes = max(1, _SC_MIN_CLASSES)
        max_passes = max(0, _SC_MAX_PASSES)

        # ì´ë¯¸ ì¶©ë¶„íˆ bin ìˆ˜ê°€ ì ìœ¼ë©´ ë” ì¤„ì´ì§€ ì•ŠëŠ”ë‹¤.
        if counts.size <= min_classes or max_passes == 0:
            return edges, counts

        e = edges.copy()
        c = counts.copy()

        for _ in range(max_passes):
            if c.size <= min_classes:
                break

            # í¬ì†Œ bin ì¸ë±ìŠ¤: ìƒ˜í”Œ ìˆ˜ê°€ ê¸°ì¤€ ë¯¸ë§Œì¸ bin (í´ë˜ìŠ¤)
            sparse_idx = np.where(c < min_samples)[0]
            if sparse_idx.size == 0:
                break

            # ê°€ì¥ ë¹ˆì•½í•œ binë¶€í„° ì²˜ë¦¬
            sparse_idx = list(sorted(sparse_idx, key=lambda i: c[i]))
            changed = False

            for idx in sparse_idx:
                if c.size <= min_classes:
                    break
                if idx >= c.size:
                    continue
                if c[idx] >= min_samples:
                    continue

                left_ok = idx - 1 >= 0
                right_ok = idx + 1 < c.size
                if not left_ok and not right_ok:
                    continue

                # ì–‘ìª½ ë‹¤ ìˆìœ¼ë©´ ë” "ë‘êº¼ìš´" ìª½ìœ¼ë¡œ í•©ì¹˜ê¸°
                if left_ok and right_ok:
                    if c[idx - 1] >= c[idx + 1]:
                        nbr = idx - 1
                    else:
                        nbr = idx + 1
                elif left_ok:
                    nbr = idx - 1
                else:
                    nbr = idx + 1

                # ì‹¤ì œ ë³‘í•© ìˆ˜í–‰ (ì¸ì ‘ binë§Œ)
                if nbr == idx - 1:
                    # ì™¼ìª½ê³¼ ë³‘í•©: ê²½ê³„ e[idx] ì œê±°, c[nbr] += c[idx]
                    c[nbr] = c[nbr] + c[idx]
                    c = np.delete(c, idx)
                    e = np.delete(e, idx)
                elif nbr == idx + 1:
                    # ì˜¤ë¥¸ìª½ê³¼ ë³‘í•©: ê²½ê³„ e[idx+1] ì œê±°, c[idx] += c[nbr]
                    c[idx] = c[idx] + c[nbr]
                    c = np.delete(c, nbr)
                    e = np.delete(e, nbr)
                else:
                    # ë…¼ë¦¬ìƒ ì˜¬ ì¼ ì—†ìŒ
                    continue

                changed = True

            if not changed:
                break

        # ì•ˆì „ê²€ì‚¬
        if e.size != c.size + 1:
            # ë­”ê°€ ê¼¬ì˜€ìœ¼ë©´ ì›ë³¸ ìœ ì§€ (ë¼ë²¨-ê²½ê³„ ë¶ˆì¼ì¹˜ ë°©ì§€)
            logger.warning("merge_sparse_bins: edge/count size mismatch â†’ ì›ë³¸ ìœ ì§€")
            return edges, counts

        return e, c
    except Exception as ex:
        logger.warning("merge_sparse_bins failed: %s", ex)
        # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
        e2 = edges.copy()
        e2[-1] += 1e-12
        counts, _ = np.histogram(values, bins=e2)
        return edges, counts.astype(int)

# ============================================================
# target bin ìˆ˜
# ============================================================
def _auto_target_bins(df_len: int) -> int:
    if df_len <= 300:  return max(8, _TARGET_BINS)
    if df_len <= 600:  return max(10, _TARGET_BINS)
    if df_len <= 1000: return max(14, _TARGET_BINS)
    if df_len <= 2000: return max(18, _TARGET_BINS)
    if df_len <= 4000: return max(24, _TARGET_BINS)
    return max(32, _TARGET_BINS)

# ============================================================
# ìˆ˜ìµë¥  ê³„ì‚° (í•µì‹¬ ìˆ˜ì •)
# ============================================================
def compute_label_returns(df: pd.DataFrame, symbol: str, strategy: str):
    pure = _normalize_strategy_name(strategy)
    H = _get_fixed_horizon_candles(pure)   # ğŸ”¥ ì „ëµë³„ H ê³ ì • ì ìš© (ë‹¨ê¸°/ì¤‘ê¸°/ì¥ê¸° ëª¨ë‘ 1ìº”ë“¤)
    up, dn = _future_extreme_signed_returns_by_candles(df, H)
    gains = _pick_per_candle_gain(up, dn)
    target = _auto_target_bins(len(df))
    return gains, up, dn, target

# ============================================================
# ì €ì¥ í—¬í¼ë“¤ (ê·¸ëŒ€ë¡œ ìœ ì§€)
# ============================================================
def _edge_key(symbol: str, strategy: str) -> str:
    return f"{symbol.upper()}__{_normalize_strategy_name(strategy)}"

def _edge_path(symbol: str, strategy: str) -> Path:
    return _EDGES_DIR / f"{_edge_key(symbol, strategy)}.json"

def _hash_array(a: np.ndarray) -> str:
    try:
        b = np.ascontiguousarray(a.astype(np.float64)).tobytes()
        return hashlib.md5(b).hexdigest()
    except:
        return "na"

def _save_edges(symbol, strategy, edges, meta):
    p = _edge_path(symbol, strategy)
    data = {
        "symbol": symbol,
        "strategy": strategy,
        "edges": list(map(float, edges.tolist())),
        "edges_hash": _hash_array(edges),
        "meta": meta or {},
    }
    try:
        p.parent.mkdir(parents=True, exist_ok=True)
        with p.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.warning("failed to save edges: %s", e)

def _labels_path(symbol, strategy):
    return _LABELS_DIR / f"{_edge_key(symbol, strategy)}.parquet"

def _labels_csv_path(symbol, strategy):
    return _LABELS_DIR / f"{_edge_key(symbol, strategy)}.csv"

# ============================================================
# ë¼ë²¨ ì €ì¥
# ============================================================
def _save_label_table(df, symbol, strategy, gains, labels, edges, counts,
                      spans, extra_cols=None, extra_meta=None, group_id=None):

    pure = _normalize_strategy_name(strategy)
    ts = _to_series_ts_kst(df["timestamp"]) if "timestamp" in df else pd.Series(pd.NaT)

    out = pd.DataFrame({
        "ts": ts,
        "symbol": symbol,
        "strategy": pure,
        "class_id": labels,
        "signed_gain": gains,
    })
    if group_id is not None:
        out["group_id"] = int(group_id)
    if extra_cols:
        for k, v in extra_cols.items():
            out[k] = v

    p_parquet = _labels_path(symbol, pure)
    p_csv = _labels_csv_path(symbol, pure)
    p_parquet.parent.mkdir(parents=True, exist_ok=True)

    try:
        out.to_parquet(p_parquet, index=False)
    except Exception:
        out.to_csv(p_csv, index=False)

    class_ranges = [(float(edges[i]), float(edges[i+1])) for i in range(edges.size - 1)]

    meta = {
        "symbol": symbol,
        "strategy": pure,
        "NUM_CLASSES": int(edges.size - 1),
        "edges": list(map(float, edges.tolist())),
        "edges_hash": _hash_array(edges),
        "class_ranges": class_ranges,
        "bin_counts": list(map(int, counts)),
    }
    if extra_meta:
        meta.update(extra_meta)
    if group_id is not None:
        meta["group_id"] = group_id

    _save_edges(symbol, pure, edges, meta)

# ============================================================
# make_labels
# ============================================================
def make_labels(df, symbol, strategy, group_id=None):
    pure = _normalize_strategy_name(strategy)

    gains, up_c, dn_c, target_bins = compute_label_returns(df, symbol, pure)

    # ë¶„í¬: up/dn í•©ì¹œ ì „ì²´ ë¶„í¬ ê¸°ì¤€ìœ¼ë¡œ 1ì°¨ ì—£ì§€ ìƒì„±
    dist = np.concatenate([dn_c, up_c], axis=0)

    # 1ì°¨: ë™ì  RAW bin ìƒì„± (ê¼¬ë¦¬ ì •ë¦¬ + quantile ê¸°ë°˜)
    edges = _raw_bins(dist, target_bins)

    # 2ì°¨: í¬ì†Œ bin ë³‘í•© (ì•„ì´ë””ì–´ A) â€” ì˜µì…˜
    if MERGE_SPARSE_LABEL_BINS:
        edges, _ = _merge_sparse_bins(edges, gains)

    # ë³‘í•©(ë˜ëŠ” ì›ë³¸) ê²½ê³„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœì¢… ë¼ë²¨ë§
    labels = _vector_bin(gains, edges)

    # ìµœì¢… bin ë¶„í¬/í­ ì¬ê³„ì‚° (gains ê¸°ì¤€)
    edges2 = edges.copy()
    edges2[-1] += 1e-12
    bin_counts, _ = np.histogram(gains, bins=edges2)
    spans = np.diff(edges) * 100.0

    # ğŸ”¥ í•™ìŠµì—ì„œë§Œ ë²„ë¦´ ì¤‘ì•™(0% ê·¼ì²˜) ë§ˆìŠ¤í¬
    #  - |gain| < TRAIN_ZERO_BAND_ABS â†’ train_mask = 0  (í•™ìŠµì—ì„œ ì œì™¸)
    #  - ë‚˜ë¨¸ì§€ â†’ train_mask = 1      (í•™ìŠµì— ì‚¬ìš©)
    train_mask = (np.abs(gains) >= float(TRAIN_ZERO_BAND_ABS)).astype(np.int8)

    sl = 0.02
    extra_cols = {
        "future_up": up_c,
        "future_dn": dn_c,
        "up_ge_2pct": (up_c >= sl).astype(np.int8),
        "dn_le_-2pct": (dn_c <= -sl).astype(np.int8),
        "train_mask": train_mask,  # ğŸ”¥ í•™ìŠµìš© ë§ˆìŠ¤í¬ ì¶”ê°€
    }

    _save_label_table(
        df, symbol, pure,
        gains, labels,
        edges, bin_counts, spans,
        extra_cols=extra_cols,
        extra_meta={"target_bins_used": target_bins},
        group_id=group_id,
    )

    class_ranges = [(float(edges[i]), float(edges[i+1]))
                    for i in range(edges.size - 1)]

    return (
        gains.astype(np.float32),
        labels.astype(np.int64),
        class_ranges,
        edges.astype(float),
        bin_counts.astype(int),
        spans.astype(float),
    )


# ============================================================
# make_labels_for_horizon (RAW í†µì¼)
# ============================================================
def make_labels_for_horizon(df, symbol, horizon_hours, group_id=None):
    n = len(df)
    both = _future_extreme_signed_returns(df, horizon_hours=horizon_hours)
    if both is None:
        dn = np.zeros(n, dtype=np.float32)
        up = np.zeros(n, dtype=np.float32)
    else:
        dn = np.asarray(both[:n], dtype=np.float32)
        up = np.asarray(both[n:], dtype=np.float32)

    # up/dn ì „ì²´ ë¶„í¬
    dist = np.concatenate([dn, up], axis=0)
    target_bins = _auto_target_bins(len(df))

    # 1ì°¨: RAW bin (ê¼¬ë¦¬ ì •ë¦¬ + quantile ê¸°ë°˜)
    edges = _raw_bins(dist, target_bins)

    # gains ë¨¼ì € ê³„ì‚°
    gains = _pick_per_candle_gain(up, dn)

    # 2ì°¨: í¬ì†Œ bin ë³‘í•© (gains ê¸°ì¤€) â€” ì˜µì…˜
    if MERGE_SPARSE_LABEL_BINS:
        edges, _ = _merge_sparse_bins(edges, gains)

    labels = _vector_bin(gains, edges)

    edges2 = edges.copy()
    edges2[-1] += 1e-12
    bin_counts, _ = np.histogram(gains, bins=edges2)
    spans = np.diff(edges) * 100.0

    strategy = "ë‹¨ê¸°" if horizon_hours <= 4 else ("ì¤‘ê¸°" if horizon_hours <= 24 else "ì¥ê¸°")

    # ğŸ”¥ í•™ìŠµì—ì„œë§Œ ë²„ë¦´ ì¤‘ì•™(0% ê·¼ì²˜) ë§ˆìŠ¤í¬
    train_mask = (np.abs(gains) >= float(TRAIN_ZERO_BAND_ABS)).astype(np.int8)

    extra_cols = {
        "future_up": up,
        "future_dn": dn,
        "up_ge_2pct": (up >= 0.02).astype(np.int8),
        "dn_le_-2pct": (dn <= -0.02).astype(np.int8),
        "train_mask": train_mask,  # ğŸ”¥ í•™ìŠµìš© ë§ˆìŠ¤í¬ ì¶”ê°€
    }

    _save_label_table(
        df, symbol, strategy, gains, labels,
        edges, bin_counts, spans,
        extra_cols=extra_cols,
        extra_meta={"target_bins_used": target_bins},
        group_id=group_id,
    )

    class_ranges = [(float(edges[i]), float(edges[i+1]))
                    for i in range(edges.size - 1)]

    return (
        gains.astype(np.float32),
        labels.astype(np.int64),
        class_ranges,
        strategy,
        edges.astype(float),
        bin_counts.astype(int),
        spans.astype(float),
    )


# ============================================================
# make_all_horizon_labels
# ============================================================
def make_all_horizon_labels(df, symbol, horizons=None, group_id=None):
    if horizons is None:
        horizons = [4, 24, 168]

    out = {}
    for h in horizons:
        gains, labels, ranges, strat, edges, counts, spans = \
            make_labels_for_horizon(df, symbol, h, group_id)
        key = (
            f"{h}h" if h < 24 else
            ("1d" if h == 24 else
             (f"{h//24}d" if h < 168 else "7d"))
        )
        out[key] = (gains, labels, ranges, edges, counts, spans)
    return out
