# âœ… Render ìºì‹œ ê°•ì œ ë¬´íš¨í™”ìš© ì£¼ì„ â€” ì ˆëŒ€ ì‚­ì œí•˜ì§€ ë§ˆ
_kline_cache = {}

import os
import time
import json
import requests
import pandas as pd
import numpy as np
import pytz
from sklearn.preprocessing import MinMaxScaler

# =========================
# ê¸°ë³¸ ìƒìˆ˜/ì „ì—­
# =========================
BASE_URL = "https://api.bybit.com"
BINANCE_BASE_URL = "https://fapi.binance.com"  # Binance Futures (USDT-M)
BTC_DOMINANCE_CACHE = {"value": 0.5, "timestamp": 0}

# âš ï¸ SYMBOLS/SYMBOL_GROUPSëŠ” í”„ë¡œì íŠ¸ì—ì„œ data.utilsë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ ìœ ì§€
SYMBOLS = [
    "BTCUSDT", "ETHUSDT", "SOLUSDT", "XRPUSDT", "ADAUSDT",
    "AVAXUSDT", "DOGEUSDT", "MATICUSDT", "DOTUSDT", "TRXUSDT",
    "LTCUSDT", "BCHUSDT", "LINKUSDT", "ATOMUSDT", "XLMUSDT",
    "ETCUSDT", "ICPUSDT", "HBARUSDT", "FILUSDT", "SANDUSDT",
    "RNDRUSDT", "INJUSDT", "NEARUSDT", "APEUSDT", "ARBUSDT",
    "AAVEUSDT", "OPUSDT", "SUIUSDT", "DYDXUSDT", "CHZUSDT",
    "LDOUSDT", "STXUSDT", "GMTUSDT", "FTMUSDT", "WLDUSDT",
    "TIAUSDT", "SEIUSDT", "ARKMUSDT", "JASMYUSDT", "AKTUSDT",
    "GMXUSDT", "SKLUSDT", "BLURUSDT", "ENSUSDT", "CFXUSDT",
    "FLOWUSDT", "ALGOUSDT", "MINAUSDT", "NEOUSDT", "MASKUSDT",
    "KAVAUSDT", "BATUSDT", "ZILUSDT", "WAVESUSDT", "OCEANUSDT",
    "1INCHUSDT", "YFIUSDT", "STGUSDT", "GALAUSDT", "IMXUSDT"
]
# âœ… ê³ ì • ìˆœì„œ ìœ ì§€í•˜ë©° 5ê°œì”© ë¬¶ì–´ SYMBOL_GROUPS êµ¬ì„±
SYMBOL_GROUPS = [SYMBOLS[i:i + 5] for i in range(0, len(SYMBOLS), 5)]

# âœ… ê±°ë˜ì†Œë³„ ì‹¬ë³¼ ë§¤í•‘
SYMBOL_MAP = {
    "bybit": {s: s for s in SYMBOLS},
    "binance": {s: s for s in SYMBOLS}
}

# âœ… ì „ëµ ì„¤ì •ì€ ë‹¨ì¼ ì†ŒìŠ¤(config.py)ë¥¼ ë”°ë¥¸ë‹¤
try:
    from config import STRATEGY_CONFIG  # {"ë‹¨ê¸°":{"interval":"240","limit":1000,"binance_interval":"4h"}, ...}
except Exception:
    # ìµœí›„ ì•ˆì „ë§(ë§Œì•½ config ì„í¬íŠ¸ê°€ ì‹¤íŒ¨í•˜ë©´)
    STRATEGY_CONFIG = {
        "ë‹¨ê¸°": {"interval": "240", "limit": 1000, "binance_interval": "4h"},
        "ì¤‘ê¸°": {"interval": "D",   "limit": 500,  "binance_interval": "1d"},
        "ì¥ê¸°": {"interval": "D",   "limit": 500,  "binance_interval": "1d"},
    }

# =========================
# ìºì‹œ ë§¤ë‹ˆì € (ì´ íŒŒì¼ ë‚´ë¶€ ì‚¬ìš©)
# =========================
class CacheManager:
    _cache = {}
    _ttl = {}

    @classmethod
    def get(cls, key, ttl_sec=None):
        now = time.time()
        if key in cls._cache:
            if ttl_sec is None or now - cls._ttl.get(key, 0) < ttl_sec:
                print(f"[ìºì‹œ HIT] {key}")
                return cls._cache[key]
            else:
                print(f"[ìºì‹œ EXPIRED] {key}")
                cls.delete(key)
        return None

    @classmethod
    def set(cls, key, value):
        cls._cache[key] = value
        cls._ttl[key] = time.time()
        print(f"[ìºì‹œ SET] {key}")

    @classmethod
    def delete(cls, key):
        if key in cls._cache:
            del cls._cache[key]
            cls._ttl.pop(key, None)
            print(f"[ìºì‹œ DELETE] {key}")

    @classmethod
    def clear(cls):
        cls._cache.clear()
        cls._ttl.clear()
        print("[ìºì‹œ CLEAR ALL]")

# =========================
# ì‹¤íŒ¨ ë¡œê¹…(ìˆœí™˜ ì˜ì¡´ ì œê±°ìš© ê²½ëŸ‰ í—¬í¼)
# =========================
def safe_failed_result(symbol, strategy, reason=""):
    try:
        from failure_db import insert_failure_record  # ìˆœí™˜ ì—†ìŒ
        payload = {
            "symbol": symbol or "UNKNOWN",
            "strategy": strategy or "UNKNOWN",
            "model": "utils",
            "reason": reason,
            "timestamp": pd.Timestamp.now(tz="Asia/Seoul").strftime("%Y-%m-%d %H:%M:%S"),
            "predicted_class": -1,
            "label": -1
        }
        insert_failure_record(payload, feature_hash="utils_error", feature_vector=None, label=-1)
    except Exception as e:
        print(f"[âš ï¸ safe_failed_result ì‹¤íŒ¨] {e}")

# =========================
# ê¸°íƒ€ ìœ í‹¸
# =========================
def get_btc_dominance():
    global BTC_DOMINANCE_CACHE
    now = time.time()
    if now - BTC_DOMINANCE_CACHE["timestamp"] < 1800:
        return BTC_DOMINANCE_CACHE["value"]
    try:
        url = "https://api.coinpaprika.com/v1/global"
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        data = res.json()
        dom = float(data["bitcoin_dominance_percentage"]) / 100
        BTC_DOMINANCE_CACHE = {"value": round(dom, 4), "timestamp": now}
        return BTC_DOMINANCE_CACHE["value"]
    except:
        return BTC_DOMINANCE_CACHE["value"]

# =========================
# ë°ì´í„°ì…‹ ìƒì„± (ë°˜í™˜ê°’ í•­ìƒ X, y)
# =========================
def create_dataset(features, window=10, strategy="ë‹¨ê¸°", input_size=None):
    """
    features: list[dict] (timestamp, open/high/low/close/volume, â€¦)
    window:   ì‹œí€€ìŠ¤ ê¸¸ì´
    return:   (X, y) â€” í•­ìƒ 2ê°œ ë°˜í™˜
    """
    import pandas as pd
    from config import MIN_FEATURES
    from logger import log_prediction

    def _dummy(symbol_name):
        X = np.zeros((max(1, window), window, input_size if input_size else MIN_FEATURES), dtype=np.float32)
        y = np.zeros((max(1, window),), dtype=np.int64)
        log_prediction(symbol=symbol_name, strategy=strategy, direction="dummy", entry_price=0,
                       target_price=0, model="dummy_model", success=False, reason="ì…ë ¥ feature ë¶€ì¡±/ì‹¤íŒ¨",
                       rate=0.0, return_value=0.0, volatility=False, source="create_dataset",
                       predicted_class=0, label=0)
        return X, y

    symbol_name = "UNKNOWN"
    if isinstance(features, list) and features and isinstance(features[0], dict) and "symbol" in features[0]:
        symbol_name = features[0]["symbol"]

    if not isinstance(features, list) or len(features) <= window:
        print(f"[âš ï¸ ë¶€ì¡±] features length={len(features) if isinstance(features, list) else 'Invalid'}, window={window}")
        return _dummy(symbol_name)

    try:
        df = pd.DataFrame(features)
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
        df = df.dropna(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)
        df = df.drop(columns=["strategy"], errors="ignore")

        feature_cols = [c for c in df.columns if c != "timestamp"]
        if not feature_cols:
            print("[âŒ feature_cols ì—†ìŒ]")
            return _dummy(symbol_name)

        if len(feature_cols) < MIN_FEATURES:
            for i in range(len(feature_cols), MIN_FEATURES):
                pad_col = f"pad_{i}"
                df[pad_col] = 0.0
                feature_cols.append(pad_col)

        scaler = MinMaxScaler()
        scaled = scaler.fit_transform(df[feature_cols])
        df_scaled = pd.DataFrame(scaled, columns=feature_cols)
        df_scaled["timestamp"] = df["timestamp"].values
        df_scaled["high"] = df["high"] if "high" in df.columns else df["close"]

        if input_size and len(feature_cols) < input_size:
            for i in range(len(feature_cols), input_size):
                pad_col = f"pad_{i}"
                df_scaled[pad_col] = 0.0

        features = df_scaled.to_dict(orient="records")

        # lookahead ê¸°ë°˜ ë¼ë²¨ë§
        strategy_minutes = {"ë‹¨ê¸°": 240, "ì¤‘ê¸°": 1440, "ì¥ê¸°": 2880}
        lookahead_minutes = strategy_minutes.get(strategy, 1440)

        samples, gains = [], []
        for i in range(window, len(features)):
            seq = features[i - window:i]
            base = features[i]
            entry_time = pd.to_datetime(base.get("timestamp"), errors="coerce")
            entry_price = float(base.get("close", 0.0))

            if pd.isnull(entry_time) or entry_price <= 0:
                continue

            future = [f for f in features[i + 1:]
                      if pd.to_datetime(f.get("timestamp", None)) - entry_time <= pd.Timedelta(minutes=lookahead_minutes)]
            valid_prices = [f.get("high", f.get("close", entry_price)) for f in future if f.get("high", 0) > 0]
            if len(seq) != window or not valid_prices:
                continue

            max_future_price = max(valid_prices)
            gain = float((max_future_price - entry_price) / (entry_price + 1e-6))
            gains.append(gain)

            row_cols = [c for c in df_scaled.columns if c != "timestamp"]
            sample = [[float(r.get(c, 0.0)) for c in row_cols] for r in seq]

            if input_size:
                for j in range(len(sample)):
                    row = sample[j]
                    if len(row) < input_size:
                        row.extend([0.0] * (input_size - len(row)))
                    elif len(row) > input_size:
                        sample[j] = row[:input_size]
            samples.append((sample, gain))

        if not samples:
            print("[â„¹ï¸ lookahead ê¸°ë°˜ ìƒ˜í”Œ ì—†ìŒ â†’ ì¸ì ‘ ë³€í™”ìœ¨ë¡œ 3â€‘í´ë˜ìŠ¤ ë¼ë²¨ë§ ì‚¬ìš©]")
            closes_np = df_scaled["close"].to_numpy()
            pct = np.diff(closes_np) / (closes_np[:-1] + 1e-6)
            thresh = 0.001  # Â±0.1%

            for i in range(window, len(df_scaled) - 1):
                seq_rows = df_scaled.iloc[i - window:i]
                g = pct[i] if i < len(pct) else 0.0
                cls = 2 if g > thresh else (0 if g < -thresh else 1)

                row_cols = [c for c in df_scaled.columns if c != "timestamp"]
                sample = [[float(r.get(c, 0.0)) for c in row_cols] for _, r in seq_rows.iterrows()]
                if input_size:
                    for j in range(len(sample)):
                        row = sample[j]
                        if len(row) < input_size:
                            row.extend([0.0] * (input_size - len(row)))
                        elif len(row) > input_size:
                            sample[j] = row[:input_size]
                samples.append((sample, cls))

            X = np.array([s[0] for s in samples], dtype=np.float32)
            y = np.array([s[1] for s in samples], dtype=np.int64)
            if len(X) == 0:
                return _dummy(symbol_name)
            print(f"[âœ… create_dataset ì™„ë£Œ] (fallback 3â€‘class) ìƒ˜í”Œ ìˆ˜: {len(y)}, X.shape={X.shape}")
            return X, y

        min_gain, max_gain = min(gains), max(gains)
        spread = max_gain - min_gain
        est_class = int(spread / 0.01)
        num_classes = max(3, min(21, est_class if est_class > 0 else 3))
        step = spread / num_classes if num_classes > 0 else 1e-6
        if step == 0:
            step = 1e-6

        X_list, y_list = [], []
        for sample, gain in samples:
            cls = min(int((gain - min_gain) / step), num_classes - 1)
            X_list.append(sample)
            y_list.append(cls)

        X = np.array(X_list, dtype=np.float32)
        y = np.array(y_list, dtype=np.int64)
        print(f"[âœ… create_dataset ì™„ë£Œ] ìƒ˜í”Œ ìˆ˜: {len(y)}, X.shape={X.shape}, ë™ì  í´ë˜ìŠ¤ ìˆ˜: {num_classes}")
        return X, y

    except Exception as e:
        print(f"[âŒ ìµœìƒìœ„ ì˜ˆì™¸] create_dataset ì‹¤íŒ¨ â†’ {e}")
        return _dummy(symbol_name)

# =========================
# ê±°ë˜ì†Œ ìˆ˜ì§‘ê¸°(Bybit)
# =========================
def get_kline(symbol: str, interval: str = "60", limit: int = 300, max_retry: int = 2, end_time=None) -> pd.DataFrame:
    real_symbol = SYMBOL_MAP["bybit"].get(symbol, symbol)
    target_rows = int(limit)
    collected_data, total_rows = [], 0

    while total_rows < target_rows:
        success = False
        for attempt in range(max_retry):
            try:
                rows_needed = target_rows - total_rows
                request_limit = min(1000, rows_needed)
                params = {
                    "category": "linear",
                    "symbol": real_symbol,
                    "interval": interval,
                    "limit": request_limit
                }
                if end_time is not None:
                    params["end"] = int(end_time.timestamp() * 1000)

                print(f"[ğŸ“¡ Bybit ìš”ì²­] {real_symbol}-{interval} | ì‹œë„ {attempt+1}/{max_retry} | ìš”ì²­ ìˆ˜ëŸ‰={request_limit}")
                res = requests.get(f"{BASE_URL}/v5/market/kline", params=params, timeout=10)
                res.raise_for_status()
                data = res.json()

                if "result" not in data or "list" not in data["result"] or not data["result"]["list"]:
                    print(f"[âŒ ë°ì´í„° ì—†ìŒ] {real_symbol} (ì‹œë„ {attempt+1})")
                    break

                raw = data["result"]["list"]
                if not raw or len(raw[0]) < 6:
                    print(f"[âŒ í•„ë“œ ë¶€ì¡±] {real_symbol}")
                    break

                df_chunk = pd.DataFrame(raw, columns=[
                    "timestamp", "open", "high", "low", "close", "volume", "turnover"
                ])
                df_chunk = df_chunk[["timestamp", "open", "high", "low", "close", "volume"]].apply(pd.to_numeric, errors="coerce")
                df_chunk.dropna(subset=["open", "high", "low", "close", "volume"], inplace=True)
                if df_chunk.empty:
                    break

                df_chunk["timestamp"] = pd.to_datetime(df_chunk["timestamp"], unit="ms", errors="coerce")
                df_chunk.dropna(subset=["timestamp"], inplace=True)
                df_chunk["timestamp"] = df_chunk["timestamp"].dt.tz_localize("UTC").dt.tz_convert("Asia/Seoul")
                df_chunk = df_chunk.sort_values("timestamp").reset_index(drop=True)
                df_chunk["datetime"] = df_chunk["timestamp"]

                collected_data.append(df_chunk)
                total_rows += len(df_chunk)
                success = True

                if total_rows >= target_rows:
                    break

                end_time = df_chunk["timestamp"].min() - pd.Timedelta(milliseconds=1)
                time.sleep(0.2)
                break

            except Exception as e:
                print(f"[ì—ëŸ¬] get_kline({real_symbol}) ì‹¤íŒ¨ â†’ {e}")
                time.sleep(1)
                continue

        if not success:
            break

    if collected_data:
        df = (pd.concat(collected_data, ignore_index=True)
              .drop_duplicates(subset=["timestamp"])
              .sort_values("timestamp")
              .reset_index(drop=True))
        print(f"[ğŸ“Š ìˆ˜ì§‘ ì™„ë£Œ] {symbol}-{interval} â†’ ì´ {len(df)}ê°œ ë´‰ í™•ë³´")
        return df
    else:
        print(f"[âŒ ìµœì¢… ì‹¤íŒ¨] {symbol}-{interval} â†’ ìˆ˜ì§‘ëœ ë´‰ ì—†ìŒ")
        return pd.DataFrame(columns=["timestamp", "open", "high", "low", "close", "volume", "datetime"])

# =========================
# ê±°ë˜ì†Œ ìˆ˜ì§‘ê¸°(Binance)
# =========================
def get_kline_binance(symbol: str, interval: str = "240", limit: int = 300, max_retry: int = 2, end_time=None) -> pd.DataFrame:
    real_symbol = SYMBOL_MAP["binance"].get(symbol, symbol)

    # configì˜ binance_interval ìš°ì„  ì‚¬ìš©
    _bin_iv = None
    for name, cfg in STRATEGY_CONFIG.items():
        if cfg.get("interval") == interval:
            _bin_iv = cfg.get("binance_interval")
            break
    if _bin_iv is None:
        interval_map = {"240": "4h", "D": "1d", "2D": "2d", "60": "1h"}
        _bin_iv = interval_map.get(interval, "1h")

    target_rows = int(limit)
    collected_data, total_rows = [], 0

    while total_rows < target_rows:
        success = False
        for attempt in range(max_retry):
            try:
                rows_needed = target_rows - total_rows
                request_limit = min(1000, rows_needed)
                params = {
                    "symbol": real_symbol,
                    "interval": _bin_iv,
                    "limit": request_limit
                }
                if end_time is not None:
                    params["endTime"] = int(end_time.timestamp() * 1000)

                print(f"[ğŸ“¡ Binance ìš”ì²­] {real_symbol}-{interval} | ìš”ì²­ {request_limit}ê°œ | ì‹œë„ {attempt+1}/{max_retry} | end_time={end_time}")
                res = requests.get(f"{BINANCE_BASE_URL}/fapi/v1/klines", params=params, timeout=10)
                res.raise_for_status()
                raw = res.json()
                if not raw:
                    print(f"[âŒ Binance ë°ì´í„° ì—†ìŒ] {real_symbol}-{interval} (ì‹œë„ {attempt+1})")
                    break

                df_chunk = pd.DataFrame(raw, columns=[
                    "timestamp", "open", "high", "low", "close", "volume",
                    "close_time", "quote_asset_volume", "trades", "taker_base_vol", "taker_quote_vol", "ignore"
                ])
                df_chunk = df_chunk[["timestamp", "open", "high", "low", "close", "volume"]].apply(pd.to_numeric, errors="coerce")
                df_chunk["timestamp"] = (pd.to_datetime(df_chunk["timestamp"], unit="ms", errors="coerce")
                                          .dt.tz_localize("UTC").dt.tz_convert("Asia/Seoul"))
                df_chunk = df_chunk.dropna(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)
                df_chunk["datetime"] = df_chunk["timestamp"]

                if df_chunk.empty:
                    break

                collected_data.append(df_chunk)
                total_rows += len(df_chunk)
                success = True

                if total_rows >= target_rows:
                    break

                oldest_ts = df_chunk["timestamp"].min()
                end_time = oldest_ts - pd.Timedelta(milliseconds=1)
                time.sleep(0.2)
                break

            except Exception as e:
                print(f"[ì—ëŸ¬] get_kline_binance({real_symbol}) ì‹¤íŒ¨ â†’ {e}")
                time.sleep(1)
                continue

        if not success:
            break

    if collected_data:
        df = (pd.concat(collected_data, ignore_index=True)
              .drop_duplicates(subset=["timestamp"])
              .sort_values("timestamp")
              .reset_index(drop=True))
        print(f"[ğŸ“Š Binance ìˆ˜ì§‘ ì™„ë£Œ] {symbol}-{interval} â†’ ì´ {len(df)}ê°œ ë´‰ í™•ë³´")
        return df
    else:
        print(f"[âŒ ìµœì¢… ì‹¤íŒ¨] {symbol}-{interval} â†’ ìˆ˜ì§‘ëœ ë´‰ ì—†ìŒ")
        return pd.DataFrame(columns=["timestamp", "open", "high", "low", "close", "volume", "datetime"])

# =========================
# (ì˜µì…˜) í†µí•© ìˆ˜ì§‘ + ë³‘í•© ë„ìš°ë¯¸
# =========================
def get_merged_kline_by_strategy(symbol: str, strategy: str) -> pd.DataFrame:
    config = STRATEGY_CONFIG.get(strategy)
    if not config:
        print(f"[âŒ ì‹¤íŒ¨] ì „ëµ ì„¤ì • ì—†ìŒ: {strategy}")
        return pd.DataFrame()

    interval = config["interval"]
    base_limit = int(config["limit"])
    max_total = base_limit

    def fetch_until_target(fetch_func, source_name):
        total_data = []
        end_time = None
        total_count = 0
        max_repeat = 10

        print(f"[â³ {source_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘] {symbol}-{strategy} | ëª©í‘œ {base_limit}ê°œ")
        while total_count < max_total and len(total_data) < max_repeat:
            df_chunk = fetch_func(symbol, interval=interval, limit=base_limit, end_time=end_time)
            if df_chunk is None or df_chunk.empty:
                break

            total_data.append(df_chunk)
            total_count += len(df_chunk)

            if len(df_chunk) < base_limit:
                break

            oldest_ts = df_chunk["timestamp"].min()
            end_time = oldest_ts - pd.Timedelta(milliseconds=1)

        df_final = pd.concat(total_data, ignore_index=True) if total_data else pd.DataFrame()
        print(f"[âœ… {source_name} ìˆ˜ì§‘ ì™„ë£Œ] {symbol}-{strategy} â†’ {len(df_final)}ê°œ")
        return df_final

    df_bybit = fetch_until_target(get_kline, "Bybit")
    df_binance = pd.DataFrame()
    if len(df_bybit) < base_limit:
        print(f"[â³ Binance ë³´ì¶© ì‹œì‘] ë¶€ì¡± {base_limit - len(df_bybit)}ê°œ")
        df_binance = fetch_until_target(get_kline_binance, "Binance")

    df_all = pd.concat([df_bybit, df_binance], ignore_index=True)
    if df_all.empty:
        print(f"[â© í•™ìŠµ ìŠ¤í‚µ] {symbol}-{strategy} â†’ ê±°ë˜ì†Œ ë°ì´í„° ì „ë¬´")
        return pd.DataFrame()

    df_all = df_all.drop_duplicates(subset=["timestamp"]).sort_values("timestamp").reset_index(drop=True)

    required_cols = ["timestamp", "open", "high", "low", "close", "volume"]
    for col in required_cols:
        if col not in df_all.columns:
            df_all[col] = 0.0 if col != "timestamp" else pd.Timestamp.now(tz="Asia/Seoul")

    df_all.attrs["augment_needed"] = len(df_all) < base_limit
    print(f"[ğŸ”„ ë³‘í•© ì™„ë£Œ] {symbol}-{strategy} â†’ ìµœì¢… {len(df_all)}ê°œ (ëª©í‘œ {base_limit}ê°œ)")
    if len(df_all) < base_limit:
        print(f"[âš ï¸ ê²½ê³ ] {symbol}-{strategy} ë°ì´í„° ë¶€ì¡± ({len(df_all)}/{base_limit})")

    return df_all

# =========================
# ì „ëµë³„ Kline ìˆ˜ì§‘(ìºì‹œ í¬í•¨, ê¸°ë³¸ ì—”íŠ¸ë¦¬)
# =========================
def get_kline_by_strategy(symbol: str, strategy: str):
    cache_key = f"{symbol}-{strategy}"
    cached_df = CacheManager.get(cache_key, ttl_sec=600)
    if cached_df is not None:
        print(f"[âœ… ìºì‹œ ì‚¬ìš©] {symbol}-{strategy} â†’ {len(cached_df)}ê°œ ë´‰")
        return cached_df

    try:
        cfg = STRATEGY_CONFIG.get(strategy, {"limit": 300, "interval": "D"})
        limit = int(cfg.get("limit", 300))
        interval = cfg.get("interval", "D")

        # 1) Bybit ë°˜ë³µ ìˆ˜ì§‘
        df_bybit = []
        total_bybit = 0
        end_time = None
        print(f"[ğŸ“¡ Bybit 1ì°¨ ë°˜ë³µ ìˆ˜ì§‘ ì‹œì‘] {symbol}-{strategy} (limit={limit})")
        while total_bybit < limit:
            df_chunk = get_kline(symbol, interval=interval, limit=limit, end_time=end_time)
            if df_chunk is None or df_chunk.empty:
                break
            df_bybit.append(df_chunk)
            total_bybit += len(df_chunk)
            end_time = df_chunk["timestamp"].min() - pd.Timedelta(milliseconds=1)
            if len(df_chunk) < limit:
                break

        df_bybit = (pd.concat(df_bybit, ignore_index=True)
                    .drop_duplicates(subset=["timestamp"])
                    .sort_values("timestamp")
                    .reset_index(drop=True)) if df_bybit else pd.DataFrame()

        # 2) Binance ë³´ì™„ ìˆ˜ì§‘
        df_binance = []
        total_binance = 0
        if len(df_bybit) < int(limit * 0.9):
            print(f"[ğŸ“¡ Binance 2ì°¨ ë°˜ë³µ ìˆ˜ì§‘ ì‹œì‘] {symbol}-{strategy} (limit={limit})")
            end_time = None
            while total_binance < limit:
                try:
                    df_chunk = get_kline_binance(symbol, interval=interval, limit=limit, end_time=end_time)
                    if df_chunk is None or df_chunk.empty:
                        break
                    df_binance.append(df_chunk)
                    total_binance += len(df_chunk)
                    end_time = df_chunk["timestamp"].min() - pd.Timedelta(milliseconds=1)
                    if len(df_chunk) < limit:
                        break
                except Exception as be:
                    print(f"[âŒ Binance ìˆ˜ì§‘ ì‹¤íŒ¨] {symbol}-{strategy} â†’ {be}")
                    break

        df_binance = (pd.concat(df_binance, ignore_index=True)
                      .drop_duplicates(subset=["timestamp"])
                      .sort_values("timestamp")
                      .reset_index(drop=True)) if df_binance else pd.DataFrame()

        # 3) ë³‘í•© + ì •ë¦¬
        df_list = [df for df in [df_bybit, df_binance] if not df.empty]
        df = (pd.concat(df_list, ignore_index=True)
              .drop_duplicates(subset=["timestamp"])
              .sort_values("timestamp")
              .reset_index(drop=True)) if df_list else pd.DataFrame()

        total_count = len(df)
        if total_count < limit:
            print(f"[âš ï¸ ìˆ˜ì§‘ ìˆ˜ëŸ‰ ë¶€ì¡±] {symbol}-{strategy} â†’ ì´ {total_count}ê°œ (ëª©í‘œ: {limit})")
        else:
            print(f"[âœ… ìˆ˜ì§‘ ì„±ê³µ] {symbol}-{strategy} â†’ ì´ {total_count}ê°œ")

        CacheManager.set(cache_key, df)
        return df

    except Exception as e:
        print(f"[âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨] {symbol}-{strategy} â†’ {e}")
        safe_failed_result(symbol, strategy, reason=str(e))
        return pd.DataFrame()

# =========================
# í”„ë¦¬íŒ¨ì¹˜
# =========================
def prefetch_symbol_groups(strategy: str):
    for group in SYMBOL_GROUPS:
        for sym in group:
            try:
                get_kline_by_strategy(sym, strategy)
            except Exception as e:
                print(f"[âš ï¸ prefetch ì‹¤íŒ¨] {sym}-{strategy}: {e}")

# =========================
# ì‹¤ì‹œê°„ í‹°ì»¤
# =========================
def get_realtime_prices():
    url = f"{BASE_URL}/v5/market/tickers"
    params = {"category": "linear"}
    try:
        res = requests.get(url, params=params, timeout=10)
        res.raise_for_status()
        data = res.json()
        if "result" not in data or "list" not in data["result"]:
            return {}
        tickers = data["result"]["list"]
        return {item["symbol"]: float(item["lastPrice"]) for item in tickers if item["symbol"] in SYMBOLS}
    except:
        return {}

# =========================
# í”¼ì²˜ ìƒì„±
# =========================
_feature_cache = {}

def compute_features(symbol: str, df: pd.DataFrame, strategy: str, required_features: list = None, fallback_input_size: int = None) -> pd.DataFrame:
    from config import FEATURE_INPUT_SIZE
    import ta

    cache_key = f"{symbol}-{strategy}-features"
    cached_feat = CacheManager.get(cache_key, ttl_sec=600)
    if cached_feat is not None:
        print(f"[ìºì‹œ HIT] {cache_key}")
        return cached_feat

    if df is None or df.empty or not isinstance(df, pd.DataFrame):
        print(f"[âŒ compute_features ì‹¤íŒ¨] ì…ë ¥ DataFrame empty or invalid")
        safe_failed_result(symbol, strategy, reason="ì…ë ¥DataFrame empty")
        return pd.DataFrame()

    df = df.copy()
    if "datetime" in df.columns:
        df["timestamp"] = df["datetime"]
    elif "timestamp" not in df.columns:
        df["timestamp"] = pd.to_datetime("now", utc=True).tz_convert("Asia/Seoul")

    df["strategy"] = strategy
    base_cols = ["open", "high", "low", "close", "volume"]
    for col in base_cols:
        if col not in df.columns:
            df[col] = 0.0

    df = df[["timestamp"] + base_cols]

    if len(df) < 20:
        print(f"[âš ï¸ í”¼ì²˜ ì‹¤íŒ¨] {symbol}-{strategy} â†’ row ìˆ˜ ë¶€ì¡±: {len(df)}")
        safe_failed_result(symbol, strategy, reason=f"row ë¶€ì¡± {len(df)}")
        return df  # ìµœì†Œ ë°˜í™˜

    try:
        # ê¸°ë³¸ ê¸°ìˆ ì§€í‘œ
        df["ma20"] = df["close"].rolling(window=20, min_periods=1).mean()
        delta = df["close"].diff()
        gain = delta.where(delta > 0, 0).rolling(window=14, min_periods=1).mean()
        loss = -delta.where(delta < 0, 0).rolling(window=14, min_periods=1).mean()
        rs = gain / (loss + 1e-6)
        df["rsi"] = 100 - (100 / (1 + rs))
        ema12 = df["close"].ewm(span=12, adjust=False).mean()
        ema26 = df["close"].ewm(span=26, adjust=False).mean()
        df["macd"] = ema12 - ema26
        df["bollinger"] = df["close"].rolling(window=20, min_periods=1).std()
        df["volatility"] = df["high"] - df["low"]
        df["trend_score"] = (df["close"] > df["ma20"]).astype(int)
        df["ema50"] = df["close"].ewm(span=50, adjust=False).mean()
        df["ema100"] = df["close"].ewm(span=100, adjust=False).mean()
        df["ema200"] = df["close"].ewm(span=200, adjust=False).mean()
        df["roc"] = df["close"].pct_change(periods=10)
        df["adx"] = ta.trend.adx(df["high"], df["low"], df["close"], window=14, fillna=True)
        df["cci"] = ta.trend.cci(df["high"], df["low"], df["close"], window=20, fillna=True)
        df["mfi"] = ta.volume.money_flow_index(df["high"], df["low"], df["close"], df["volume"], window=14, fillna=True)
        df["obv"] = ta.volume.on_balance_volume(df["close"], df["volume"], fillna=True)
        df["atr"] = ta.volatility.average_true_range(df["high"], df["low"], df["close"], window=14, fillna=True)
        df["williams_r"] = ta.momentum.williams_r(df["high"], df["low"], df["close"], lbp=14, fillna=True)
        df["stoch_k"] = ta.momentum.stoch(df["high"], df["low"], df["close"], fillna=True)
        df["stoch_d"] = ta.momentum.stoch_signal(df["high"], df["low"], df["close"], fillna=True)
        df["vwap"] = (df["volume"] * df["close"]).cumsum() / (df["volume"].cumsum() + 1e-6)

        df.replace([np.inf, -np.inf], np.nan, inplace=True)
        df.fillna(0, inplace=True)

        feature_cols = [c for c in df.columns if c != "timestamp"]
        if len(feature_cols) < FEATURE_INPUT_SIZE:
            for i in range(len(feature_cols), FEATURE_INPUT_SIZE):
                pad_col = f"pad_{i}"
                df[pad_col] = 0.0
                feature_cols.append(pad_col)

        df[feature_cols] = MinMaxScaler().fit_transform(df[feature_cols])

    except Exception as e:
        print(f"[âŒ compute_features ì‹¤íŒ¨] feature ê³„ì‚° ì˜ˆì™¸ â†’ {e}")
        safe_failed_result(symbol, strategy, reason=f"feature ê³„ì‚° ì‹¤íŒ¨: {e}")
        return df  # ìµœì†Œ êµ¬ì¡°ë¼ë„ ë°˜í™˜

    if df.empty or df.isnull().values.any():
        print(f"[âŒ compute_features ì‹¤íŒ¨] ê²°ê³¼ DataFrame ë¬¸ì œ â†’ ë¹ˆ df ë˜ëŠ” NaN ì¡´ì¬")
        safe_failed_result(symbol, strategy, reason="ìµœì¢… ê²°ê³¼ DataFrame ì˜¤ë¥˜")
        return df

    print(f"[âœ… ì™„ë£Œ] {symbol}-{strategy}: í”¼ì²˜ {df.shape[0]}ê°œ ìƒì„±")
    print(f"[ğŸ” feature ìƒíƒœ] {symbol}-{strategy} â†’ shape: {df.shape}, NaN: {df.isnull().values.any()}, ì»¬ëŸ¼ìˆ˜: {len(df.columns)}")
    CacheManager.set(cache_key, df)
    return df
