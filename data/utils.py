# âœ… Render ìºì‹œ ê°•ì œ ë¬´íš¨í™”ìš© ì£¼ì„ â€” ì ˆëŒ€ ì‚­ì œí•˜ì§€ ë§ˆ
_kline_cache = {}

import requests
import pandas as pd
import numpy as np
import time
import pytz

BASE_URL = "https://api.bybit.com"
BTC_DOMINANCE_CACHE = {"value": 0.5, "timestamp": 0}

SYMBOLS = [
    "BTCUSDT", "ETHUSDT", "SOLUSDT", "XRPUSDT", "ADAUSDT",
    "AVAXUSDT", "DOGEUSDT", "MATICUSDT", "DOTUSDT", "TRXUSDT",
    "LTCUSDT", "BCHUSDT", "LINKUSDT", "ATOMUSDT", "XLMUSDT",
    "ETCUSDT", "ICPUSDT", "HBARUSDT", "FILUSDT", "SANDUSDT",
    "RNDRUSDT", "INJUSDT", "NEARUSDT", "APEUSDT", "ARBUSDT",
    "AAVEUSDT", "OPUSDT", "SUIUSDT", "DYDXUSDT", "CHZUSDT",
    "LDOUSDT", "STXUSDT", "GMTUSDT", "FTMUSDT", "WLDUSDT",
    "TIAUSDT", "SEIUSDT", "ARKMUSDT", "JASMYUSDT", "AKTUSDT",
    "GMXUSDT", "SKLUSDT", "BLURUSDT", "ENSUSDT", "CFXUSDT",
    "FLOWUSDT", "ALGOUSDT", "MINAUSDT", "NEOUSDT", "MASKUSDT",
    "KAVAUSDT", "BATUSDT", "ZILUSDT", "WAVESUSDT", "OCEANUSDT",
    "1INCHUSDT", "YFIUSDT", "STGUSDT", "GALAUSDT", "IMXUSDT"
]

STRATEGY_CONFIG = {
    "ë‹¨ê¸°": {"interval": "240", "limit": 600},  # 4ì‹œê°„ë´‰, ìµœëŒ€ 1000ê°œ
    "ì¤‘ê¸°": {"interval": "D", "limit": 600},    # 1ì¼ë´‰, ìµœëŒ€ 1000ê°œ
    "ì¥ê¸°": {"interval": "D", "limit": 600}     # 1ì¼ë´‰, ìµœëŒ€ 1000ê°œ
}

def get_btc_dominance():
    global BTC_DOMINANCE_CACHE
    now = time.time()
    if now - BTC_DOMINANCE_CACHE["timestamp"] < 1800:
        return BTC_DOMINANCE_CACHE["value"]
    try:
        url = "https://api.coinpaprika.com/v1/global"
        res = requests.get(url, timeout=10)
        res.raise_for_status()
        data = res.json()
        dom = float(data["bitcoin_dominance_percentage"]) / 100
        BTC_DOMINANCE_CACHE = {"value": round(dom, 4), "timestamp": now}
        return BTC_DOMINANCE_CACHE["value"]
    except:
        return BTC_DOMINANCE_CACHE["value"]

import numpy as np

def create_dataset(features, window=20, strategy="ë‹¨ê¸°"):
    import numpy as np
    import pandas as pd
    from sklearn.preprocessing import MinMaxScaler

    X, y = [], []

    if not features or len(features) <= window:
        print(f"[âŒ ìŠ¤í‚µ] features ë¶€ì¡± â†’ len={len(features) if features else 0}")
        return np.array([]), np.array([-1])

    try:
        columns = [c for c in features[0].keys() if c != "timestamp"]
    except Exception as e:
        print(f"[ì˜¤ë¥˜] features[0] í‚¤ í™•ì¸ ì‹¤íŒ¨ â†’ {e}")
        return np.array([]), np.array([-1])

    required_keys = {"timestamp", "close", "high"}
    if not all(all(k in f for k in required_keys) for f in features):
        print("[âŒ ìŠ¤í‚µ] í•„ìˆ˜ í‚¤ ëˆ„ë½ëœ feature ì¡´ì¬")
        return np.array([]), np.array([-1])

    df = pd.DataFrame(features)
    df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce")
    df = df.dropna(subset=["timestamp", "close", "high"]).sort_values("timestamp").reset_index(drop=True)

    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df.drop(columns=["timestamp"]))
    df_scaled = pd.DataFrame(scaled, columns=[c for c in df.columns if c != "timestamp"])
    df_scaled["timestamp"] = df["timestamp"].values

    features = df_scaled.to_dict(orient="records")

    class_ranges = [
        (-1.00, -0.60), (-0.60, -0.30), (-0.30, -0.20), (-0.20, -0.15),
        (-0.15, -0.10), (-0.10, -0.07), (-0.07, -0.05), (-0.05, -0.03),
        (-0.03, -0.01), (-0.01, 0.01),
        ( 0.01, 0.03), ( 0.03, 0.05), ( 0.05, 0.07), ( 0.07, 0.10),
        ( 0.10, 0.15), ( 0.15, 0.20), ( 0.20, 0.30), ( 0.30, 0.60),
        ( 0.60, 1.00), ( 1.00, 2.00), ( 2.00, 5.00)
    ]

    strategy_minutes = {"ë‹¨ê¸°": 240, "ì¤‘ê¸°": 1440, "ì¥ê¸°": 10080}
    lookahead_minutes = strategy_minutes.get(strategy, 1440)

    for i in range(window, len(features) - 3):
        try:
            seq = features[i - window:i]
            base = features[i]
            entry_time = pd.to_datetime(base.get("timestamp"), errors="coerce")
            entry_price = float(base.get("close", 0.0))

            if pd.isnull(entry_time) or entry_price <= 0:
                continue

            future = [
                f for f in features[i + 1:]
                if "timestamp" in f and pd.to_datetime(f["timestamp"], errors="coerce") - entry_time <= pd.Timedelta(minutes=lookahead_minutes)
            ]

            if len(seq) != window or len(future) < 1:
                continue

            max_future_price = max(f.get("high", f.get("close", entry_price)) for f in future)
            gain = (max_future_price - entry_price) / (entry_price + 1e-6)

            # âœ… ìˆ˜ì •: gain ê°’ NaN ë°©ì§€
            if pd.isnull(gain) or not np.isfinite(gain):
                gain = 0.0

            # âœ… ìˆ˜ì •: í´ë˜ìŠ¤ ë§¤í•‘ ì•ˆì •í™”
            cls = next((j for j, (low, high) in enumerate(class_ranges) if low <= gain < high), None)
            if cls is None:
                if gain < class_ranges[0][0]:
                    cls = 0
                else:
                    cls = len(class_ranges) - 1

            sample = [[float(r.get(c, 0.0)) for c in columns] for r in seq]
            if any(len(row) != len(columns) for row in sample):
                continue

            X.append(sample)
            y.append(cls)

        except Exception as e:
            print(f"[ì˜ˆì™¸ ë°œìƒ] âŒ {e} â†’ i={i}")
            continue

    if not y:
        print("[âš ï¸ ê²½ê³ ] ìƒì„±ëœ ë¼ë²¨ ì—†ìŒ")
        y = [-1]
    else:
        labels, counts = np.unique(y, return_counts=True)
        print(f"[ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬] â†’ {dict(zip(labels, counts))}")

    return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)

def get_kline_by_strategy(symbol: str, strategy: str):
    global _kline_cache
    cache_key = f"{symbol}-{strategy}"
    if cache_key in _kline_cache:
        print(f"[ìºì‹œ ì‚¬ìš©] {cache_key}")
        return _kline_cache[cache_key]

    config = STRATEGY_CONFIG.get(strategy)
    if config is None:
        print(f"[ì˜¤ë¥˜] ì „ëµ ì„¤ì • ì—†ìŒ: {strategy}")
        # âœ… fallback: ë¹ˆ DataFrame ë°˜í™˜
        return pd.DataFrame(columns=["timestamp", "open", "high", "low", "close", "volume"])

    df = get_kline(symbol, interval=config["interval"], limit=config["limit"])
    if df is None or not isinstance(df, pd.DataFrame):
        print(f"[âŒ ì‹¤íŒ¨] {symbol}-{strategy}: get_kline() â†’ None ë˜ëŠ” í˜•ì‹ ì˜¤ë¥˜")
        # âœ… fallback: ë¹ˆ DataFrame ë°˜í™˜
        return pd.DataFrame(columns=["timestamp", "open", "high", "low", "close", "volume"])

    required_cols = ["open", "high", "low", "close", "volume", "timestamp"]
    missing_or_nan = [col for col in required_cols if col not in df.columns or df[col].isnull().any()]
    if missing_or_nan:
        print(f"[âŒ ì‹¤íŒ¨] {symbol}-{strategy}: í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ ë˜ëŠ” NaN ì¡´ì¬: {missing_or_nan}")
        # âœ… fallback: ë¹ˆ DataFrame ë°˜í™˜
        return pd.DataFrame(columns=required_cols)

    print(f"[í™•ì¸] {symbol}-{strategy}: ë°ì´í„° {len(df)}ê°œ í™•ë³´")
    _kline_cache[cache_key] = df
    return df



def get_kline(symbol: str, interval: str = "60", limit: int = 300) -> pd.DataFrame:
    try:
        url = f"{BASE_URL}/v5/market/kline"
        params = {"category": "linear", "symbol": symbol, "interval": interval, "limit": limit}
        res = requests.get(url, params=params, timeout=10)
        res.raise_for_status()
        data = res.json()

        if "result" not in data or "list" not in data["result"]:
            print(f"[ê²½ê³ ] get_kline() â†’ ë°ì´í„° ì‘ë‹µ êµ¬ì¡° ì´ìƒ: {symbol}")
            return None

        raw = data["result"]["list"]
        if not raw or len(raw[0]) < 6:
            print(f"[ê²½ê³ ] get_kline() â†’ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {symbol}")
            return None

        df = pd.DataFrame(raw, columns=[
            "timestamp", "open", "high", "low", "close", "volume", "turnover"
        ])
        df = df[["timestamp", "open", "high", "low", "close", "volume"]].apply(pd.to_numeric, errors="coerce")

        # âœ… í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ or ì „ë¶€ NaN or ì „ë¶€ 0ì¸ ê²½ìš° ì œê±°
        essential = ["open", "high", "low", "close", "volume"]
        df.dropna(subset=essential, inplace=True)
        if df.empty:
            print(f"[ê²½ê³ ] get_kline() â†’ í•„ìˆ˜ê°’ ê²°ì¸¡: {symbol}")
            return None

        if "high" not in df.columns or df["high"].isnull().all() or (df["high"] == 0).all():
            print(f"[ì¹˜ëª…] get_kline() â†’ 'high' ê°’ ì „ë¶€ ë¹„ì •ìƒ: {symbol}")
            return None

        df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", errors="coerce")
        df = df.dropna(subset=["timestamp"])
        df["timestamp"] = df["timestamp"].dt.tz_localize("UTC").dt.tz_convert("Asia/Seoul")
        df = df.sort_values("timestamp").reset_index(drop=True)
        df["datetime"] = df["timestamp"]

        return df

    except Exception as e:
        print(f"[ì—ëŸ¬] get_kline({symbol}) ì‹¤íŒ¨ â†’ {e}")
        return None


def get_realtime_prices():
    url = f"{BASE_URL}/v5/market/tickers"
    params = {"category": "linear"}
    try:
        res = requests.get(url, params=params, timeout=10)
        res.raise_for_status()
        data = res.json()
        if "result" not in data or "list" not in data["result"]:
            return {}
        tickers = data["result"]["list"]
        return {item["symbol"]: float(item["lastPrice"]) for item in tickers if item["symbol"] in SYMBOLS}
    except:
        return {}

_feature_cache = {}

def compute_features(symbol: str, df: pd.DataFrame, strategy: str) -> pd.DataFrame:
    global _feature_cache
    cache_key = f"{symbol}-{strategy}"
    if cache_key in _feature_cache:
        print(f"[ìºì‹œ ì‚¬ìš©] {cache_key} í”¼ì²˜")
        return _feature_cache[cache_key]

    df = df.copy()

    if "datetime" in df.columns:
        df["timestamp"] = df["datetime"]
    elif "timestamp" not in df.columns:
        df["timestamp"] = pd.to_datetime("now")

    # âœ… strategy ì»¬ëŸ¼ ì¶”ê°€
    df["strategy"] = strategy

    # âœ… Feature ê³„ì‚° ì¶”ê°€
    df["ma20"] = df["close"].rolling(window=20, min_periods=1).mean()
    delta = df["close"].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14, min_periods=1).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14, min_periods=1).mean()
    rs = gain / (loss + 1e-6)
    df["rsi"] = 100 - (100 / (1 + rs))
    ema12 = df["close"].ewm(span=12, adjust=False).mean()
    ema26 = df["close"].ewm(span=26, adjust=False).mean()
    df["macd"] = ema12 - ema26
    df["bollinger"] = df["close"].rolling(window=20, min_periods=1).std()
    df["volatility"] = df["high"] - df["low"]
    df["trend_score"] = (df["close"] > df["ma20"]).astype(int)
    min14 = df["close"].rolling(window=14, min_periods=1).min()
    max14 = df["close"].rolling(window=14, min_periods=1).max()
    df["stoch_rsi"] = (df["close"] - min14) / (max14 - min14 + 1e-6)
    typical = (df["high"] + df["low"] + df["close"]) / 3
    ma_typical = typical.rolling(window=20, min_periods=1).mean()
    md = (typical - ma_typical).abs().rolling(window=20, min_periods=1).mean()
    df["cci"] = (typical - ma_typical) / (0.015 * md + 1e-6)
    df["obv"] = (np.sign(df["close"].diff()) * df["volume"]).fillna(0).cumsum()

    # âœ… ì¤‘ê¸°, ì¥ê¸° ì¶”ê°€ feature ê³„ì‚°
    if strategy == "ì¤‘ê¸°":
        df["ema_cross"] = ema12 > ema26
    elif strategy == "ì¥ê¸°":
        df["volume_cumsum"] = df["volume"].cumsum()
        df["roc"] = df["close"].pct_change(periods=10)
        df["mfi"] = df["volume"] / (df["high"] - df["low"] + 1e-6)

    # âœ… NaN, inf ë°©ì§€
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.fillna(0, inplace=True)

    # âœ… í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    base = [
        "timestamp", "strategy", "open", "high", "low", "close", "volume",
        "ma20", "rsi", "macd", "bollinger", "volatility",
        "trend_score", "stoch_rsi", "cci", "obv"
    ]
    if strategy == "ì¤‘ê¸°":
        base.append("ema_cross")
    elif strategy == "ì¥ê¸°":
        base += ["volume_cumsum", "roc", "mfi"]

    df = df[base].reset_index(drop=True)

    required_cols = ["timestamp", "close", "high"]
    missing_cols = [col for col in required_cols if col not in df.columns or df[col].isnull().any()]
    if missing_cols or df.empty:
        print(f"[âŒ compute_features ì‹¤íŒ¨] í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ ë˜ëŠ” NaN ì¡´ì¬: {missing_cols}")
        return None

    print(f"[ì™„ë£Œ] {symbol}-{strategy}: í”¼ì²˜ {df.shape[0]}ê°œ ìƒì„±")
    _feature_cache[cache_key] = df
    return df

# data/utils.py ë§¨ ì•„ë˜ì— ì¶”ê°€

SYMBOL_GROUPS = [SYMBOLS[i:i+5] for i in range(0, len(SYMBOLS), 5)]
